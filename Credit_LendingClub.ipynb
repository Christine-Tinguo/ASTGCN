{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RuBwAbQ33xuLcmSHD54Age4eiZIIZY-k",
      "authorship_tag": "ABX9TyNwZteg4Q2Nw+eRpdMDJKoQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christine-Tinguo/ASTGCN/blob/master/Credit_LendingClub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWQrhY55wJVx"
      },
      "outputs": [],
      "source": [
        "# Environment set up\n",
        "\n",
        "1. python==3.7.10\n",
        "\n",
        "2. pip install requirements.txt\n",
        "\n",
        "# Data uncompression\n",
        "\n",
        "1. put train_data.csv, train_labels.csv, test_data.csv in ./input/\n",
        "\n",
        "# Running\n",
        "\n",
        "1. sh run.sh\n",
        "\n",
        "# Result\n",
        "\n",
        "1. final submission in ./output/final_submission.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C9GhWj29kk5",
        "outputId": "4fb3420e-cae9-4b0f-c656-856783de38c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Credit_risk/Kaggle-American-Express"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBs4CZ-9wVxO",
        "outputId": "5dca8870-4082-460d-eb43-f984ee67a4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Credit_risk/Kaggle-American-Express\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Credit_risk/Lending_Club_Credit.zip -d /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CXrR2yCPphv",
        "outputId": "3eab9c7e-b2d0-4385-9fcc-9cb904845f5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Credit_risk/Lending_Club_Credit.zip\n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/scheduler.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/S6_NN_main.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/S2_manual_feature.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/model.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/S5_LGB_main.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/S4_feature_combined.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/S3_series_feature.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/README.md  \n",
            "   creating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/.ipynb_checkpoints/\n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/S7_ensemble.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/.DS_Store  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/requirements.txt  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/utils.py  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/run.sh  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/__pycache__/utils.cpython-38.pyc  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/__pycache__/utils.cpython-37.pyc  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/__pycache__/model.cpython-38.pyc  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/__pycache__/scheduler.cpython-38.pyc  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/__pycache__/scheduler.cpython-37.pyc  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/__pycache__/model.cpython-37.pyc  \n",
            "  inflating: /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/Kaggle-American-Express/S1_denoise.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Credit_risk/Kaggle-American-Express/input/amex-default-prediction.zip"
      ],
      "metadata": {
        "id": "AFbzEQQ8mJ4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGXyadU3wWDf",
        "outputId": "4334a897-8985-4901-cbcf-0661e076db6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement requirements.txt (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for requirements.txt\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh run.sh"
      ],
      "metadata": {
        "id": "6QjPLx4YwlUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python S1_denoise.py"
      ],
      "metadata": {
        "id": "B05WhESCxEZQ",
        "outputId": "56a2967f-b8ac-48bc-bebb-f1c6d6b5e144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start ------\n",
            "train.shape (50000, 190)\n",
            "100% 190/190 [00:00<00:00, 1391.33it/s]\n",
            "test.shape (80000, 190)\n",
            "100% 190/190 [00:00<00:00, 1113.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"start ------\")\n",
        "train_L = pd.read_csv('/content/drive/MyDrive/Credit_risk/Kaggle-American-Express/input/train_labels.csv')\n",
        "#train = pd.read_parquet('./input/train.parquet')\n",
        "print(\"train_L.shape\",train_L.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUjfl6-W3xcM",
        "outputId": "1cd21e5c-2fe8-40cb-903e-f80f316477fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start ------\n",
            "train_L.shape (458913, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python S2_manual_feature.py"
      ],
      "metadata": {
        "id": "KBsHWwtn2JWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29497b1-4e13-4a13-8600-1ca2de1155c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------li-----------: 0\n",
            "one hot encoding: B_30\n",
            "one hot encoding: B_38\n",
            "one hot encoding: D_114\n",
            "one hot encoding: D_116\n",
            "one hot encoding: D_117\n",
            "one hot encoding: D_120\n",
            "one hot encoding: D_126\n",
            "one hot encoding: D_63\n",
            "one hot encoding: D_64\n",
            "one hot encoding: D_66\n",
            "one hot encoding: D_68\n",
            "cat_feature: 100% 16/16 [00:04<00:00,  3.73it/s]\n",
            "prefix----: \n",
            "cat_feature_df.shape-----------: (10683, 208)\n",
            "num_feature: 100% 16/16 [00:10<00:00,  1.52it/s]\n",
            "prefix----: \n",
            "num_feature_df.shape-----------: (10683, 1063)\n",
            "diff_feature: 100% 16/16 [00:06<00:00,  2.41it/s]\n",
            "prefix----: \n",
            "diff_feature_df.shape-----------: (10683, 1063)\n",
            "num_feature: 100% 16/16 [00:03<00:00,  4.63it/s]\n",
            "prefix----: rank_\n",
            "num_feature_df.shape-----------: (10683, 178)\n",
            "num_feature: 100% 16/16 [00:07<00:00,  2.05it/s]\n",
            "prefix----: ym_rank_\n",
            "num_feature_df.shape-----------: (10683, 1063)\n",
            "-----------li-----------: 1\n",
            "all df shape (130000, 190)\n",
            "last 3 shape (31725, 190)\n",
            "one hot encoding: B_30\n",
            "one hot encoding: B_38\n",
            "one hot encoding: D_114\n",
            "one hot encoding: D_116\n",
            "one hot encoding: D_117\n",
            "one hot encoding: D_120\n",
            "one hot encoding: D_126\n",
            "one hot encoding: D_63\n",
            "one hot encoding: D_64\n",
            "one hot encoding: D_66\n",
            "one hot encoding: D_68\n",
            "cat_feature: 100% 16/16 [00:01<00:00, 11.31it/s]\n",
            "prefix----: last3_\n",
            "cat_feature_df.shape-----------: (10683, 142)\n",
            "num_feature: 100% 16/16 [00:00<00:00, 17.00it/s]\n",
            "prefix----: last3_\n",
            "num_feature_df.shape-----------: (10683, 886)\n",
            "diff_feature: 100% 16/16 [00:01<00:00, 15.93it/s]\n",
            "prefix----: last3_\n",
            "diff_feature_df.shape-----------: (10683, 886)\n",
            "-----------li-----------: 2\n",
            "all df shape (130000, 190)\n",
            "last 6 shape (62466, 190)\n",
            "num_feature: 100% 16/16 [00:03<00:00,  4.77it/s]\n",
            "prefix----: last6_\n",
            "num_feature_df.shape-----------: (10683, 886)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python S3_series_feature.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84o299Beuihy",
        "outputId": "9b41a347-6cc0-4800-fbf0-554cab2ee129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "available gpus: []\n",
            "-----------train.shape----------- (5000, 190)\n",
            "-----------test.shape----------- (8000, 190)\n",
            "(5000, 191) (8000, 190)\n",
            "====utils.py====test.shape (8000, 190)\n",
            "----features.len: 188\n",
            "[50]\ttraining's binary_logloss: 0.444032\tvalid_1's binary_logloss: 0.472427\n",
            "[100]\ttraining's binary_logloss: 0.385261\tvalid_1's binary_logloss: 0.428589\n",
            "[150]\ttraining's binary_logloss: 0.359246\tvalid_1's binary_logloss: 0.405767\n",
            "[200]\ttraining's binary_logloss: 0.345325\tvalid_1's binary_logloss: 0.397006\n",
            "[250]\ttraining's binary_logloss: 0.314403\tvalid_1's binary_logloss: 0.381821\n",
            "[300]\ttraining's binary_logloss: 0.29471\tvalid_1's binary_logloss: 0.376968\n",
            "[350]\ttraining's binary_logloss: 0.279002\tvalid_1's binary_logloss: 0.373886\n",
            "[400]\ttraining's binary_logloss: 0.270954\tvalid_1's binary_logloss: 0.371293\n",
            "[450]\ttraining's binary_logloss: 0.265217\tvalid_1's binary_logloss: 0.372245\n",
            "[500]\ttraining's binary_logloss: 0.243459\tvalid_1's binary_logloss: 0.370011\n",
            "[550]\ttraining's binary_logloss: 0.235131\tvalid_1's binary_logloss: 0.36855\n",
            "[600]\ttraining's binary_logloss: 0.22852\tvalid_1's binary_logloss: 0.37349\n",
            "[650]\ttraining's binary_logloss: 0.21189\tvalid_1's binary_logloss: 0.374113\n",
            "[700]\ttraining's binary_logloss: 0.202099\tvalid_1's binary_logloss: 0.376231\n",
            "[750]\ttraining's binary_logloss: 0.191404\tvalid_1's binary_logloss: 0.378889\n",
            "[800]\ttraining's binary_logloss: 0.183848\tvalid_1's binary_logloss: 0.38024\n",
            "[850]\ttraining's binary_logloss: 0.174262\tvalid_1's binary_logloss: 0.381393\n",
            "[900]\ttraining's binary_logloss: 0.169417\tvalid_1's binary_logloss: 0.38216\n",
            "[950]\ttraining's binary_logloss: 0.168776\tvalid_1's binary_logloss: 0.377775\n",
            "[1000]\ttraining's binary_logloss: 0.163331\tvalid_1's binary_logloss: 0.381132\n",
            "[1050]\ttraining's binary_logloss: 0.158656\tvalid_1's binary_logloss: 0.382398\n",
            "[1100]\ttraining's binary_logloss: 0.149559\tvalid_1's binary_logloss: 0.385982\n",
            "[1150]\ttraining's binary_logloss: 0.148628\tvalid_1's binary_logloss: 0.384607\n",
            "[1200]\ttraining's binary_logloss: 0.144627\tvalid_1's binary_logloss: 0.383718\n",
            "[1250]\ttraining's binary_logloss: 0.14131\tvalid_1's binary_logloss: 0.38394\n",
            "[1300]\ttraining's binary_logloss: 0.139272\tvalid_1's binary_logloss: 0.384937\n",
            "[1350]\ttraining's binary_logloss: 0.136902\tvalid_1's binary_logloss: 0.383317\n",
            "[1400]\ttraining's binary_logloss: 0.131612\tvalid_1's binary_logloss: 0.387288\n",
            "[1450]\ttraining's binary_logloss: 0.129545\tvalid_1's binary_logloss: 0.387197\n",
            "[1500]\ttraining's binary_logloss: 0.127022\tvalid_1's binary_logloss: 0.389561\n",
            "[1550]\ttraining's binary_logloss: 0.12133\tvalid_1's binary_logloss: 0.396751\n",
            "[1600]\ttraining's binary_logloss: 0.11729\tvalid_1's binary_logloss: 0.398857\n",
            "[1650]\ttraining's binary_logloss: 0.114366\tvalid_1's binary_logloss: 0.39898\n",
            "[1700]\ttraining's binary_logloss: 0.112435\tvalid_1's binary_logloss: 0.401543\n",
            "[1750]\ttraining's binary_logloss: 0.11074\tvalid_1's binary_logloss: 0.399582\n",
            "[1800]\ttraining's binary_logloss: 0.109694\tvalid_1's binary_logloss: 0.397622\n",
            "[1850]\ttraining's binary_logloss: 0.107573\tvalid_1's binary_logloss: 0.40135\n",
            "[1900]\ttraining's binary_logloss: 0.105167\tvalid_1's binary_logloss: 0.402018\n",
            "[1950]\ttraining's binary_logloss: 0.102153\tvalid_1's binary_logloss: 0.404997\n",
            "[2000]\ttraining's binary_logloss: 0.100321\tvalid_1's binary_logloss: 0.407144\n",
            "[2050]\ttraining's binary_logloss: 0.0987063\tvalid_1's binary_logloss: 0.407005\n",
            "[2100]\ttraining's binary_logloss: 0.0971337\tvalid_1's binary_logloss: 0.408497\n",
            "[2150]\ttraining's binary_logloss: 0.0970064\tvalid_1's binary_logloss: 0.407075\n",
            "[2200]\ttraining's binary_logloss: 0.094576\tvalid_1's binary_logloss: 0.411712\n",
            "[2250]\ttraining's binary_logloss: 0.0927119\tvalid_1's binary_logloss: 0.415201\n",
            "[2300]\ttraining's binary_logloss: 0.090524\tvalid_1's binary_logloss: 0.418\n",
            "[2350]\ttraining's binary_logloss: 0.0891513\tvalid_1's binary_logloss: 0.417968\n",
            "[2400]\ttraining's binary_logloss: 0.0881632\tvalid_1's binary_logloss: 0.418603\n",
            "[2450]\ttraining's binary_logloss: 0.0864823\tvalid_1's binary_logloss: 0.41829\n",
            "[2500]\ttraining's binary_logloss: 0.0856791\tvalid_1's binary_logloss: 0.416478\n",
            "[2550]\ttraining's binary_logloss: 0.0845395\tvalid_1's binary_logloss: 0.418033\n",
            "[2600]\ttraining's binary_logloss: 0.0831458\tvalid_1's binary_logloss: 0.421396\n",
            "[2650]\ttraining's binary_logloss: 0.0818217\tvalid_1's binary_logloss: 0.422543\n",
            "[2700]\ttraining's binary_logloss: 0.0803386\tvalid_1's binary_logloss: 0.424022\n",
            "[2750]\ttraining's binary_logloss: 0.0797382\tvalid_1's binary_logloss: 0.423564\n",
            "[2800]\ttraining's binary_logloss: 0.0787656\tvalid_1's binary_logloss: 0.422475\n",
            "[2850]\ttraining's binary_logloss: 0.0766608\tvalid_1's binary_logloss: 0.426075\n",
            "[2900]\ttraining's binary_logloss: 0.0758291\tvalid_1's binary_logloss: 0.428014\n",
            "[2950]\ttraining's binary_logloss: 0.0744081\tvalid_1's binary_logloss: 0.43103\n",
            "[3000]\ttraining's binary_logloss: 0.0729136\tvalid_1's binary_logloss: 0.433374\n",
            "[3050]\ttraining's binary_logloss: 0.0717642\tvalid_1's binary_logloss: 0.434285\n",
            "[3100]\ttraining's binary_logloss: 0.0708982\tvalid_1's binary_logloss: 0.435729\n",
            "[3150]\ttraining's binary_logloss: 0.0700932\tvalid_1's binary_logloss: 0.437815\n",
            "[3200]\ttraining's binary_logloss: 0.0686761\tvalid_1's binary_logloss: 0.438543\n",
            "[3250]\ttraining's binary_logloss: 0.0676741\tvalid_1's binary_logloss: 0.438008\n",
            "[3300]\ttraining's binary_logloss: 0.0668783\tvalid_1's binary_logloss: 0.440341\n",
            "[3350]\ttraining's binary_logloss: 0.0655024\tvalid_1's binary_logloss: 0.44064\n",
            "[3400]\ttraining's binary_logloss: 0.0642559\tvalid_1's binary_logloss: 0.443774\n",
            "[3450]\ttraining's binary_logloss: 0.0631678\tvalid_1's binary_logloss: 0.445544\n",
            "[3500]\ttraining's binary_logloss: 0.0625989\tvalid_1's binary_logloss: 0.446672\n",
            "[3550]\ttraining's binary_logloss: 0.0618244\tvalid_1's binary_logloss: 0.447175\n",
            "[3600]\ttraining's binary_logloss: 0.0609554\tvalid_1's binary_logloss: 0.451646\n",
            "[3650]\ttraining's binary_logloss: 0.0601669\tvalid_1's binary_logloss: 0.453946\n",
            "[3700]\ttraining's binary_logloss: 0.0585018\tvalid_1's binary_logloss: 0.456664\n",
            "[3750]\ttraining's binary_logloss: 0.0577897\tvalid_1's binary_logloss: 0.454403\n",
            "[3800]\ttraining's binary_logloss: 0.0571365\tvalid_1's binary_logloss: 0.455711\n",
            "[3850]\ttraining's binary_logloss: 0.0564903\tvalid_1's binary_logloss: 0.455305\n",
            "[3900]\ttraining's binary_logloss: 0.0560895\tvalid_1's binary_logloss: 0.455587\n",
            "[3950]\ttraining's binary_logloss: 0.0561234\tvalid_1's binary_logloss: 0.454955\n",
            "[4000]\ttraining's binary_logloss: 0.055107\tvalid_1's binary_logloss: 0.457333\n",
            "[4050]\ttraining's binary_logloss: 0.0544849\tvalid_1's binary_logloss: 0.458362\n",
            "[4100]\ttraining's binary_logloss: 0.0537556\tvalid_1's binary_logloss: 0.45995\n",
            "[4150]\ttraining's binary_logloss: 0.0528676\tvalid_1's binary_logloss: 0.462163\n",
            "[4200]\ttraining's binary_logloss: 0.0521621\tvalid_1's binary_logloss: 0.462403\n",
            "[4250]\ttraining's binary_logloss: 0.0515313\tvalid_1's binary_logloss: 0.463728\n",
            "[4300]\ttraining's binary_logloss: 0.0504187\tvalid_1's binary_logloss: 0.465722\n",
            "[4350]\ttraining's binary_logloss: 0.050149\tvalid_1's binary_logloss: 0.465706\n",
            "[4400]\ttraining's binary_logloss: 0.0497293\tvalid_1's binary_logloss: 0.464886\n",
            "[4450]\ttraining's binary_logloss: 0.0490502\tvalid_1's binary_logloss: 0.466053\n",
            "[4500]\ttraining's binary_logloss: 0.0487062\tvalid_1's binary_logloss: 0.467589\n",
            " - 0 round - train_metric: 0.676234 - valid_metric: 0.678538\n",
            "\n",
            " - 50 round - train_metric: 0.446238 - valid_metric: 0.474299\n",
            "\n",
            " - 100 round - train_metric: 0.381181 - valid_metric: 0.425344\n",
            "\n",
            " - 150 round - train_metric: 0.361161 - valid_metric: 0.407045\n",
            "\n",
            " - 200 round - train_metric: 0.346617 - valid_metric: 0.397962\n",
            "\n",
            " - 250 round - train_metric: 0.312528 - valid_metric: 0.381521\n",
            "\n",
            " - 300 round - train_metric: 0.292971 - valid_metric: 0.376663\n",
            "\n",
            " - 350 round - train_metric: 0.279792 - valid_metric: 0.374044\n",
            "\n",
            " - 400 round - train_metric: 0.271634 - valid_metric: 0.371467\n",
            "\n",
            " - 450 round - train_metric: 0.265811 - valid_metric: 0.372351\n",
            "\n",
            " - 500 round - train_metric: 0.242558 - valid_metric: 0.369777\n",
            "\n",
            " - 550 round - train_metric: 0.234144 - valid_metric: 0.368011\n",
            "\n",
            " - 600 round - train_metric: 0.227757 - valid_metric: 0.373394\n",
            "\n",
            " - 650 round - train_metric: 0.212178 - valid_metric: 0.374071\n",
            "\n",
            " - 700 round - train_metric: 0.202419 - valid_metric: 0.376084\n",
            "\n",
            " - 750 round - train_metric: 0.191711 - valid_metric: 0.378779\n",
            "\n",
            " - 800 round - train_metric: 0.184054 - valid_metric: 0.380063\n",
            "\n",
            " - 850 round - train_metric: 0.173816 - valid_metric: 0.381438\n",
            "\n",
            " - 900 round - train_metric: 0.169025 - valid_metric: 0.381970\n",
            "\n",
            " - 950 round - train_metric: 0.168334 - valid_metric: 0.378262\n",
            "\n",
            " - 1000 round - train_metric: 0.163514 - valid_metric: 0.380886\n",
            "\n",
            " - 1050 round - train_metric: 0.158262 - valid_metric: 0.382566\n",
            "\n",
            " - 1100 round - train_metric: 0.149295 - valid_metric: 0.385797\n",
            "\n",
            " - 1150 round - train_metric: 0.148760 - valid_metric: 0.384458\n",
            "\n",
            " - 1200 round - train_metric: 0.144760 - valid_metric: 0.383601\n",
            "\n",
            " - 1250 round - train_metric: 0.141425 - valid_metric: 0.383792\n",
            "\n",
            " - 1300 round - train_metric: 0.139384 - valid_metric: 0.384799\n",
            "\n",
            " - 1350 round - train_metric: 0.137042 - valid_metric: 0.383137\n",
            "\n",
            " - 1400 round - train_metric: 0.131458 - valid_metric: 0.387527\n",
            "\n",
            " - 1450 round - train_metric: 0.129655 - valid_metric: 0.387074\n",
            "\n",
            " - 1500 round - train_metric: 0.126862 - valid_metric: 0.389468\n",
            "\n",
            " - 1550 round - train_metric: 0.121135 - valid_metric: 0.397004\n",
            "\n",
            " - 1600 round - train_metric: 0.117408 - valid_metric: 0.398678\n",
            "\n",
            " - 1650 round - train_metric: 0.114155 - valid_metric: 0.399291\n",
            "\n",
            " - 1700 round - train_metric: 0.112228 - valid_metric: 0.401523\n",
            "\n",
            " - 1750 round - train_metric: 0.110827 - valid_metric: 0.399447\n",
            "\n",
            " - 1800 round - train_metric: 0.109500 - valid_metric: 0.397769\n",
            "\n",
            " - 1850 round - train_metric: 0.107685 - valid_metric: 0.401132\n",
            "\n",
            " - 1900 round - train_metric: 0.105038 - valid_metric: 0.402340\n",
            "\n",
            " - 1950 round - train_metric: 0.102223 - valid_metric: 0.404924\n",
            "\n",
            " - 2000 round - train_metric: 0.100197 - valid_metric: 0.406707\n",
            "\n",
            " - 2050 round - train_metric: 0.098770 - valid_metric: 0.406912\n",
            "\n",
            " - 2100 round - train_metric: 0.097189 - valid_metric: 0.408397\n",
            "\n",
            " - 2150 round - train_metric: 0.097084 - valid_metric: 0.406964\n",
            "\n",
            " - 2200 round - train_metric: 0.094652 - valid_metric: 0.411577\n",
            "\n",
            " - 2250 round - train_metric: 0.092613 - valid_metric: 0.415384\n",
            "\n",
            " - 2300 round - train_metric: 0.090595 - valid_metric: 0.417889\n",
            "\n",
            " - 2350 round - train_metric: 0.089227 - valid_metric: 0.417837\n",
            "\n",
            " - 2400 round - train_metric: 0.088049 - valid_metric: 0.418337\n",
            "\n",
            " - 2450 round - train_metric: 0.086360 - valid_metric: 0.418186\n",
            "\n",
            " - 2500 round - train_metric: 0.085716 - valid_metric: 0.416409\n",
            "\n",
            " - 2550 round - train_metric: 0.084422 - valid_metric: 0.418154\n",
            "\n",
            " - 2600 round - train_metric: 0.083179 - valid_metric: 0.421295\n",
            "\n",
            " - 2650 round - train_metric: 0.081855 - valid_metric: 0.422460\n",
            "\n",
            " - 2700 round - train_metric: 0.080386 - valid_metric: 0.423956\n",
            "\n",
            " - 2750 round - train_metric: 0.079779 - valid_metric: 0.423496\n",
            "\n",
            " - 2800 round - train_metric: 0.078679 - valid_metric: 0.422900\n",
            "\n",
            " - 2850 round - train_metric: 0.076699 - valid_metric: 0.426001\n",
            "\n",
            " - 2900 round - train_metric: 0.075883 - valid_metric: 0.427902\n",
            "\n",
            " - 2950 round - train_metric: 0.074445 - valid_metric: 0.430942\n",
            "\n",
            " - 3000 round - train_metric: 0.072948 - valid_metric: 0.433277\n",
            "\n",
            " - 3050 round - train_metric: 0.071663 - valid_metric: 0.434451\n",
            "\n",
            " - 3100 round - train_metric: 0.070926 - valid_metric: 0.435638\n",
            "\n",
            " - 3150 round - train_metric: 0.070131 - valid_metric: 0.437730\n",
            "\n",
            " - 3200 round - train_metric: 0.068591 - valid_metric: 0.438824\n",
            "\n",
            " - 3250 round - train_metric: 0.067698 - valid_metric: 0.437944\n",
            "\n",
            " - 3300 round - train_metric: 0.066914 - valid_metric: 0.440242\n",
            "\n",
            " - 3350 round - train_metric: 0.065535 - valid_metric: 0.440527\n",
            "\n",
            " - 3400 round - train_metric: 0.064285 - valid_metric: 0.443700\n",
            "\n",
            " - 3450 round - train_metric: 0.063081 - valid_metric: 0.445526\n",
            "\n",
            " - 3500 round - train_metric: 0.062528 - valid_metric: 0.446869\n",
            "\n",
            " - 3550 round - train_metric: 0.061846 - valid_metric: 0.447108\n",
            "\n",
            " - 3600 round - train_metric: 0.060982 - valid_metric: 0.451544\n",
            "\n",
            " - 3650 round - train_metric: 0.060208 - valid_metric: 0.453812\n",
            "\n",
            " - 3700 round - train_metric: 0.058445 - valid_metric: 0.456599\n",
            "\n",
            " - 3750 round - train_metric: 0.057731 - valid_metric: 0.454549\n",
            "\n",
            " - 3800 round - train_metric: 0.057087 - valid_metric: 0.455988\n",
            "\n",
            " - 3850 round - train_metric: 0.056436 - valid_metric: 0.455385\n",
            "\n",
            " - 3900 round - train_metric: 0.056108 - valid_metric: 0.455535\n",
            "\n",
            " - 3950 round - train_metric: 0.056068 - valid_metric: 0.454973\n",
            "\n",
            " - 4000 round - train_metric: 0.055053 - valid_metric: 0.457619\n",
            "\n",
            " - 4050 round - train_metric: 0.054507 - valid_metric: 0.458282\n",
            "\n",
            " - 4100 round - train_metric: 0.053784 - valid_metric: 0.459865\n",
            "\n",
            " - 4150 round - train_metric: 0.052895 - valid_metric: 0.462074\n",
            "\n",
            " - 4200 round - train_metric: 0.052184 - valid_metric: 0.462349\n",
            "\n",
            " - 4250 round - train_metric: 0.051553 - valid_metric: 0.463674\n",
            "\n",
            " - 4300 round - train_metric: 0.050449 - valid_metric: 0.465634\n",
            "\n",
            " - 4350 round - train_metric: 0.050098 - valid_metric: 0.465814\n",
            "\n",
            " - 4400 round - train_metric: 0.049694 - valid_metric: 0.464917\n",
            "\n",
            " - 4450 round - train_metric: 0.049069 - valid_metric: 0.465994\n",
            "\n",
            "- fold0 valid metric: 0.548732\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.454062\tvalid_1's binary_logloss: 0.444032\n",
            "[100]\ttraining's binary_logloss: 0.400688\tvalid_1's binary_logloss: 0.39146\n",
            "[150]\ttraining's binary_logloss: 0.375824\tvalid_1's binary_logloss: 0.368865\n",
            "[200]\ttraining's binary_logloss: 0.363249\tvalid_1's binary_logloss: 0.355688\n",
            "[250]\ttraining's binary_logloss: 0.333082\tvalid_1's binary_logloss: 0.325102\n",
            "[300]\ttraining's binary_logloss: 0.315031\tvalid_1's binary_logloss: 0.307932\n",
            "[350]\ttraining's binary_logloss: 0.30012\tvalid_1's binary_logloss: 0.296906\n",
            "[400]\ttraining's binary_logloss: 0.292999\tvalid_1's binary_logloss: 0.292631\n",
            "[450]\ttraining's binary_logloss: 0.287624\tvalid_1's binary_logloss: 0.287272\n",
            "[500]\ttraining's binary_logloss: 0.267039\tvalid_1's binary_logloss: 0.269149\n",
            "[550]\ttraining's binary_logloss: 0.257809\tvalid_1's binary_logloss: 0.261957\n",
            "[600]\ttraining's binary_logloss: 0.251125\tvalid_1's binary_logloss: 0.259596\n",
            "[650]\ttraining's binary_logloss: 0.236348\tvalid_1's binary_logloss: 0.252136\n",
            "[700]\ttraining's binary_logloss: 0.225141\tvalid_1's binary_logloss: 0.249834\n",
            "[750]\ttraining's binary_logloss: 0.214064\tvalid_1's binary_logloss: 0.244657\n",
            "[800]\ttraining's binary_logloss: 0.20675\tvalid_1's binary_logloss: 0.242205\n",
            "[850]\ttraining's binary_logloss: 0.195407\tvalid_1's binary_logloss: 0.240881\n",
            "[900]\ttraining's binary_logloss: 0.189186\tvalid_1's binary_logloss: 0.239116\n",
            "[950]\ttraining's binary_logloss: 0.187956\tvalid_1's binary_logloss: 0.241228\n",
            "[1000]\ttraining's binary_logloss: 0.180364\tvalid_1's binary_logloss: 0.239784\n",
            "[1050]\ttraining's binary_logloss: 0.176113\tvalid_1's binary_logloss: 0.238916\n",
            "[1100]\ttraining's binary_logloss: 0.166072\tvalid_1's binary_logloss: 0.236664\n",
            "[1150]\ttraining's binary_logloss: 0.164597\tvalid_1's binary_logloss: 0.238848\n",
            "[1200]\ttraining's binary_logloss: 0.160064\tvalid_1's binary_logloss: 0.239303\n",
            "[1250]\ttraining's binary_logloss: 0.156227\tvalid_1's binary_logloss: 0.239156\n",
            "[1300]\ttraining's binary_logloss: 0.15378\tvalid_1's binary_logloss: 0.235307\n",
            "[1350]\ttraining's binary_logloss: 0.152\tvalid_1's binary_logloss: 0.23494\n",
            "[1400]\ttraining's binary_logloss: 0.145783\tvalid_1's binary_logloss: 0.234948\n",
            "[1450]\ttraining's binary_logloss: 0.143645\tvalid_1's binary_logloss: 0.235553\n",
            "[1500]\ttraining's binary_logloss: 0.141555\tvalid_1's binary_logloss: 0.235976\n",
            "[1550]\ttraining's binary_logloss: 0.135275\tvalid_1's binary_logloss: 0.233223\n",
            "[1600]\ttraining's binary_logloss: 0.130668\tvalid_1's binary_logloss: 0.233924\n",
            "[1650]\ttraining's binary_logloss: 0.127526\tvalid_1's binary_logloss: 0.233496\n",
            "[1700]\ttraining's binary_logloss: 0.125583\tvalid_1's binary_logloss: 0.234649\n",
            "[1750]\ttraining's binary_logloss: 0.123587\tvalid_1's binary_logloss: 0.23504\n",
            "[1800]\ttraining's binary_logloss: 0.122793\tvalid_1's binary_logloss: 0.235079\n",
            "[1850]\ttraining's binary_logloss: 0.120228\tvalid_1's binary_logloss: 0.233204\n",
            "[1900]\ttraining's binary_logloss: 0.117973\tvalid_1's binary_logloss: 0.233366\n",
            "[1950]\ttraining's binary_logloss: 0.114778\tvalid_1's binary_logloss: 0.234795\n",
            "[2000]\ttraining's binary_logloss: 0.112587\tvalid_1's binary_logloss: 0.235139\n",
            "[2050]\ttraining's binary_logloss: 0.110839\tvalid_1's binary_logloss: 0.232963\n",
            "[2100]\ttraining's binary_logloss: 0.109199\tvalid_1's binary_logloss: 0.231052\n",
            "[2150]\ttraining's binary_logloss: 0.108967\tvalid_1's binary_logloss: 0.232497\n",
            "[2200]\ttraining's binary_logloss: 0.10635\tvalid_1's binary_logloss: 0.233386\n",
            "[2250]\ttraining's binary_logloss: 0.104285\tvalid_1's binary_logloss: 0.234064\n",
            "[2300]\ttraining's binary_logloss: 0.101701\tvalid_1's binary_logloss: 0.232892\n",
            "[2350]\ttraining's binary_logloss: 0.100225\tvalid_1's binary_logloss: 0.233642\n",
            "[2400]\ttraining's binary_logloss: 0.0990997\tvalid_1's binary_logloss: 0.233223\n",
            "[2450]\ttraining's binary_logloss: 0.0972053\tvalid_1's binary_logloss: 0.234606\n",
            "[2500]\ttraining's binary_logloss: 0.0959924\tvalid_1's binary_logloss: 0.235623\n",
            "[2550]\ttraining's binary_logloss: 0.0945403\tvalid_1's binary_logloss: 0.235558\n",
            "[2600]\ttraining's binary_logloss: 0.0932144\tvalid_1's binary_logloss: 0.237453\n",
            "[2650]\ttraining's binary_logloss: 0.0917713\tvalid_1's binary_logloss: 0.2386\n",
            "[2700]\ttraining's binary_logloss: 0.089949\tvalid_1's binary_logloss: 0.238471\n",
            "[2750]\ttraining's binary_logloss: 0.0892668\tvalid_1's binary_logloss: 0.239236\n",
            "[2800]\ttraining's binary_logloss: 0.0881677\tvalid_1's binary_logloss: 0.23911\n",
            "[2850]\ttraining's binary_logloss: 0.0858468\tvalid_1's binary_logloss: 0.239339\n",
            "[2900]\ttraining's binary_logloss: 0.0850297\tvalid_1's binary_logloss: 0.238919\n",
            "[2950]\ttraining's binary_logloss: 0.0828047\tvalid_1's binary_logloss: 0.239805\n",
            "[3000]\ttraining's binary_logloss: 0.081627\tvalid_1's binary_logloss: 0.239306\n",
            "[3050]\ttraining's binary_logloss: 0.0804998\tvalid_1's binary_logloss: 0.238975\n",
            "[3100]\ttraining's binary_logloss: 0.0793701\tvalid_1's binary_logloss: 0.238939\n",
            "[3150]\ttraining's binary_logloss: 0.0784919\tvalid_1's binary_logloss: 0.239726\n",
            "[3200]\ttraining's binary_logloss: 0.0770016\tvalid_1's binary_logloss: 0.239665\n",
            "[3250]\ttraining's binary_logloss: 0.0759238\tvalid_1's binary_logloss: 0.239312\n",
            "[3300]\ttraining's binary_logloss: 0.0748346\tvalid_1's binary_logloss: 0.239141\n",
            "[3350]\ttraining's binary_logloss: 0.0734241\tvalid_1's binary_logloss: 0.239708\n",
            "[3400]\ttraining's binary_logloss: 0.071857\tvalid_1's binary_logloss: 0.241201\n",
            "[3450]\ttraining's binary_logloss: 0.0705035\tvalid_1's binary_logloss: 0.240431\n",
            "[3500]\ttraining's binary_logloss: 0.0699094\tvalid_1's binary_logloss: 0.242155\n",
            "[3550]\ttraining's binary_logloss: 0.0689629\tvalid_1's binary_logloss: 0.24122\n",
            "[3600]\ttraining's binary_logloss: 0.0682951\tvalid_1's binary_logloss: 0.240379\n",
            "[3650]\ttraining's binary_logloss: 0.0673213\tvalid_1's binary_logloss: 0.24274\n",
            "[3700]\ttraining's binary_logloss: 0.0652668\tvalid_1's binary_logloss: 0.243517\n",
            "[3750]\ttraining's binary_logloss: 0.064399\tvalid_1's binary_logloss: 0.244163\n",
            "[3800]\ttraining's binary_logloss: 0.0638485\tvalid_1's binary_logloss: 0.243591\n",
            "[3850]\ttraining's binary_logloss: 0.0629206\tvalid_1's binary_logloss: 0.243726\n",
            "[3900]\ttraining's binary_logloss: 0.0624347\tvalid_1's binary_logloss: 0.243003\n",
            "[3950]\ttraining's binary_logloss: 0.0623873\tvalid_1's binary_logloss: 0.242965\n",
            "[4000]\ttraining's binary_logloss: 0.0611884\tvalid_1's binary_logloss: 0.24352\n",
            "[4050]\ttraining's binary_logloss: 0.0605424\tvalid_1's binary_logloss: 0.243295\n",
            "[4100]\ttraining's binary_logloss: 0.0596186\tvalid_1's binary_logloss: 0.243653\n",
            "[4150]\ttraining's binary_logloss: 0.058241\tvalid_1's binary_logloss: 0.244055\n",
            "[4200]\ttraining's binary_logloss: 0.0575395\tvalid_1's binary_logloss: 0.243487\n",
            "[4250]\ttraining's binary_logloss: 0.0566901\tvalid_1's binary_logloss: 0.243428\n",
            "[4300]\ttraining's binary_logloss: 0.0556561\tvalid_1's binary_logloss: 0.24339\n",
            "[4350]\ttraining's binary_logloss: 0.0553829\tvalid_1's binary_logloss: 0.244548\n",
            "[4400]\ttraining's binary_logloss: 0.0548836\tvalid_1's binary_logloss: 0.245601\n",
            "[4450]\ttraining's binary_logloss: 0.0539169\tvalid_1's binary_logloss: 0.246422\n",
            "[4500]\ttraining's binary_logloss: 0.0535342\tvalid_1's binary_logloss: 0.246346\n",
            " - 0 round - train_metric: 0.677105 - valid_metric: 0.675744\n",
            "\n",
            " - 50 round - train_metric: 0.456213 - valid_metric: 0.446369\n",
            "\n",
            " - 100 round - train_metric: 0.396575 - valid_metric: 0.387478\n",
            "\n",
            " - 150 round - train_metric: 0.377622 - valid_metric: 0.370795\n",
            "\n",
            " - 200 round - train_metric: 0.364462 - valid_metric: 0.357021\n",
            "\n",
            " - 250 round - train_metric: 0.331104 - valid_metric: 0.323556\n",
            "\n",
            " - 300 round - train_metric: 0.313509 - valid_metric: 0.306451\n",
            "\n",
            " - 350 round - train_metric: 0.300858 - valid_metric: 0.297730\n",
            "\n",
            " - 400 round - train_metric: 0.293607 - valid_metric: 0.293203\n",
            "\n",
            " - 450 round - train_metric: 0.288204 - valid_metric: 0.287868\n",
            "\n",
            " - 500 round - train_metric: 0.265961 - valid_metric: 0.267919\n",
            "\n",
            " - 550 round - train_metric: 0.256878 - valid_metric: 0.261540\n",
            "\n",
            " - 600 round - train_metric: 0.250432 - valid_metric: 0.258462\n",
            "\n",
            " - 650 round - train_metric: 0.236630 - valid_metric: 0.252431\n",
            "\n",
            " - 700 round - train_metric: 0.225448 - valid_metric: 0.250159\n",
            "\n",
            " - 750 round - train_metric: 0.214377 - valid_metric: 0.244850\n",
            "\n",
            " - 800 round - train_metric: 0.206955 - valid_metric: 0.242398\n",
            "\n",
            " - 850 round - train_metric: 0.194965 - valid_metric: 0.240349\n",
            "\n",
            " - 900 round - train_metric: 0.188779 - valid_metric: 0.238902\n",
            "\n",
            " - 950 round - train_metric: 0.187516 - valid_metric: 0.241015\n",
            "\n",
            " - 1000 round - train_metric: 0.180559 - valid_metric: 0.239961\n",
            "\n",
            " - 1050 round - train_metric: 0.175753 - valid_metric: 0.238982\n",
            "\n",
            " - 1100 round - train_metric: 0.165622 - valid_metric: 0.236599\n",
            "\n",
            " - 1150 round - train_metric: 0.164738 - valid_metric: 0.238934\n",
            "\n",
            " - 1200 round - train_metric: 0.160206 - valid_metric: 0.239424\n",
            "\n",
            " - 1250 round - train_metric: 0.156345 - valid_metric: 0.239278\n",
            "\n",
            " - 1300 round - train_metric: 0.153897 - valid_metric: 0.235400\n",
            "\n",
            " - 1350 round - train_metric: 0.152150 - valid_metric: 0.235037\n",
            "\n",
            " - 1400 round - train_metric: 0.145501 - valid_metric: 0.234963\n",
            "\n",
            " - 1450 round - train_metric: 0.143769 - valid_metric: 0.235670\n",
            "\n",
            " - 1500 round - train_metric: 0.141263 - valid_metric: 0.236028\n",
            "\n",
            " - 1550 round - train_metric: 0.135034 - valid_metric: 0.233242\n",
            "\n",
            " - 1600 round - train_metric: 0.130798 - valid_metric: 0.233974\n",
            "\n",
            " - 1650 round - train_metric: 0.127339 - valid_metric: 0.233319\n",
            "\n",
            " - 1700 round - train_metric: 0.125433 - valid_metric: 0.234762\n",
            "\n",
            " - 1750 round - train_metric: 0.123686 - valid_metric: 0.235081\n",
            "\n",
            " - 1800 round - train_metric: 0.122486 - valid_metric: 0.235049\n",
            "\n",
            " - 1850 round - train_metric: 0.120352 - valid_metric: 0.233216\n",
            "\n",
            " - 1900 round - train_metric: 0.117823 - valid_metric: 0.233378\n",
            "\n",
            " - 1950 round - train_metric: 0.114861 - valid_metric: 0.234842\n",
            "\n",
            " - 2000 round - train_metric: 0.112437 - valid_metric: 0.235034\n",
            "\n",
            " - 2050 round - train_metric: 0.110909 - valid_metric: 0.232977\n",
            "\n",
            " - 2100 round - train_metric: 0.109260 - valid_metric: 0.231079\n",
            "\n",
            " - 2150 round - train_metric: 0.109054 - valid_metric: 0.232495\n",
            "\n",
            " - 2200 round - train_metric: 0.106426 - valid_metric: 0.233379\n",
            "\n",
            " - 2250 round - train_metric: 0.104150 - valid_metric: 0.233794\n",
            "\n",
            " - 2300 round - train_metric: 0.101776 - valid_metric: 0.232923\n",
            "\n",
            " - 2350 round - train_metric: 0.100310 - valid_metric: 0.233696\n",
            "\n",
            " - 2400 round - train_metric: 0.098951 - valid_metric: 0.233083\n",
            "\n",
            " - 2450 round - train_metric: 0.097019 - valid_metric: 0.234731\n",
            "\n",
            " - 2500 round - train_metric: 0.096036 - valid_metric: 0.235634\n",
            "\n",
            " - 2550 round - train_metric: 0.094390 - valid_metric: 0.235699\n",
            "\n",
            " - 2600 round - train_metric: 0.093250 - valid_metric: 0.237483\n",
            "\n",
            " - 2650 round - train_metric: 0.091808 - valid_metric: 0.238628\n",
            "\n",
            " - 2700 round - train_metric: 0.090002 - valid_metric: 0.238499\n",
            "\n",
            " - 2750 round - train_metric: 0.089312 - valid_metric: 0.239268\n",
            "\n",
            " - 2800 round - train_metric: 0.088030 - valid_metric: 0.239190\n",
            "\n",
            " - 2850 round - train_metric: 0.085888 - valid_metric: 0.239362\n",
            "\n",
            " - 2900 round - train_metric: 0.085088 - valid_metric: 0.238912\n",
            "\n",
            " - 2950 round - train_metric: 0.082846 - valid_metric: 0.239820\n",
            "\n",
            " - 3000 round - train_metric: 0.081665 - valid_metric: 0.239316\n",
            "\n",
            " - 3050 round - train_metric: 0.080378 - valid_metric: 0.239022\n",
            "\n",
            " - 3100 round - train_metric: 0.079402 - valid_metric: 0.238956\n",
            "\n",
            " - 3150 round - train_metric: 0.078533 - valid_metric: 0.239729\n",
            "\n",
            " - 3200 round - train_metric: 0.076948 - valid_metric: 0.239374\n",
            "\n",
            " - 3250 round - train_metric: 0.075951 - valid_metric: 0.239337\n",
            "\n",
            " - 3300 round - train_metric: 0.074869 - valid_metric: 0.239164\n",
            "\n",
            " - 3350 round - train_metric: 0.073458 - valid_metric: 0.239719\n",
            "\n",
            " - 3400 round - train_metric: 0.071891 - valid_metric: 0.241222\n",
            "\n",
            " - 3450 round - train_metric: 0.070429 - valid_metric: 0.240378\n",
            "\n",
            " - 3500 round - train_metric: 0.069831 - valid_metric: 0.242179\n",
            "\n",
            " - 3550 round - train_metric: 0.068990 - valid_metric: 0.241227\n",
            "\n",
            " - 3600 round - train_metric: 0.068327 - valid_metric: 0.240395\n",
            "\n",
            " - 3650 round - train_metric: 0.067365 - valid_metric: 0.242730\n",
            "\n",
            " - 3700 round - train_metric: 0.065208 - valid_metric: 0.243594\n",
            "\n",
            " - 3750 round - train_metric: 0.064354 - valid_metric: 0.244073\n",
            "\n",
            " - 3800 round - train_metric: 0.063773 - valid_metric: 0.243449\n",
            "\n",
            " - 3850 round - train_metric: 0.062874 - valid_metric: 0.243568\n",
            "\n",
            " - 3900 round - train_metric: 0.062455 - valid_metric: 0.242995\n",
            "\n",
            " - 3950 round - train_metric: 0.062318 - valid_metric: 0.242977\n",
            "\n",
            " - 4000 round - train_metric: 0.061144 - valid_metric: 0.243687\n",
            "\n",
            " - 4050 round - train_metric: 0.060568 - valid_metric: 0.243303\n",
            "\n",
            " - 4100 round - train_metric: 0.059650 - valid_metric: 0.243675\n",
            "\n",
            " - 4150 round - train_metric: 0.058270 - valid_metric: 0.244061\n",
            "\n",
            " - 4200 round - train_metric: 0.057565 - valid_metric: 0.243471\n",
            "\n",
            " - 4250 round - train_metric: 0.056712 - valid_metric: 0.243434\n",
            "\n",
            " - 4300 round - train_metric: 0.055687 - valid_metric: 0.243385\n",
            "\n",
            " - 4350 round - train_metric: 0.055343 - valid_metric: 0.244517\n",
            "\n",
            " - 4400 round - train_metric: 0.054836 - valid_metric: 0.245613\n",
            "\n",
            " - 4450 round - train_metric: 0.053936 - valid_metric: 0.246422\n",
            "\n",
            "- fold1 valid metric: 0.762176\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.439999\tvalid_1's binary_logloss: 0.468452\n",
            "[100]\ttraining's binary_logloss: 0.38178\tvalid_1's binary_logloss: 0.425236\n",
            "[150]\ttraining's binary_logloss: 0.35519\tvalid_1's binary_logloss: 0.406653\n",
            "[200]\ttraining's binary_logloss: 0.341818\tvalid_1's binary_logloss: 0.400619\n",
            "[250]\ttraining's binary_logloss: 0.310538\tvalid_1's binary_logloss: 0.384637\n",
            "[300]\ttraining's binary_logloss: 0.292513\tvalid_1's binary_logloss: 0.378109\n",
            "[350]\ttraining's binary_logloss: 0.277982\tvalid_1's binary_logloss: 0.371224\n",
            "[400]\ttraining's binary_logloss: 0.272433\tvalid_1's binary_logloss: 0.369936\n",
            "[450]\ttraining's binary_logloss: 0.269293\tvalid_1's binary_logloss: 0.365396\n",
            "[500]\ttraining's binary_logloss: 0.249821\tvalid_1's binary_logloss: 0.360089\n",
            "[550]\ttraining's binary_logloss: 0.241193\tvalid_1's binary_logloss: 0.357649\n",
            "[600]\ttraining's binary_logloss: 0.235067\tvalid_1's binary_logloss: 0.355366\n",
            "[650]\ttraining's binary_logloss: 0.221823\tvalid_1's binary_logloss: 0.354551\n",
            "[700]\ttraining's binary_logloss: 0.21205\tvalid_1's binary_logloss: 0.348686\n",
            "[750]\ttraining's binary_logloss: 0.200001\tvalid_1's binary_logloss: 0.348953\n",
            "[800]\ttraining's binary_logloss: 0.191627\tvalid_1's binary_logloss: 0.348339\n",
            "[850]\ttraining's binary_logloss: 0.181116\tvalid_1's binary_logloss: 0.351079\n",
            "[900]\ttraining's binary_logloss: 0.17486\tvalid_1's binary_logloss: 0.352149\n",
            "[950]\ttraining's binary_logloss: 0.173023\tvalid_1's binary_logloss: 0.354373\n",
            "[1000]\ttraining's binary_logloss: 0.166667\tvalid_1's binary_logloss: 0.353265\n",
            "[1050]\ttraining's binary_logloss: 0.161669\tvalid_1's binary_logloss: 0.353799\n",
            "[1100]\ttraining's binary_logloss: 0.152657\tvalid_1's binary_logloss: 0.357107\n",
            "[1150]\ttraining's binary_logloss: 0.15131\tvalid_1's binary_logloss: 0.356072\n",
            "[1200]\ttraining's binary_logloss: 0.147677\tvalid_1's binary_logloss: 0.356171\n",
            "[1250]\ttraining's binary_logloss: 0.14368\tvalid_1's binary_logloss: 0.357531\n",
            "[1300]\ttraining's binary_logloss: 0.141055\tvalid_1's binary_logloss: 0.357054\n",
            "[1350]\ttraining's binary_logloss: 0.13881\tvalid_1's binary_logloss: 0.357674\n",
            "[1400]\ttraining's binary_logloss: 0.133467\tvalid_1's binary_logloss: 0.360215\n",
            "[1450]\ttraining's binary_logloss: 0.131031\tvalid_1's binary_logloss: 0.360851\n",
            "[1500]\ttraining's binary_logloss: 0.129368\tvalid_1's binary_logloss: 0.360935\n",
            "[1550]\ttraining's binary_logloss: 0.123758\tvalid_1's binary_logloss: 0.362957\n",
            "[1600]\ttraining's binary_logloss: 0.119639\tvalid_1's binary_logloss: 0.365502\n",
            "[1650]\ttraining's binary_logloss: 0.116295\tvalid_1's binary_logloss: 0.365737\n",
            "[1700]\ttraining's binary_logloss: 0.114222\tvalid_1's binary_logloss: 0.365159\n",
            "[1750]\ttraining's binary_logloss: 0.11211\tvalid_1's binary_logloss: 0.36611\n",
            "[1800]\ttraining's binary_logloss: 0.110892\tvalid_1's binary_logloss: 0.36529\n",
            "[1850]\ttraining's binary_logloss: 0.108848\tvalid_1's binary_logloss: 0.366324\n",
            "[1900]\ttraining's binary_logloss: 0.106813\tvalid_1's binary_logloss: 0.364449\n",
            "[1950]\ttraining's binary_logloss: 0.103969\tvalid_1's binary_logloss: 0.365889\n",
            "[2000]\ttraining's binary_logloss: 0.101829\tvalid_1's binary_logloss: 0.366068\n",
            "[2050]\ttraining's binary_logloss: 0.100276\tvalid_1's binary_logloss: 0.367468\n",
            "[2100]\ttraining's binary_logloss: 0.0985134\tvalid_1's binary_logloss: 0.368774\n",
            "[2150]\ttraining's binary_logloss: 0.0981814\tvalid_1's binary_logloss: 0.368978\n",
            "[2200]\ttraining's binary_logloss: 0.0954799\tvalid_1's binary_logloss: 0.370757\n",
            "[2250]\ttraining's binary_logloss: 0.0939584\tvalid_1's binary_logloss: 0.371427\n",
            "[2300]\ttraining's binary_logloss: 0.0920958\tvalid_1's binary_logloss: 0.371483\n",
            "[2350]\ttraining's binary_logloss: 0.0906006\tvalid_1's binary_logloss: 0.372188\n",
            "[2400]\ttraining's binary_logloss: 0.0893929\tvalid_1's binary_logloss: 0.372705\n",
            "[2450]\ttraining's binary_logloss: 0.0873677\tvalid_1's binary_logloss: 0.370697\n",
            "[2500]\ttraining's binary_logloss: 0.0867045\tvalid_1's binary_logloss: 0.370599\n",
            "[2550]\ttraining's binary_logloss: 0.0849945\tvalid_1's binary_logloss: 0.370779\n",
            "[2600]\ttraining's binary_logloss: 0.0838537\tvalid_1's binary_logloss: 0.371437\n",
            "[2650]\ttraining's binary_logloss: 0.0825227\tvalid_1's binary_logloss: 0.373326\n",
            "[2700]\ttraining's binary_logloss: 0.0809067\tvalid_1's binary_logloss: 0.374845\n",
            "[2750]\ttraining's binary_logloss: 0.0807102\tvalid_1's binary_logloss: 0.373133\n",
            "[2800]\ttraining's binary_logloss: 0.0796842\tvalid_1's binary_logloss: 0.374549\n",
            "[2850]\ttraining's binary_logloss: 0.0777206\tvalid_1's binary_logloss: 0.375894\n",
            "[2900]\ttraining's binary_logloss: 0.0766092\tvalid_1's binary_logloss: 0.376643\n",
            "[2950]\ttraining's binary_logloss: 0.0750045\tvalid_1's binary_logloss: 0.378965\n",
            "[3000]\ttraining's binary_logloss: 0.0734415\tvalid_1's binary_logloss: 0.378953\n",
            "[3050]\ttraining's binary_logloss: 0.0724057\tvalid_1's binary_logloss: 0.380641\n",
            "[3100]\ttraining's binary_logloss: 0.0713098\tvalid_1's binary_logloss: 0.381846\n",
            "[3150]\ttraining's binary_logloss: 0.0705332\tvalid_1's binary_logloss: 0.382052\n",
            "[3200]\ttraining's binary_logloss: 0.0693115\tvalid_1's binary_logloss: 0.385095\n",
            "[3250]\ttraining's binary_logloss: 0.0684022\tvalid_1's binary_logloss: 0.385175\n",
            "[3300]\ttraining's binary_logloss: 0.0675921\tvalid_1's binary_logloss: 0.384587\n",
            "[3350]\ttraining's binary_logloss: 0.0661571\tvalid_1's binary_logloss: 0.38497\n",
            "[3400]\ttraining's binary_logloss: 0.0649481\tvalid_1's binary_logloss: 0.386607\n",
            "[3450]\ttraining's binary_logloss: 0.0638028\tvalid_1's binary_logloss: 0.3892\n",
            "[3500]\ttraining's binary_logloss: 0.063171\tvalid_1's binary_logloss: 0.38809\n",
            "[3550]\ttraining's binary_logloss: 0.0623737\tvalid_1's binary_logloss: 0.388771\n",
            "[3600]\ttraining's binary_logloss: 0.0615409\tvalid_1's binary_logloss: 0.387863\n",
            "[3650]\ttraining's binary_logloss: 0.0608593\tvalid_1's binary_logloss: 0.390426\n",
            "[3700]\ttraining's binary_logloss: 0.0590982\tvalid_1's binary_logloss: 0.392728\n",
            "[3750]\ttraining's binary_logloss: 0.0583402\tvalid_1's binary_logloss: 0.395388\n",
            "[3800]\ttraining's binary_logloss: 0.05776\tvalid_1's binary_logloss: 0.39582\n",
            "[3850]\ttraining's binary_logloss: 0.0569846\tvalid_1's binary_logloss: 0.396387\n",
            "[3900]\ttraining's binary_logloss: 0.0564922\tvalid_1's binary_logloss: 0.395166\n",
            "[3950]\ttraining's binary_logloss: 0.0565362\tvalid_1's binary_logloss: 0.394975\n",
            "[4000]\ttraining's binary_logloss: 0.0555513\tvalid_1's binary_logloss: 0.395375\n",
            "[4050]\ttraining's binary_logloss: 0.0550203\tvalid_1's binary_logloss: 0.394628\n",
            "[4100]\ttraining's binary_logloss: 0.054288\tvalid_1's binary_logloss: 0.394123\n",
            "[4150]\ttraining's binary_logloss: 0.0531384\tvalid_1's binary_logloss: 0.396775\n",
            "[4200]\ttraining's binary_logloss: 0.0525339\tvalid_1's binary_logloss: 0.397383\n",
            "[4250]\ttraining's binary_logloss: 0.0517773\tvalid_1's binary_logloss: 0.397853\n",
            "[4300]\ttraining's binary_logloss: 0.0505913\tvalid_1's binary_logloss: 0.398474\n",
            "[4350]\ttraining's binary_logloss: 0.0505066\tvalid_1's binary_logloss: 0.398694\n",
            "[4400]\ttraining's binary_logloss: 0.0501315\tvalid_1's binary_logloss: 0.399612\n",
            "[4450]\ttraining's binary_logloss: 0.049307\tvalid_1's binary_logloss: 0.399203\n",
            "[4500]\ttraining's binary_logloss: 0.0488376\tvalid_1's binary_logloss: 0.400462\n",
            " - 0 round - train_metric: 0.675887 - valid_metric: 0.679699\n",
            "\n",
            " - 50 round - train_metric: 0.442221 - valid_metric: 0.470422\n",
            "\n",
            " - 100 round - train_metric: 0.377546 - valid_metric: 0.423689\n",
            "\n",
            " - 150 round - train_metric: 0.357176 - valid_metric: 0.407976\n",
            "\n",
            " - 200 round - train_metric: 0.343125 - valid_metric: 0.401343\n",
            "\n",
            " - 250 round - train_metric: 0.308638 - valid_metric: 0.383761\n",
            "\n",
            " - 300 round - train_metric: 0.290742 - valid_metric: 0.378329\n",
            "\n",
            " - 350 round - train_metric: 0.278720 - valid_metric: 0.371543\n",
            "\n",
            " - 400 round - train_metric: 0.273030 - valid_metric: 0.370078\n",
            "\n",
            " - 450 round - train_metric: 0.269835 - valid_metric: 0.365615\n",
            "\n",
            " - 500 round - train_metric: 0.248822 - valid_metric: 0.360409\n",
            "\n",
            " - 550 round - train_metric: 0.240419 - valid_metric: 0.358107\n",
            "\n",
            " - 600 round - train_metric: 0.234111 - valid_metric: 0.355481\n",
            "\n",
            " - 650 round - train_metric: 0.222100 - valid_metric: 0.354515\n",
            "\n",
            " - 700 round - train_metric: 0.212339 - valid_metric: 0.348687\n",
            "\n",
            " - 750 round - train_metric: 0.200293 - valid_metric: 0.348888\n",
            "\n",
            " - 800 round - train_metric: 0.191825 - valid_metric: 0.348246\n",
            "\n",
            " - 850 round - train_metric: 0.180549 - valid_metric: 0.351179\n",
            "\n",
            " - 900 round - train_metric: 0.174539 - valid_metric: 0.351674\n",
            "\n",
            " - 950 round - train_metric: 0.172720 - valid_metric: 0.353950\n",
            "\n",
            " - 1000 round - train_metric: 0.166848 - valid_metric: 0.353256\n",
            "\n",
            " - 1050 round - train_metric: 0.161429 - valid_metric: 0.353400\n",
            "\n",
            " - 1100 round - train_metric: 0.152316 - valid_metric: 0.357171\n",
            "\n",
            " - 1150 round - train_metric: 0.151438 - valid_metric: 0.355991\n",
            "\n",
            " - 1200 round - train_metric: 0.147807 - valid_metric: 0.356126\n",
            "\n",
            " - 1250 round - train_metric: 0.143797 - valid_metric: 0.357453\n",
            "\n",
            " - 1300 round - train_metric: 0.141171 - valid_metric: 0.356990\n",
            "\n",
            " - 1350 round - train_metric: 0.138949 - valid_metric: 0.357608\n",
            "\n",
            " - 1400 round - train_metric: 0.133240 - valid_metric: 0.359918\n",
            "\n",
            " - 1450 round - train_metric: 0.131147 - valid_metric: 0.360745\n",
            "\n",
            " - 1500 round - train_metric: 0.129099 - valid_metric: 0.361056\n",
            "\n",
            " - 1550 round - train_metric: 0.123536 - valid_metric: 0.363160\n",
            "\n",
            " - 1600 round - train_metric: 0.119754 - valid_metric: 0.365438\n",
            "\n",
            " - 1650 round - train_metric: 0.115959 - valid_metric: 0.366088\n",
            "\n",
            " - 1700 round - train_metric: 0.113997 - valid_metric: 0.365302\n",
            "\n",
            " - 1750 round - train_metric: 0.112196 - valid_metric: 0.366041\n",
            "\n",
            " - 1800 round - train_metric: 0.110712 - valid_metric: 0.365654\n",
            "\n",
            " - 1850 round - train_metric: 0.108957 - valid_metric: 0.366253\n",
            "\n",
            " - 1900 round - train_metric: 0.106662 - valid_metric: 0.364529\n",
            "\n",
            " - 1950 round - train_metric: 0.104048 - valid_metric: 0.365820\n",
            "\n",
            " - 2000 round - train_metric: 0.101649 - valid_metric: 0.366095\n",
            "\n",
            " - 2050 round - train_metric: 0.100343 - valid_metric: 0.367402\n",
            "\n",
            " - 2100 round - train_metric: 0.098567 - valid_metric: 0.368709\n",
            "\n",
            " - 2150 round - train_metric: 0.098263 - valid_metric: 0.368906\n",
            "\n",
            " - 2200 round - train_metric: 0.095555 - valid_metric: 0.370649\n",
            "\n",
            " - 2250 round - train_metric: 0.093886 - valid_metric: 0.371698\n",
            "\n",
            " - 2300 round - train_metric: 0.092167 - valid_metric: 0.371437\n",
            "\n",
            " - 2350 round - train_metric: 0.090678 - valid_metric: 0.372090\n",
            "\n",
            " - 2400 round - train_metric: 0.089225 - valid_metric: 0.372912\n",
            "\n",
            " - 2450 round - train_metric: 0.087241 - valid_metric: 0.370588\n",
            "\n",
            " - 2500 round - train_metric: 0.086742 - valid_metric: 0.370545\n",
            "\n",
            " - 2550 round - train_metric: 0.084907 - valid_metric: 0.370650\n",
            "\n",
            " - 2600 round - train_metric: 0.083887 - valid_metric: 0.371386\n",
            "\n",
            " - 2650 round - train_metric: 0.082556 - valid_metric: 0.373283\n",
            "\n",
            " - 2700 round - train_metric: 0.080958 - valid_metric: 0.374756\n",
            "\n",
            " - 2750 round - train_metric: 0.080753 - valid_metric: 0.373061\n",
            "\n",
            " - 2800 round - train_metric: 0.079588 - valid_metric: 0.374562\n",
            "\n",
            " - 2850 round - train_metric: 0.077758 - valid_metric: 0.375826\n",
            "\n",
            " - 2900 round - train_metric: 0.076665 - valid_metric: 0.376607\n",
            "\n",
            " - 2950 round - train_metric: 0.075045 - valid_metric: 0.378886\n",
            "\n",
            " - 3000 round - train_metric: 0.073480 - valid_metric: 0.378892\n",
            "\n",
            " - 3050 round - train_metric: 0.072325 - valid_metric: 0.380793\n",
            "\n",
            " - 3100 round - train_metric: 0.071338 - valid_metric: 0.381787\n",
            "\n",
            " - 3150 round - train_metric: 0.070572 - valid_metric: 0.381988\n",
            "\n",
            " - 3200 round - train_metric: 0.069249 - valid_metric: 0.385243\n",
            "\n",
            " - 3250 round - train_metric: 0.068427 - valid_metric: 0.385114\n",
            "\n",
            " - 3300 round - train_metric: 0.067625 - valid_metric: 0.384534\n",
            "\n",
            " - 3350 round - train_metric: 0.066187 - valid_metric: 0.384926\n",
            "\n",
            " - 3400 round - train_metric: 0.064980 - valid_metric: 0.386546\n",
            "\n",
            " - 3450 round - train_metric: 0.063754 - valid_metric: 0.389173\n",
            "\n",
            " - 3500 round - train_metric: 0.063090 - valid_metric: 0.388349\n",
            "\n",
            " - 3550 round - train_metric: 0.062396 - valid_metric: 0.388725\n",
            "\n",
            " - 3600 round - train_metric: 0.061570 - valid_metric: 0.387820\n",
            "\n",
            " - 3650 round - train_metric: 0.060898 - valid_metric: 0.390336\n",
            "\n",
            " - 3700 round - train_metric: 0.059048 - valid_metric: 0.393252\n",
            "\n",
            " - 3750 round - train_metric: 0.058286 - valid_metric: 0.395158\n",
            "\n",
            " - 3800 round - train_metric: 0.057664 - valid_metric: 0.396082\n",
            "\n",
            " - 3850 round - train_metric: 0.056931 - valid_metric: 0.396943\n",
            "\n",
            " - 3900 round - train_metric: 0.056509 - valid_metric: 0.395120\n",
            "\n",
            " - 3950 round - train_metric: 0.056466 - valid_metric: 0.394816\n",
            "\n",
            " - 4000 round - train_metric: 0.055478 - valid_metric: 0.395323\n",
            "\n",
            " - 4050 round - train_metric: 0.055044 - valid_metric: 0.394562\n",
            "\n",
            " - 4100 round - train_metric: 0.054321 - valid_metric: 0.394041\n",
            "\n",
            " - 4150 round - train_metric: 0.053168 - valid_metric: 0.396705\n",
            "\n",
            " - 4200 round - train_metric: 0.052557 - valid_metric: 0.397329\n",
            "\n",
            " - 4250 round - train_metric: 0.051802 - valid_metric: 0.397806\n",
            "\n",
            " - 4300 round - train_metric: 0.050621 - valid_metric: 0.398417\n",
            "\n",
            " - 4350 round - train_metric: 0.050455 - valid_metric: 0.398950\n",
            "\n",
            " - 4400 round - train_metric: 0.050091 - valid_metric: 0.399513\n",
            "\n",
            " - 4450 round - train_metric: 0.049324 - valid_metric: 0.399169\n",
            "\n",
            "- fold2 valid metric: 0.528670\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.449902\tvalid_1's binary_logloss: 0.454394\n",
            "[100]\ttraining's binary_logloss: 0.395888\tvalid_1's binary_logloss: 0.401737\n",
            "[150]\ttraining's binary_logloss: 0.371476\tvalid_1's binary_logloss: 0.380454\n",
            "[200]\ttraining's binary_logloss: 0.358928\tvalid_1's binary_logloss: 0.36554\n",
            "[250]\ttraining's binary_logloss: 0.329689\tvalid_1's binary_logloss: 0.343298\n",
            "[300]\ttraining's binary_logloss: 0.312343\tvalid_1's binary_logloss: 0.325751\n",
            "[350]\ttraining's binary_logloss: 0.296228\tvalid_1's binary_logloss: 0.316802\n",
            "[400]\ttraining's binary_logloss: 0.290294\tvalid_1's binary_logloss: 0.310071\n",
            "[450]\ttraining's binary_logloss: 0.284507\tvalid_1's binary_logloss: 0.308658\n",
            "[500]\ttraining's binary_logloss: 0.262561\tvalid_1's binary_logloss: 0.295839\n",
            "[550]\ttraining's binary_logloss: 0.254444\tvalid_1's binary_logloss: 0.296245\n",
            "[600]\ttraining's binary_logloss: 0.246971\tvalid_1's binary_logloss: 0.294099\n",
            "[650]\ttraining's binary_logloss: 0.23154\tvalid_1's binary_logloss: 0.289733\n",
            "[700]\ttraining's binary_logloss: 0.221558\tvalid_1's binary_logloss: 0.288626\n",
            "[750]\ttraining's binary_logloss: 0.210142\tvalid_1's binary_logloss: 0.285404\n",
            "[800]\ttraining's binary_logloss: 0.202271\tvalid_1's binary_logloss: 0.286039\n",
            "[850]\ttraining's binary_logloss: 0.191513\tvalid_1's binary_logloss: 0.284136\n",
            "[900]\ttraining's binary_logloss: 0.186017\tvalid_1's binary_logloss: 0.286497\n",
            "[950]\ttraining's binary_logloss: 0.184611\tvalid_1's binary_logloss: 0.287335\n",
            "[1000]\ttraining's binary_logloss: 0.178742\tvalid_1's binary_logloss: 0.28602\n",
            "[1050]\ttraining's binary_logloss: 0.172945\tvalid_1's binary_logloss: 0.287375\n",
            "[1100]\ttraining's binary_logloss: 0.162827\tvalid_1's binary_logloss: 0.289691\n",
            "[1150]\ttraining's binary_logloss: 0.161807\tvalid_1's binary_logloss: 0.292875\n",
            "[1200]\ttraining's binary_logloss: 0.157014\tvalid_1's binary_logloss: 0.295612\n",
            "[1250]\ttraining's binary_logloss: 0.1534\tvalid_1's binary_logloss: 0.292908\n",
            "[1300]\ttraining's binary_logloss: 0.150943\tvalid_1's binary_logloss: 0.294151\n",
            "[1350]\ttraining's binary_logloss: 0.148256\tvalid_1's binary_logloss: 0.294356\n",
            "[1400]\ttraining's binary_logloss: 0.142208\tvalid_1's binary_logloss: 0.29566\n",
            "[1450]\ttraining's binary_logloss: 0.139864\tvalid_1's binary_logloss: 0.297588\n",
            "[1500]\ttraining's binary_logloss: 0.137203\tvalid_1's binary_logloss: 0.29914\n",
            "[1550]\ttraining's binary_logloss: 0.130814\tvalid_1's binary_logloss: 0.300323\n",
            "[1600]\ttraining's binary_logloss: 0.126082\tvalid_1's binary_logloss: 0.303054\n",
            "[1650]\ttraining's binary_logloss: 0.122198\tvalid_1's binary_logloss: 0.30421\n",
            "[1700]\ttraining's binary_logloss: 0.120252\tvalid_1's binary_logloss: 0.305701\n",
            "[1750]\ttraining's binary_logloss: 0.118247\tvalid_1's binary_logloss: 0.307272\n",
            "[1800]\ttraining's binary_logloss: 0.117479\tvalid_1's binary_logloss: 0.306852\n",
            "[1850]\ttraining's binary_logloss: 0.114848\tvalid_1's binary_logloss: 0.305862\n",
            "[1900]\ttraining's binary_logloss: 0.112773\tvalid_1's binary_logloss: 0.305406\n",
            "[1950]\ttraining's binary_logloss: 0.109241\tvalid_1's binary_logloss: 0.307612\n",
            "[2000]\ttraining's binary_logloss: 0.107015\tvalid_1's binary_logloss: 0.308071\n",
            "[2050]\ttraining's binary_logloss: 0.105323\tvalid_1's binary_logloss: 0.309232\n",
            "[2100]\ttraining's binary_logloss: 0.103646\tvalid_1's binary_logloss: 0.307972\n",
            "[2150]\ttraining's binary_logloss: 0.103502\tvalid_1's binary_logloss: 0.308108\n",
            "[2200]\ttraining's binary_logloss: 0.100882\tvalid_1's binary_logloss: 0.307582\n",
            "[2250]\ttraining's binary_logloss: 0.0993336\tvalid_1's binary_logloss: 0.307845\n",
            "[2300]\ttraining's binary_logloss: 0.0966206\tvalid_1's binary_logloss: 0.312024\n",
            "[2350]\ttraining's binary_logloss: 0.0955806\tvalid_1's binary_logloss: 0.311768\n",
            "[2400]\ttraining's binary_logloss: 0.0941201\tvalid_1's binary_logloss: 0.312783\n",
            "[2450]\ttraining's binary_logloss: 0.0924292\tvalid_1's binary_logloss: 0.314011\n",
            "[2500]\ttraining's binary_logloss: 0.0913881\tvalid_1's binary_logloss: 0.31612\n",
            "[2550]\ttraining's binary_logloss: 0.0899785\tvalid_1's binary_logloss: 0.316375\n",
            "[2600]\ttraining's binary_logloss: 0.0885033\tvalid_1's binary_logloss: 0.317889\n",
            "[2650]\ttraining's binary_logloss: 0.0872527\tvalid_1's binary_logloss: 0.320795\n",
            "[2700]\ttraining's binary_logloss: 0.0849131\tvalid_1's binary_logloss: 0.322438\n",
            "[2750]\ttraining's binary_logloss: 0.0844305\tvalid_1's binary_logloss: 0.322164\n",
            "[2800]\ttraining's binary_logloss: 0.0834515\tvalid_1's binary_logloss: 0.321924\n",
            "[2850]\ttraining's binary_logloss: 0.081305\tvalid_1's binary_logloss: 0.32335\n",
            "[2900]\ttraining's binary_logloss: 0.0804917\tvalid_1's binary_logloss: 0.32378\n",
            "[2950]\ttraining's binary_logloss: 0.0787886\tvalid_1's binary_logloss: 0.324459\n",
            "[3000]\ttraining's binary_logloss: 0.0772381\tvalid_1's binary_logloss: 0.325257\n",
            "[3050]\ttraining's binary_logloss: 0.0761822\tvalid_1's binary_logloss: 0.325774\n",
            "[3100]\ttraining's binary_logloss: 0.0749931\tvalid_1's binary_logloss: 0.326938\n",
            "[3150]\ttraining's binary_logloss: 0.0743284\tvalid_1's binary_logloss: 0.328293\n",
            "[3200]\ttraining's binary_logloss: 0.0727753\tvalid_1's binary_logloss: 0.33003\n",
            "[3250]\ttraining's binary_logloss: 0.0715961\tvalid_1's binary_logloss: 0.332246\n",
            "[3300]\ttraining's binary_logloss: 0.0706524\tvalid_1's binary_logloss: 0.333717\n",
            "[3350]\ttraining's binary_logloss: 0.0692369\tvalid_1's binary_logloss: 0.335015\n",
            "[3400]\ttraining's binary_logloss: 0.0678721\tvalid_1's binary_logloss: 0.337448\n",
            "[3450]\ttraining's binary_logloss: 0.0667568\tvalid_1's binary_logloss: 0.338597\n",
            "[3500]\ttraining's binary_logloss: 0.0661641\tvalid_1's binary_logloss: 0.337526\n",
            "[3550]\ttraining's binary_logloss: 0.0652438\tvalid_1's binary_logloss: 0.33796\n",
            "[3600]\ttraining's binary_logloss: 0.0643444\tvalid_1's binary_logloss: 0.337805\n",
            "[3650]\ttraining's binary_logloss: 0.0635537\tvalid_1's binary_logloss: 0.340643\n",
            "[3700]\ttraining's binary_logloss: 0.0616639\tvalid_1's binary_logloss: 0.343047\n",
            "[3750]\ttraining's binary_logloss: 0.0608442\tvalid_1's binary_logloss: 0.34321\n",
            "[3800]\ttraining's binary_logloss: 0.0602471\tvalid_1's binary_logloss: 0.3448\n",
            "[3850]\ttraining's binary_logloss: 0.0594431\tvalid_1's binary_logloss: 0.344832\n",
            "[3900]\ttraining's binary_logloss: 0.0589744\tvalid_1's binary_logloss: 0.345401\n",
            "[3950]\ttraining's binary_logloss: 0.0590242\tvalid_1's binary_logloss: 0.3448\n",
            "[4000]\ttraining's binary_logloss: 0.0579287\tvalid_1's binary_logloss: 0.346208\n",
            "[4050]\ttraining's binary_logloss: 0.0573362\tvalid_1's binary_logloss: 0.345144\n",
            "[4100]\ttraining's binary_logloss: 0.0565007\tvalid_1's binary_logloss: 0.346705\n",
            "[4150]\ttraining's binary_logloss: 0.055428\tvalid_1's binary_logloss: 0.348837\n",
            "[4200]\ttraining's binary_logloss: 0.0546327\tvalid_1's binary_logloss: 0.348931\n",
            "[4250]\ttraining's binary_logloss: 0.0539374\tvalid_1's binary_logloss: 0.350176\n",
            "[4300]\ttraining's binary_logloss: 0.052793\tvalid_1's binary_logloss: 0.350288\n",
            "[4350]\ttraining's binary_logloss: 0.0525721\tvalid_1's binary_logloss: 0.350599\n",
            "[4400]\ttraining's binary_logloss: 0.0522012\tvalid_1's binary_logloss: 0.35096\n",
            "[4450]\ttraining's binary_logloss: 0.0512317\tvalid_1's binary_logloss: 0.351133\n",
            "[4500]\ttraining's binary_logloss: 0.0508321\tvalid_1's binary_logloss: 0.351877\n",
            " - 0 round - train_metric: 0.676990 - valid_metric: 0.678442\n",
            "\n",
            " - 50 round - train_metric: 0.452106 - valid_metric: 0.456515\n",
            "\n",
            " - 100 round - train_metric: 0.392020 - valid_metric: 0.397605\n",
            "\n",
            " - 150 round - train_metric: 0.373317 - valid_metric: 0.382084\n",
            "\n",
            " - 200 round - train_metric: 0.360146 - valid_metric: 0.366733\n",
            "\n",
            " - 250 round - train_metric: 0.327754 - valid_metric: 0.341096\n",
            "\n",
            " - 300 round - train_metric: 0.310451 - valid_metric: 0.325084\n",
            "\n",
            " - 350 round - train_metric: 0.296984 - valid_metric: 0.317399\n",
            "\n",
            " - 400 round - train_metric: 0.290882 - valid_metric: 0.310524\n",
            "\n",
            " - 450 round - train_metric: 0.285076 - valid_metric: 0.309087\n",
            "\n",
            " - 500 round - train_metric: 0.261682 - valid_metric: 0.295281\n",
            "\n",
            " - 550 round - train_metric: 0.253598 - valid_metric: 0.295600\n",
            "\n",
            " - 600 round - train_metric: 0.246151 - valid_metric: 0.294272\n",
            "\n",
            " - 650 round - train_metric: 0.231814 - valid_metric: 0.289873\n",
            "\n",
            " - 700 round - train_metric: 0.221862 - valid_metric: 0.288690\n",
            "\n",
            " - 750 round - train_metric: 0.210448 - valid_metric: 0.285496\n",
            "\n",
            " - 800 round - train_metric: 0.202483 - valid_metric: 0.286108\n",
            "\n",
            " - 850 round - train_metric: 0.191083 - valid_metric: 0.284042\n",
            "\n",
            " - 900 round - train_metric: 0.185578 - valid_metric: 0.287038\n",
            "\n",
            " - 950 round - train_metric: 0.184104 - valid_metric: 0.287543\n",
            "\n",
            " - 1000 round - train_metric: 0.178919 - valid_metric: 0.286051\n",
            "\n",
            " - 1050 round - train_metric: 0.172596 - valid_metric: 0.288110\n",
            "\n",
            " - 1100 round - train_metric: 0.162611 - valid_metric: 0.289708\n",
            "\n",
            " - 1150 round - train_metric: 0.161937 - valid_metric: 0.292874\n",
            "\n",
            " - 1200 round - train_metric: 0.157157 - valid_metric: 0.295615\n",
            "\n",
            " - 1250 round - train_metric: 0.153522 - valid_metric: 0.292917\n",
            "\n",
            " - 1300 round - train_metric: 0.151061 - valid_metric: 0.294135\n",
            "\n",
            " - 1350 round - train_metric: 0.148391 - valid_metric: 0.294338\n",
            "\n",
            " - 1400 round - train_metric: 0.141973 - valid_metric: 0.295823\n",
            "\n",
            " - 1450 round - train_metric: 0.139980 - valid_metric: 0.297552\n",
            "\n",
            " - 1500 round - train_metric: 0.136936 - valid_metric: 0.299323\n",
            "\n",
            " - 1550 round - train_metric: 0.130633 - valid_metric: 0.300218\n",
            "\n",
            " - 1600 round - train_metric: 0.126203 - valid_metric: 0.303007\n",
            "\n",
            " - 1650 round - train_metric: 0.122006 - valid_metric: 0.304389\n",
            "\n",
            " - 1700 round - train_metric: 0.120100 - valid_metric: 0.305672\n",
            "\n",
            " - 1750 round - train_metric: 0.118336 - valid_metric: 0.307218\n",
            "\n",
            " - 1800 round - train_metric: 0.117333 - valid_metric: 0.306923\n",
            "\n",
            " - 1850 round - train_metric: 0.114971 - valid_metric: 0.305821\n",
            "\n",
            " - 1900 round - train_metric: 0.112558 - valid_metric: 0.305017\n",
            "\n",
            " - 1950 round - train_metric: 0.109321 - valid_metric: 0.307577\n",
            "\n",
            " - 2000 round - train_metric: 0.106813 - valid_metric: 0.307769\n",
            "\n",
            " - 2050 round - train_metric: 0.105393 - valid_metric: 0.309191\n",
            "\n",
            " - 2100 round - train_metric: 0.103700 - valid_metric: 0.307963\n",
            "\n",
            " - 2150 round - train_metric: 0.103583 - valid_metric: 0.308079\n",
            "\n",
            " - 2200 round - train_metric: 0.100964 - valid_metric: 0.307513\n",
            "\n",
            " - 2250 round - train_metric: 0.099194 - valid_metric: 0.308122\n",
            "\n",
            " - 2300 round - train_metric: 0.096696 - valid_metric: 0.311976\n",
            "\n",
            " - 2350 round - train_metric: 0.095664 - valid_metric: 0.311686\n",
            "\n",
            " - 2400 round - train_metric: 0.094010 - valid_metric: 0.312901\n",
            "\n",
            " - 2450 round - train_metric: 0.092340 - valid_metric: 0.314202\n",
            "\n",
            " - 2500 round - train_metric: 0.091432 - valid_metric: 0.316080\n",
            "\n",
            " - 2550 round - train_metric: 0.089855 - valid_metric: 0.316358\n",
            "\n",
            " - 2600 round - train_metric: 0.088537 - valid_metric: 0.317864\n",
            "\n",
            " - 2650 round - train_metric: 0.087288 - valid_metric: 0.320773\n",
            "\n",
            " - 2700 round - train_metric: 0.084965 - valid_metric: 0.322410\n",
            "\n",
            " - 2750 round - train_metric: 0.084475 - valid_metric: 0.322117\n",
            "\n",
            " - 2800 round - train_metric: 0.083328 - valid_metric: 0.321946\n",
            "\n",
            " - 2850 round - train_metric: 0.081346 - valid_metric: 0.323338\n",
            "\n",
            " - 2900 round - train_metric: 0.080550 - valid_metric: 0.323739\n",
            "\n",
            " - 2950 round - train_metric: 0.078826 - valid_metric: 0.324425\n",
            "\n",
            " - 3000 round - train_metric: 0.077277 - valid_metric: 0.325209\n",
            "\n",
            " - 3050 round - train_metric: 0.076079 - valid_metric: 0.325436\n",
            "\n",
            " - 3100 round - train_metric: 0.075022 - valid_metric: 0.326918\n",
            "\n",
            " - 3150 round - train_metric: 0.074371 - valid_metric: 0.328240\n",
            "\n",
            " - 3200 round - train_metric: 0.072685 - valid_metric: 0.329946\n",
            "\n",
            " - 3250 round - train_metric: 0.071621 - valid_metric: 0.332226\n",
            "\n",
            " - 3300 round - train_metric: 0.070691 - valid_metric: 0.333702\n",
            "\n",
            " - 3350 round - train_metric: 0.069272 - valid_metric: 0.334982\n",
            "\n",
            " - 3400 round - train_metric: 0.067910 - valid_metric: 0.337410\n",
            "\n",
            " - 3450 round - train_metric: 0.066710 - valid_metric: 0.338540\n",
            "\n",
            " - 3500 round - train_metric: 0.066109 - valid_metric: 0.337524\n",
            "\n",
            " - 3550 round - train_metric: 0.065269 - valid_metric: 0.337929\n",
            "\n",
            " - 3600 round - train_metric: 0.064375 - valid_metric: 0.337779\n",
            "\n",
            " - 3650 round - train_metric: 0.063597 - valid_metric: 0.340591\n",
            "\n",
            " - 3700 round - train_metric: 0.061594 - valid_metric: 0.343139\n",
            "\n",
            " - 3750 round - train_metric: 0.060775 - valid_metric: 0.343432\n",
            "\n",
            " - 3800 round - train_metric: 0.060206 - valid_metric: 0.344749\n",
            "\n",
            " - 3850 round - train_metric: 0.059392 - valid_metric: 0.344859\n",
            "\n",
            " - 3900 round - train_metric: 0.058995 - valid_metric: 0.345371\n",
            "\n",
            " - 3950 round - train_metric: 0.058968 - valid_metric: 0.344962\n",
            "\n",
            " - 4000 round - train_metric: 0.057869 - valid_metric: 0.346364\n",
            "\n",
            " - 4050 round - train_metric: 0.057361 - valid_metric: 0.345100\n",
            "\n",
            " - 4100 round - train_metric: 0.056529 - valid_metric: 0.346670\n",
            "\n",
            " - 4150 round - train_metric: 0.055456 - valid_metric: 0.348825\n",
            "\n",
            " - 4200 round - train_metric: 0.054659 - valid_metric: 0.348867\n",
            "\n",
            " - 4250 round - train_metric: 0.053959 - valid_metric: 0.350132\n",
            "\n",
            " - 4300 round - train_metric: 0.052826 - valid_metric: 0.350255\n",
            "\n",
            " - 4350 round - train_metric: 0.052534 - valid_metric: 0.350540\n",
            "\n",
            " - 4400 round - train_metric: 0.052142 - valid_metric: 0.351259\n",
            "\n",
            " - 4450 round - train_metric: 0.051252 - valid_metric: 0.351103\n",
            "\n",
            "- fold3 valid metric: 0.638026\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.43532\tvalid_1's binary_logloss: 0.487368\n",
            "[100]\ttraining's binary_logloss: 0.376438\tvalid_1's binary_logloss: 0.447659\n",
            "[150]\ttraining's binary_logloss: 0.351094\tvalid_1's binary_logloss: 0.436737\n",
            "[200]\ttraining's binary_logloss: 0.336181\tvalid_1's binary_logloss: 0.432461\n",
            "[250]\ttraining's binary_logloss: 0.304808\tvalid_1's binary_logloss: 0.417526\n",
            "[300]\ttraining's binary_logloss: 0.285527\tvalid_1's binary_logloss: 0.412648\n",
            "[350]\ttraining's binary_logloss: 0.269892\tvalid_1's binary_logloss: 0.412499\n",
            "[400]\ttraining's binary_logloss: 0.261828\tvalid_1's binary_logloss: 0.414101\n",
            "[450]\ttraining's binary_logloss: 0.258535\tvalid_1's binary_logloss: 0.411702\n",
            "[500]\ttraining's binary_logloss: 0.238746\tvalid_1's binary_logloss: 0.410331\n",
            "[550]\ttraining's binary_logloss: 0.229872\tvalid_1's binary_logloss: 0.413849\n",
            "[600]\ttraining's binary_logloss: 0.223826\tvalid_1's binary_logloss: 0.415803\n",
            "[650]\ttraining's binary_logloss: 0.20861\tvalid_1's binary_logloss: 0.42224\n",
            "[700]\ttraining's binary_logloss: 0.19817\tvalid_1's binary_logloss: 0.425137\n",
            "[750]\ttraining's binary_logloss: 0.187661\tvalid_1's binary_logloss: 0.42543\n",
            "[800]\ttraining's binary_logloss: 0.180154\tvalid_1's binary_logloss: 0.428525\n",
            "[850]\ttraining's binary_logloss: 0.169217\tvalid_1's binary_logloss: 0.432914\n",
            "[900]\ttraining's binary_logloss: 0.164015\tvalid_1's binary_logloss: 0.43493\n",
            "[950]\ttraining's binary_logloss: 0.163002\tvalid_1's binary_logloss: 0.430754\n",
            "[1000]\ttraining's binary_logloss: 0.156596\tvalid_1's binary_logloss: 0.43215\n",
            "[1050]\ttraining's binary_logloss: 0.153084\tvalid_1's binary_logloss: 0.435477\n",
            "[1100]\ttraining's binary_logloss: 0.145024\tvalid_1's binary_logloss: 0.439921\n",
            "[1150]\ttraining's binary_logloss: 0.143875\tvalid_1's binary_logloss: 0.441698\n",
            "[1200]\ttraining's binary_logloss: 0.140117\tvalid_1's binary_logloss: 0.441691\n",
            "[1250]\ttraining's binary_logloss: 0.137025\tvalid_1's binary_logloss: 0.441948\n",
            "[1300]\ttraining's binary_logloss: 0.134857\tvalid_1's binary_logloss: 0.441561\n",
            "[1350]\ttraining's binary_logloss: 0.132829\tvalid_1's binary_logloss: 0.441817\n",
            "[1400]\ttraining's binary_logloss: 0.128066\tvalid_1's binary_logloss: 0.448601\n",
            "[1450]\ttraining's binary_logloss: 0.126189\tvalid_1's binary_logloss: 0.446754\n",
            "[1500]\ttraining's binary_logloss: 0.124432\tvalid_1's binary_logloss: 0.447261\n",
            "[1550]\ttraining's binary_logloss: 0.119061\tvalid_1's binary_logloss: 0.452288\n",
            "[1600]\ttraining's binary_logloss: 0.114908\tvalid_1's binary_logloss: 0.456617\n",
            "[1650]\ttraining's binary_logloss: 0.111625\tvalid_1's binary_logloss: 0.460222\n",
            "[1700]\ttraining's binary_logloss: 0.109568\tvalid_1's binary_logloss: 0.460822\n",
            "[1750]\ttraining's binary_logloss: 0.107547\tvalid_1's binary_logloss: 0.464564\n",
            "[1800]\ttraining's binary_logloss: 0.106736\tvalid_1's binary_logloss: 0.463081\n",
            "[1850]\ttraining's binary_logloss: 0.104735\tvalid_1's binary_logloss: 0.466844\n",
            "[1900]\ttraining's binary_logloss: 0.10257\tvalid_1's binary_logloss: 0.466728\n",
            "[1950]\ttraining's binary_logloss: 0.0994719\tvalid_1's binary_logloss: 0.470781\n",
            "[2000]\ttraining's binary_logloss: 0.0974781\tvalid_1's binary_logloss: 0.469525\n",
            "[2050]\ttraining's binary_logloss: 0.0960191\tvalid_1's binary_logloss: 0.469355\n",
            "[2100]\ttraining's binary_logloss: 0.0945496\tvalid_1's binary_logloss: 0.470629\n",
            "[2150]\ttraining's binary_logloss: 0.0944379\tvalid_1's binary_logloss: 0.469185\n",
            "[2200]\ttraining's binary_logloss: 0.0919602\tvalid_1's binary_logloss: 0.472369\n",
            "[2250]\ttraining's binary_logloss: 0.0903138\tvalid_1's binary_logloss: 0.475254\n",
            "[2300]\ttraining's binary_logloss: 0.0881926\tvalid_1's binary_logloss: 0.479696\n",
            "[2350]\ttraining's binary_logloss: 0.0867879\tvalid_1's binary_logloss: 0.480633\n",
            "[2400]\ttraining's binary_logloss: 0.0856546\tvalid_1's binary_logloss: 0.483734\n",
            "[2450]\ttraining's binary_logloss: 0.0843933\tvalid_1's binary_logloss: 0.485204\n",
            "[2500]\ttraining's binary_logloss: 0.0834457\tvalid_1's binary_logloss: 0.485124\n",
            "[2550]\ttraining's binary_logloss: 0.0824359\tvalid_1's binary_logloss: 0.484807\n",
            "[2600]\ttraining's binary_logloss: 0.0812266\tvalid_1's binary_logloss: 0.486486\n",
            "[2650]\ttraining's binary_logloss: 0.0797468\tvalid_1's binary_logloss: 0.488728\n",
            "[2700]\ttraining's binary_logloss: 0.0782311\tvalid_1's binary_logloss: 0.491034\n",
            "[2750]\ttraining's binary_logloss: 0.0776784\tvalid_1's binary_logloss: 0.488558\n",
            "[2800]\ttraining's binary_logloss: 0.0768217\tvalid_1's binary_logloss: 0.489381\n",
            "[2850]\ttraining's binary_logloss: 0.0749736\tvalid_1's binary_logloss: 0.492875\n",
            "[2900]\ttraining's binary_logloss: 0.073973\tvalid_1's binary_logloss: 0.495937\n",
            "[2950]\ttraining's binary_logloss: 0.0724284\tvalid_1's binary_logloss: 0.499097\n",
            "[3000]\ttraining's binary_logloss: 0.0712957\tvalid_1's binary_logloss: 0.500564\n",
            "[3050]\ttraining's binary_logloss: 0.0700983\tvalid_1's binary_logloss: 0.501886\n",
            "[3100]\ttraining's binary_logloss: 0.0692408\tvalid_1's binary_logloss: 0.501856\n",
            "[3150]\ttraining's binary_logloss: 0.0684474\tvalid_1's binary_logloss: 0.506684\n",
            "[3200]\ttraining's binary_logloss: 0.0671386\tvalid_1's binary_logloss: 0.507905\n",
            "[3250]\ttraining's binary_logloss: 0.0661276\tvalid_1's binary_logloss: 0.510596\n",
            "[3300]\ttraining's binary_logloss: 0.0651774\tvalid_1's binary_logloss: 0.512764\n",
            "[3350]\ttraining's binary_logloss: 0.0639371\tvalid_1's binary_logloss: 0.514837\n",
            "[3400]\ttraining's binary_logloss: 0.0627093\tvalid_1's binary_logloss: 0.516587\n",
            "[3450]\ttraining's binary_logloss: 0.0616339\tvalid_1's binary_logloss: 0.519017\n",
            "[3500]\ttraining's binary_logloss: 0.0610127\tvalid_1's binary_logloss: 0.521403\n",
            "[3550]\ttraining's binary_logloss: 0.0601952\tvalid_1's binary_logloss: 0.523757\n",
            "[3600]\ttraining's binary_logloss: 0.0594751\tvalid_1's binary_logloss: 0.524761\n",
            "[3650]\ttraining's binary_logloss: 0.0587241\tvalid_1's binary_logloss: 0.526739\n",
            "[3700]\ttraining's binary_logloss: 0.0572743\tvalid_1's binary_logloss: 0.529276\n",
            "[3750]\ttraining's binary_logloss: 0.0565103\tvalid_1's binary_logloss: 0.53\n",
            "[3800]\ttraining's binary_logloss: 0.0560624\tvalid_1's binary_logloss: 0.528917\n",
            "[3850]\ttraining's binary_logloss: 0.0552895\tvalid_1's binary_logloss: 0.531683\n",
            "[3900]\ttraining's binary_logloss: 0.0548023\tvalid_1's binary_logloss: 0.531039\n",
            "[3950]\ttraining's binary_logloss: 0.0546897\tvalid_1's binary_logloss: 0.53172\n",
            "[4000]\ttraining's binary_logloss: 0.0536508\tvalid_1's binary_logloss: 0.532753\n",
            "[4050]\ttraining's binary_logloss: 0.0529319\tvalid_1's binary_logloss: 0.532144\n",
            "[4100]\ttraining's binary_logloss: 0.0520258\tvalid_1's binary_logloss: 0.533404\n",
            "[4150]\ttraining's binary_logloss: 0.0509638\tvalid_1's binary_logloss: 0.534365\n",
            "[4200]\ttraining's binary_logloss: 0.0504099\tvalid_1's binary_logloss: 0.534959\n",
            "[4250]\ttraining's binary_logloss: 0.0496771\tvalid_1's binary_logloss: 0.53545\n",
            "[4300]\ttraining's binary_logloss: 0.0487103\tvalid_1's binary_logloss: 0.538565\n",
            "[4350]\ttraining's binary_logloss: 0.0484229\tvalid_1's binary_logloss: 0.537741\n",
            "[4400]\ttraining's binary_logloss: 0.0480583\tvalid_1's binary_logloss: 0.538758\n",
            "[4450]\ttraining's binary_logloss: 0.0472209\tvalid_1's binary_logloss: 0.540105\n",
            "[4500]\ttraining's binary_logloss: 0.0466994\tvalid_1's binary_logloss: 0.541796\n",
            " - 0 round - train_metric: 0.675358 - valid_metric: 0.678743\n",
            "\n",
            " - 50 round - train_metric: 0.437636 - valid_metric: 0.489252\n",
            "\n",
            " - 100 round - train_metric: 0.372411 - valid_metric: 0.444543\n",
            "\n",
            " - 150 round - train_metric: 0.353036 - valid_metric: 0.437769\n",
            "\n",
            " - 200 round - train_metric: 0.337479 - valid_metric: 0.432957\n",
            "\n",
            " - 250 round - train_metric: 0.302698 - valid_metric: 0.417438\n",
            "\n",
            " - 300 round - train_metric: 0.283536 - valid_metric: 0.412278\n",
            "\n",
            " - 350 round - train_metric: 0.270648 - valid_metric: 0.412591\n",
            "\n",
            " - 400 round - train_metric: 0.262455 - valid_metric: 0.414110\n",
            "\n",
            " - 450 round - train_metric: 0.259126 - valid_metric: 0.411658\n",
            "\n",
            " - 500 round - train_metric: 0.237717 - valid_metric: 0.410352\n",
            "\n",
            " - 550 round - train_metric: 0.228946 - valid_metric: 0.414601\n",
            "\n",
            " - 600 round - train_metric: 0.222744 - valid_metric: 0.416349\n",
            "\n",
            " - 650 round - train_metric: 0.208877 - valid_metric: 0.422113\n",
            "\n",
            " - 700 round - train_metric: 0.198455 - valid_metric: 0.424898\n",
            "\n",
            " - 750 round - train_metric: 0.187948 - valid_metric: 0.425175\n",
            "\n",
            " - 800 round - train_metric: 0.180338 - valid_metric: 0.428328\n",
            "\n",
            " - 850 round - train_metric: 0.168842 - valid_metric: 0.433025\n",
            "\n",
            " - 900 round - train_metric: 0.163614 - valid_metric: 0.435210\n",
            "\n",
            " - 950 round - train_metric: 0.162537 - valid_metric: 0.430867\n",
            "\n",
            " - 1000 round - train_metric: 0.156761 - valid_metric: 0.431971\n",
            "\n",
            " - 1050 round - train_metric: 0.152745 - valid_metric: 0.435949\n",
            "\n",
            " - 1100 round - train_metric: 0.144718 - valid_metric: 0.440717\n",
            "\n",
            " - 1150 round - train_metric: 0.143997 - valid_metric: 0.441480\n",
            "\n",
            " - 1200 round - train_metric: 0.140250 - valid_metric: 0.441475\n",
            "\n",
            " - 1250 round - train_metric: 0.137132 - valid_metric: 0.441814\n",
            "\n",
            " - 1300 round - train_metric: 0.134973 - valid_metric: 0.441385\n",
            "\n",
            " - 1350 round - train_metric: 0.132963 - valid_metric: 0.441641\n",
            "\n",
            " - 1400 round - train_metric: 0.127756 - valid_metric: 0.448304\n",
            "\n",
            " - 1450 round - train_metric: 0.126305 - valid_metric: 0.446548\n",
            "\n",
            " - 1500 round - train_metric: 0.124162 - valid_metric: 0.447090\n",
            "\n",
            " - 1550 round - train_metric: 0.118857 - valid_metric: 0.452702\n",
            "\n",
            " - 1600 round - train_metric: 0.115019 - valid_metric: 0.456403\n",
            "\n",
            " - 1650 round - train_metric: 0.111440 - valid_metric: 0.460725\n",
            "\n",
            " - 1700 round - train_metric: 0.109394 - valid_metric: 0.461146\n",
            "\n",
            " - 1750 round - train_metric: 0.107628 - valid_metric: 0.464412\n",
            "\n",
            " - 1800 round - train_metric: 0.106580 - valid_metric: 0.463792\n",
            "\n",
            " - 1850 round - train_metric: 0.104842 - valid_metric: 0.466682\n",
            "\n",
            " - 1900 round - train_metric: 0.102426 - valid_metric: 0.467281\n",
            "\n",
            " - 1950 round - train_metric: 0.099542 - valid_metric: 0.470620\n",
            "\n",
            " - 2000 round - train_metric: 0.097298 - valid_metric: 0.469391\n",
            "\n",
            " - 2050 round - train_metric: 0.096083 - valid_metric: 0.469212\n",
            "\n",
            " - 2100 round - train_metric: 0.094600 - valid_metric: 0.470527\n",
            "\n",
            " - 2150 round - train_metric: 0.094515 - valid_metric: 0.469016\n",
            "\n",
            " - 2200 round - train_metric: 0.092034 - valid_metric: 0.472191\n",
            "\n",
            " - 2250 round - train_metric: 0.090163 - valid_metric: 0.475916\n",
            "\n",
            " - 2300 round - train_metric: 0.088260 - valid_metric: 0.479529\n",
            "\n",
            " - 2350 round - train_metric: 0.086862 - valid_metric: 0.480497\n",
            "\n",
            " - 2400 round - train_metric: 0.085541 - valid_metric: 0.483565\n",
            "\n",
            " - 2450 round - train_metric: 0.084257 - valid_metric: 0.485297\n",
            "\n",
            " - 2500 round - train_metric: 0.083481 - valid_metric: 0.485055\n",
            "\n",
            " - 2550 round - train_metric: 0.082321 - valid_metric: 0.484811\n",
            "\n",
            " - 2600 round - train_metric: 0.081258 - valid_metric: 0.486388\n",
            "\n",
            " - 2650 round - train_metric: 0.079780 - valid_metric: 0.488629\n",
            "\n",
            " - 2700 round - train_metric: 0.078281 - valid_metric: 0.490900\n",
            "\n",
            " - 2750 round - train_metric: 0.077716 - valid_metric: 0.488461\n",
            "\n",
            " - 2800 round - train_metric: 0.076755 - valid_metric: 0.489203\n",
            "\n",
            " - 2850 round - train_metric: 0.075010 - valid_metric: 0.492790\n",
            "\n",
            " - 2900 round - train_metric: 0.074026 - valid_metric: 0.495800\n",
            "\n",
            " - 2950 round - train_metric: 0.072463 - valid_metric: 0.498978\n",
            "\n",
            " - 3000 round - train_metric: 0.071331 - valid_metric: 0.500459\n",
            "\n",
            " - 3050 round - train_metric: 0.070027 - valid_metric: 0.502130\n",
            "\n",
            " - 3100 round - train_metric: 0.069268 - valid_metric: 0.501769\n",
            "\n",
            " - 3150 round - train_metric: 0.068483 - valid_metric: 0.506600\n",
            "\n",
            " - 3200 round - train_metric: 0.067062 - valid_metric: 0.508059\n",
            "\n",
            " - 3250 round - train_metric: 0.066150 - valid_metric: 0.510499\n",
            "\n",
            " - 3300 round - train_metric: 0.065207 - valid_metric: 0.512610\n",
            "\n",
            " - 3350 round - train_metric: 0.063965 - valid_metric: 0.514771\n",
            "\n",
            " - 3400 round - train_metric: 0.062737 - valid_metric: 0.516462\n",
            "\n",
            " - 3450 round - train_metric: 0.061562 - valid_metric: 0.519605\n",
            "\n",
            " - 3500 round - train_metric: 0.060939 - valid_metric: 0.521511\n",
            "\n",
            " - 3550 round - train_metric: 0.060219 - valid_metric: 0.523674\n",
            "\n",
            " - 3600 round - train_metric: 0.059503 - valid_metric: 0.524693\n",
            "\n",
            " - 3650 round - train_metric: 0.058763 - valid_metric: 0.526639\n",
            "\n",
            " - 3700 round - train_metric: 0.057233 - valid_metric: 0.529275\n",
            "\n",
            " - 3750 round - train_metric: 0.056459 - valid_metric: 0.530100\n",
            "\n",
            " - 3800 round - train_metric: 0.056016 - valid_metric: 0.528924\n",
            "\n",
            " - 3850 round - train_metric: 0.055232 - valid_metric: 0.532212\n",
            "\n",
            " - 3900 round - train_metric: 0.054819 - valid_metric: 0.530966\n",
            "\n",
            " - 3950 round - train_metric: 0.054650 - valid_metric: 0.531869\n",
            "\n",
            " - 4000 round - train_metric: 0.053581 - valid_metric: 0.532624\n",
            "\n",
            " - 4050 round - train_metric: 0.052954 - valid_metric: 0.532050\n",
            "\n",
            " - 4100 round - train_metric: 0.052056 - valid_metric: 0.533287\n",
            "\n",
            " - 4150 round - train_metric: 0.050989 - valid_metric: 0.534268\n",
            "\n",
            " - 4200 round - train_metric: 0.050434 - valid_metric: 0.534842\n",
            "\n",
            " - 4250 round - train_metric: 0.049699 - valid_metric: 0.535400\n",
            "\n",
            " - 4300 round - train_metric: 0.048741 - valid_metric: 0.538414\n",
            "\n",
            " - 4350 round - train_metric: 0.048378 - valid_metric: 0.537941\n",
            "\n",
            " - 4400 round - train_metric: 0.048023 - valid_metric: 0.538728\n",
            "\n",
            " - 4450 round - train_metric: 0.047240 - valid_metric: 0.540014\n",
            "\n",
            "- fold4 valid metric: 0.485838\n",
            "\n",
            "all valid mean metric:0.592688, global valid metric:0.588928\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (8000, 190)\n",
            "========test[features]        P_2  ...  D_145\n",
            "0     63.0  ...    NaN\n",
            "1     58.0  ...    0.0\n",
            "2     60.0  ...    0.0\n",
            "3     61.0  ...    0.0\n",
            "4     59.0  ...    0.0\n",
            "...    ...  ...    ...\n",
            "7995  38.0  ...   45.0\n",
            "7996  39.0  ...   45.0\n",
            "7997  38.0  ...   45.0\n",
            "7998  38.0  ...   46.0\n",
            "7999   2.0  ...   46.0\n",
            "\n",
            "[8000 rows x 188 columns]\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (8000, 190)\n",
            "========test[features]        P_2  ...  D_145\n",
            "0     63.0  ...    NaN\n",
            "1     58.0  ...    0.0\n",
            "2     60.0  ...    0.0\n",
            "3     61.0  ...    0.0\n",
            "4     59.0  ...    0.0\n",
            "...    ...  ...    ...\n",
            "7995  38.0  ...   45.0\n",
            "7996  39.0  ...   45.0\n",
            "7997  38.0  ...   45.0\n",
            "7998  38.0  ...   46.0\n",
            "7999   2.0  ...   46.0\n",
            "\n",
            "[8000 rows x 188 columns]\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (8000, 190)\n",
            "========test[features]        P_2  ...  D_145\n",
            "0     63.0  ...    NaN\n",
            "1     58.0  ...    0.0\n",
            "2     60.0  ...    0.0\n",
            "3     61.0  ...    0.0\n",
            "4     59.0  ...    0.0\n",
            "...    ...  ...    ...\n",
            "7995  38.0  ...   45.0\n",
            "7996  39.0  ...   45.0\n",
            "7997  38.0  ...   45.0\n",
            "7998  38.0  ...   46.0\n",
            "7999   2.0  ...   46.0\n",
            "\n",
            "[8000 rows x 188 columns]\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (8000, 190)\n",
            "========test[features]        P_2  ...  D_145\n",
            "0     63.0  ...    NaN\n",
            "1     58.0  ...    0.0\n",
            "2     60.0  ...    0.0\n",
            "3     61.0  ...    0.0\n",
            "4     59.0  ...    0.0\n",
            "...    ...  ...    ...\n",
            "7995  38.0  ...   45.0\n",
            "7996  39.0  ...   45.0\n",
            "7997  38.0  ...   45.0\n",
            "7998  38.0  ...   46.0\n",
            "7999   2.0  ...   46.0\n",
            "\n",
            "[8000 rows x 188 columns]\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (8000, 190)\n",
            "========test[features]        P_2  ...  D_145\n",
            "0     63.0  ...    NaN\n",
            "1     58.0  ...    0.0\n",
            "2     60.0  ...    0.0\n",
            "3     61.0  ...    0.0\n",
            "4     59.0  ...    0.0\n",
            "...    ...  ...    ...\n",
            "7995  38.0  ...   45.0\n",
            "7996  39.0  ...   45.0\n",
            "7997  38.0  ...   45.0\n",
            "7998  38.0  ...   46.0\n",
            "7999   2.0  ...   46.0\n",
            "\n",
            "[8000 rows x 188 columns]\n",
            "oof.shape,sub.shape (5000, 2) (8000, 2)\n",
            "mean_valid_metric,global_valid_metric 0.5926884328338352 0.5889283572536425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature importance\n",
        "import pandas as pd\n",
        "filepath = '/data/featureResult_v01_20/featureResult.20.2020-06-22.csv'\n",
        "columns = pd.read_csv(filepath, index_col=0,nrows=0).columns.tolist()[1:-3]\n",
        "df = pd.DataFrame()\n",
        "df['feature name'] = columns\n",
        "df['importance'] = bst.feature_importance()\n",
        "df = df.sort_values('importance')\n",
        "df.plot.barh(x = 'feature name',figsize=(10,12))"
      ],
      "metadata": {
        "id": "JPbFbPzqMKf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiyy_plot():\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Credit_risk/Kaggle-American-Express/output/LGB_with_series_feature/feature_importance.csv\")\n",
        "\n",
        "    x = df['feature_name']\n",
        "    y1 = df['importance_gain']\n",
        "    y2 = df['importance_split']\n",
        "    print('df.shape',df.shape)\n",
        "\n",
        "    # Plot Line1 (Left Y Axis)\n",
        "    fig, ax1 = plt.subplots(1, 1, figsize=(16, 9), dpi=80)\n",
        "    ax1.plot(x, y1, color='tab:red')\n",
        "\n",
        "    # Plot Line2 (Right Y Axis)\n",
        "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "    ax2.plot(x, y2, color='tab:blue')\n",
        "\n",
        "    # Decorations\n",
        "    # ax1 (left Y axis)\n",
        "    ax1.set_xlabel('feature_name', fontsize=20)\n",
        "    ax1.tick_params(axis='x', rotation=0, labelsize=12)\n",
        "\n",
        "    ax1.set_ylabel('importance_gain', color='tab:red', fontsize=20)\n",
        "    ax1.tick_params(axis='y', rotation=0, labelcolor='tab:red')\n",
        "    ax1.grid(alpha=.4)\n",
        "\n",
        "    # ax2 (right Y axis)\n",
        "    ax2.set_ylabel(\"importance_gain\", color='tab:blue', fontsize=20)\n",
        "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "    ax2.set_xticks(np.arange(0, len(x), 5))\n",
        "    ax2.set_xticklabels(x[::10], rotation=90, fontdict={'fontsize': 5})\n",
        "    ax2.set_title(\"importance_split and importance_gain\", fontsize=22)\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZpMm3TYyNhuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "multiyy_plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "qjzK9nCGN6C6",
        "outputId": "f69a60f9-e282-47a4-bc7a-0484bb481f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df.shape (188, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1280x720 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABPgAAALICAYAAADi7U4NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde5hsV13n//eqXZ0rxNxJJCcpTIDa/IAAkkEYLmHmZxSLASWKoAGDqIijghG1cEaJl9HCGSKTwQv8REIURgR+XrBUBCQEZSL3a6ogAYpzEkhCck5ywrnkdFft+WPv6q7Tp7q6u7ouvXu/X8+znz5V+7LWrqquJ/3Jd60VkiRBkiRJkiRJUj6V5t0BSZIkSZIkSeMz4JMkSZIkSZJyzIBPkiRJkiRJyjEDPkmSJEmSJCnHDPgkSZIkSZKkHDPgkyRJkiRJknLMgE+SJEmSJEnKMQM+SdJEhRBuCCEkIYSr590XaRJGfaaz55MQwqWz79l8hRAu7d//GOf6PaEdKYRwdfbZvmHefZEkFUt53h2QJKkoQgiPA74fuDdJktfPuz+anhBCBbgSIEmSq+fYFeWM3xOSJGkcVvBJkiZtN/BF4O55d2QbehzwGuCV8+6IJuaL2XZw1fMV0vf6NbPuUE74PbE2vyfy7W7Sz/bueXdEklQsVvBJkiYqSZIXz7sP0qwkSVKddx/yyO8J7VRJkrwBeMO8+yFJKh4r+CRJkiRJkqQcM+CTJE3URhckCCGcHUJ4QwihE0I4FEK4JYTwayGE4waOf2YI4R9CCN8MIRwMIdwUQnj2Gu1WBq5fCSHEIYS3hRC+HkI4nF3/d0IID1qn/3EI4c0hhK9m590bQvhICOEVg31bdc5Rk6qHEH40hPChEMI92fPfny1E8JbslAsG+trfrhy43mkhhJ8IIbwzhPD5EMK+rC9fDSFcF0K4eET/r8uud132+Eey/u8PIdyf/fsHR70G2XlPz16//vuzN4TwmRDC60MI37nGOaeGEH49hPCJEMJ9WZ+/HEL44xDCReu1uVEhhPNDCP8rhNDKPheHQwh7Qgj/J4Tw26vbCiFcmb0mnezxs0II78/u6UAI4eMhhJ8MIYQx+nLMIhtZOx8cckx/u3oT1z83hPDzIYS/DSG0s/fwQAjhiyGEPwghfMeIc5d/F0MIpRDCz4YQPpWdf28I4X0hhGeu0/7ZWTu7s9d5dwjhjSGEh270Htbr25B9fk+k/J7YohDCI0IIfx5CuCNr59YQwuuyPhz1vbDqvJOy1+TPs/u5O4TwQAjhthDCX4YQnj6izTUX2ZjE76QkSWtKksTNzc3NzW1iG3ADkABXD9mXZNuPAbdn/74PWBrY9+7s2JcD3Wy7b2B/D3jekGtXBo55IXD/wPUfGNj3BeCsNfr+ImBx4Nh7V537SeDsIeddne2/Abg2+3cX2Jv9/H7gjoH76GaPB7cfHnK9JHtt7gGODDx3BHjhGvdwXXbMdcAfD1xj8DVMgJ9d4/wy8KZVx+5fdf4NQ867JLuPwT4eGHh8AHj2BD5fj8vel/51F4F9q/r7qlXnXJk93wF+fuBztHfVZ+8vgNKYn+lLB577WHbt/r7V7/WrNnG/13H0a3r3qj7fDzxznd/F3wb+buAa9w+cvwQ8d43zHwl8Y+DYg8C3sn/fCby0v8/vCb8n2EbfE1lbl6669v3AoezftwBXZf/uDDn3yoHz+u/RoYHnesAvrdHu8vs86d9JNzc3Nze3UdvcO+Dm5ubmtrM2NvaH+z7gI8Bjs+dPAv7rwP7/mv3R8zvAqdkxF2TnJMBtQLTq2pWB8+8lDVkuzvaVgRcM/PH5d0P69u9Y+aP9fcAjs+cXgB8ZOPefgbDq3P4fdPdnf/j9+kC/TyH7Y3/gj8bOOq/hT2XXeDywkD1XAmLgbayELbuGnHtdtr//B+lPAydl+x4GfGjg/NOHnP/7A6/j/wQuGNh3FvBi4JpV55xHGjz1A4NHkQVlwIUDfb4fqGzx8/WB7Fr/Bjyx/14AJwCPBn4DeMGqc/qv+4Hsc3U9cO7A+9N//xKGhG9sMuDLnr+0v2+L9/tfgF/MXtMoey7K7v0fWQkQTxrR772k4c/zgeOyfY8FPsfav08LwGez/bcD3zPwWj8D+AoDQavfE35PbLPviTOAu7LrfRa4ZOD1eTbp70z/fwwc8zoDzwV+D3gycEL2XMg+X69nJfi7ZMi5/ff5hkn+Trq5ubm5ua23zb0Dbm5ubm47a2Njf7jv7f9hu2r/BwaO+dMh+y/I/jBOgKet2lcZOPfONf4ofe7AMU9ete+fBv4YPH7Iud83cO6zVu27emDf74x4ba5c6w/KTby+gTRYSIBfH7L/uoG+/OiQ/d/OSrXRi1ftqw68vq/eRJ/6bf7BiGP+ITvm2i1+vg5m1/muTZxz5cBr8k+sCl6yY/qBxT7gxDE+05euev7S/r6t3O8693U8aaXZMe/lqn4nwFOH7P/Ogf1PX7XvClZCjCcMOfcRwOFx73GDr6nfE+N/Nor+PfEaVkLcc4bsf8rAPWz6dQbePOLz13+fbxjxud/076Sbm5ubm9t6m3PwSZLm4Y+TJLl3yPPvH/j3767emSTJ14Bbs4ePWef6e4ec/zfA57OHz+8/H0I4Dfh/s4eNJEkeGHLu35NWjUE6tG+YLnDNiH5tWZIkCdDMHj51xKG7gbcPOf/rwEezh49etfvHSIOB20irV9YVQjiRtOoJ4L+POLTfl8s2ct0R7st+fvuY5/9u9hqu1iB9/05l632ciexz+r7s4ajPwoeTJPmXIed/gvS9hmM/C/351/4xSZJPDjn3S8A7N9fjTfN7Ykx+T3B59vOtSZLcsXpnkiQfIa1SHNd7sp+jXttRxvmdlCRppPK8OyBJKqTPrfH8XdnPw6z8gb7ancDDgdNGXP+GEfs+SPqH0xMGnnsC6R+scHR4sNr7gSeRVlkMc2uSJHePOH/DQggPB/4zaSXYw4AHceziWKNCro+vEWRBOuQSjn0Nn5z9/MckSbob7Op3klaSAdwU1l6nor/wwPkbvO5amqRzv701hPAU4K+Bjw0LW4ZYBP512I4kSe4MIdxMGgg9AfibLfZzYkIITyAdQvlUYBdwMiuf175Rn4WPjdh3O+nQydWfhf5n/IYR536QtNJvWvyeWIffE8fKFjl5VPbwwyMOvZH0dVvrOucCPwt8N+ln6RQ299qOMs7vpCRJIxnwSZLm4RtrPN//Y/HOEX909o9ZGHH92zew7+yB587Kfi4mSXIXa+tXVpy9xv5vjjh3w0IIl5NWsgyuxnkfaaABcCLpH5snj7jM/SP29a+z+jV8SPbzaxvrKQDnDjl/lBM3ce1hfon0j+2nk85N94vAYgjho8DfAn8yrCorc3eSJEdGXPt20oBvrfd35kIIP086fLgfLPRYWRAC0kDnZCb/Wej/Tmzkd2la/J4Ywe+JNZ1OOk8lwNdHHLfmvhDCvwf+nvT16xtcpOM40gBu1Gs7yjivuyRJIzlEV5KkydloNcuaQghnAm8h/QPy/aRB1olJkpyaJMk5SZKcQ7r6IxxbxTUP/T+kl5IkCRvZttJYkiT7kiR5BmnlzTWkwwgD8O+B1wK3hBC+ayttbBchhJj0HkvAO0gX1jghSZLTBj4Lv98/fE7d1Ob5PTHl74mtCCGUSYPTU0hXRP5e4MFJkpySJMlDstf2h+bVP0mS1mLAJ0naiUYNm3po9nOwAqdfUbMQQhhVvXXekHMn7VnAg0kXGHhukiQfTpLk8KpjNlIBM47+XFUXbOKcO7Of5RDCuMPVNi1Jkg8lSfKLSZI8ibSS5kdI5xM7HfjzNU47Mxu+t5Zhn415+kHSYORm4EeSJPlEkiSLq46Z1meh/zuxkd+lvPJ7Yjzb/XtiLysh6rkjjltr35NJhwh3geckSfLeJEm+teqYab22kiSNzYBPkrQTPWPEvkuzn4MLB3ySdNgVwH8ccW5/gv2Pj9ctetnPUdUpu7KfX0qS5OA6/Zi0j2Q/vzeEEI08csXHSOe2A3j25Lu0viRJvpUkyf8mnZsP4MIQwq4hhy6wMn/YUbLApj9v1zGLSoyh/14TRkw4to7+PXw2SZLe6p3Zdf/DmNdezyeynxv5XcorvyfGs62/J7Jh+DdnD5824tC13v/+a/vNJEnWGsY9rddWkqSxGfBJknail4cQTl39ZAjh2aysqvmO/vNJkuxjZTXSXxlW5RVCeBbpxPkA/3vMfu3Pfn7biGP6q8Q+PIRwwpB+XAY8c8z213M9abhwHvArGzkhq2zpr6b6ayGEs0Ydn61EOpYQQjmEMOq/XQ4N/PuY1y7z6jUCt18mrZa7F/inMbs4aP/Av4/5LG5Q/7Pw6DX6/JPAhWNeez399/RZIYTHrd4ZQriI/A9T9HtiPNv6eyLz/2c/fyyEcEy1XTaMf62Ar//aPmRYpWYI4TGkFcOSJG0rBnySpJ3oBOC9IYTHwnIw9HxWhm42kyS5adU5vwYsARcDf5utTkkIYSGE8ELgL7LjPgi8d8x+fT77+W3ZBPnDvI+0SugM4PpsJUdCCCeGEH4ceDdwz5jtj5QkyReB/5k9/G8hhNeHEJZXswwhnBVCeHkI4X+tOrVOOnzxPNIVMi8PIZw4cN6uEMJLQggfIV3xc1znAV8KIbw6hPCYfvVQSD0J+MPsuFsYvrrqQdKKt7eEEM7Jzn1wCOHXSRfrAPhvSZIcGnLuZn2JlYqll4x5jf7n7NHAtf0wKoRwSgjhl4A/YEqfBeAvSVexjYD3hBC+ux8yhhCeBvwjKwt95JXfE2PIwfcEwBtI7/9U0vf4O7M2SiGE7wP+ipUgb7V/BQ6QVlC+Iwuz++/x80hf+9VDdiVJmjsDPknSTvRy4P8BPhNCuI/0j7F3kFbE3MyQwCVJko+SDvFcAr6HNEi6Nzu3P+H6p4EXjFi5c6QkSW4FbsgeviuEcG8IoZNtP5gd8yXgddkxPwR8PevHfuDNpOHVb4zT/gb9MvCn2b9fAXwthHBf1oe7SEO0xwyekCTJHuAy0lU1vwN4F3B/COHuEMJB0rnx/pR0eOxYr92AC4HfAT4LHA4h3E0aNN0EPBbYB1yxxnv0TeBVwI+Rvq57s+P7r+c7SBe12LJs2OTbsoevCyF8a+C9fuUGr/F+VqqefhbYF0LYl/X590gXV/jjSfR3SNuLpJ+/O0gDmX8CvhVC+BZwI+n8b7+49hVywe+J8W3r74kkSe4Gfpi0qvdi4OMhhP2k71OTNNz7rezww6vOvZeVysRLSRfu6Z/77uz4V2ylf5IkTYMBnyRpJ/o/wCWkQ+QOklZifBn4XeBJSZJ8c9hJSZJcT/rH4FtI/wg9kfSPuZuAVwLflSTJVifOfx5wbdafE0gnqr8AeNBAP34J+HHSedAOs7LQwq8BTwHu32If1pQkyVKSJC8lnWPqncDtWT+XgM+QBmDHBFRJknyadA67V5KGE/eSBiVLpBVJbwEuB/77Frp3O/Bc0uqhj5IGCaeQBnyfJl1F91FZCLPW/V0LfB/wz6SfiyOkr/NPAS8cNtfdFrycNES4mfQ97L/Xmxmy+0LSUPILWV8D6dxuPwfUSF/fqcgqtR4H/BFwG1AmXcDgTcATSD/Deeb3xJi2+fdEv60PAI8nfX/vIl1x+OvZtZ/ESoh475Bz/4D0u+bDpNV8ZeCrpMH647P7lSRpWwlj/s9FSZK2lRBChfQPMICHJUnSmVtntK2EEK4kC2OSJKnMtzeaJ78n1BdC+HPgR4G3JEny4/PujyRJW2UFnyRJkqTCyObV689vOIlFdSRJmjsDPkmSJEk7SgjhRSGE14QQHhlCKGfPnZgtlPHPpEOKb2VlxV1JknKtPO8OSJIkSdKEPRS4Ott62QIg30Y6VyGk8/I9P0mSI3PpnSRJE2bAJ0mSZi6EcMcmT/lIkiTPm0pnJG1LW/ye+CvgNNKVcHcBZ5AupvJl4O+B16+1kIokSXnkIhuSJGnmQgib/Q+QDyVJcuk0+iJpe/J7QpKkjTPgkyRJkiRJknLMIbqbFEJISiXXJpEkSZIkSZqHXq9HkiRh3v3YTgz4NqlUKtHtdufdjYnZs2cPu3btsq0ctbdT25p1e95b/tqadXs7ta1Zt+e95a+tWbe3U9uadXveW/7amnV7O7WtWbfnveWvrVm3t5PvbTsJIeycYGZCLEWTJEmSJEmScsyAT5IkSZIkScoxAz5JkiRJkiQpxwz4JEmSJEmSpBwz4JMkSZIkSZJyzIBPkiRJkiRJyjEDPkmSJEmSJCnHDPgkSZIkSZKkHDPgkyRJkiRJknLMgE+SJEmSJEnKMQM+SZIkSZIkKccM+CRJkiRJkqQcM+CTJEmSJEmScsyAT5IkSZIkScoxAz5JkiRJkiQpxwz4JEmSJEmSpBwz4JMkSZIkSZJyzIBPkiRJkiRJyjEDPkmSJEmSJCnHDPgkSZIkSZKkHDPgkyRJkiRJknLMgE+SJEmSJEnKMQM+SZIkSZIkKccM+CRJkiRJkqQcM+CTJEmSJEmScsyAr6Bu/IeP8N2vfCs3/sNH590VSZIkSZIkbYEBX0EdOHCIW044k3vvPzTvrkiSJEmSJGkLDPgKKiqlb323N+eOSJIkSZIkaUsM+AqqXE7f+qVeMueeSJIkSZIkaSsM+AqqHEWAAZ8kSZIkSVLeGfAV1EKUDdFNDPgkSZIkSZLyzICvoKJyWsHXtYJPkiRJkiQp1wz4Cqo/B5+LbEiSJEmSJOWbAV9B9efg61rAJ0mSJEmSlGsGfAW1UsFnwidJkiRJkpRnBnwFVS6XAVgy35MkSZIkSco1A76CWuhX8BnwSZIkSZIk5ZoBX0Etr6KbmPBJkiRJkiTlmQFfQS2UXWRDkiRJkiRpJyjPuwOaj34F31IS5twTSZIkSZKkyarUm9cCzwEuAB7fadQ+Xak3zwA+MHDYScB3AGd3GrW9lXrzhuz4+7L9b+00ar+fXe9s4HrgQuAB4Gc6jdqNM7mZDTDgK6iFhfStd4iuJEmSJEnagd4F/B7wL/0nOo3aPcDj+o8r9eargGd0GrW9A+f9QqdR++sh12sAN3Uate+t1JuXAH9VqTcf1mnUFqfT/c1xiG5BlZcDPiv4JEmSJEnSztJp1G7sNGq3rXPYS4E3b/CSzwf+OLv2x4CvA88Yv4eTZQVfQZUjV9GVJEmSJEnFVKk3nwKcBvzdql2NSr35W8DNwKs7jdpXsqG9C51G7Y6B4zrA+TPp7AZYwVdQ/Qq+JQM+SZIkSZKUL6UQwm0D21VjXOOlwPWdRm1p4LkXdRq1KvBY4MMcG/5tWwZ8BVWKIkq9Lr15d0SSJEmSJGlzekmSnDewXbOZkyv15oNIh9z+6eDznUZtT/Yz6TRqbwC+o1JvnpHN3bdUqTfPGbwMsHtLdzFBBnxFFUVESc85+CRJkiRJUtH8MPCZTqPW7j9RqTfLlXrzIQOPLwfuzMI9gHcCP53tuwR4KPCh2XV5NOfgK6hQKhElPZYw4JMkSZIkSTtLpd58I1ADzgHeW6k37+80ahdlu18K/H+rTjkeaFbqzeOBHnA38JyB/b8C/Fml3rwFOAJcsV1W0AUDvuLqV/CZ70mSJEmSpB2m06i9bMS+pwx57gDwxBHn3AlcNpneTZ5DdAsqlEpEvS5dK/gkSZIkSZJyzYCvqMrltILPgE+SJEmSJCnXDPgKKq3g67GUzLsnkiRJkiRJ2goDvgKLsIJPkiRJkiQp7wz4Cqzc69Ez4JMkSZIkSco1A74Cs4JPkiRJkiQp/wz4CixKeiwZ8EmSJEmSJOWaAV+BuYquJEmSJElS/hnwFVhEQjf4EZAkSZIkScqz8rw7MKhVjY8HXgd8D3AY+Ezcbl3RqsYPB94KnAncB1wZt1tfyM6Z+L6isIJPkiRJkiQp/7Zb+VYDSIBHxO3WY4BXZc+/EXhT3G49AngtcN3AOdPYVwgRiQGfJEmSJElSzm2bCr5WNT4ZeClwXtxuJQBxu3VHqxqfDTwRuCw79N3AG1rV+CJg/6T3xe3WrVO8zW2l7BBdSZIkSZKk3NtO6c6FwF7gV1vV+OOtavzhVjX+j8Au4Btxu7UEkIV/u4Hzp7SvMKLECj5JkiRJkqS82zYVfKR9uQC4OW636q1q/HjgfUBtnp0KIVwFXDXwmD179syxR5NTSroshdLM7mfv3r0zaWfWbc26vZ3a1qzb897y19as29upbc26Pe8tf23Nur2d2tas2/Pe8tfWrNvbqW3Nuj3vLX9tzbq9nXxv2t62U8C3G+gBbwOI261PtarxV0lDv3Nb1bgct1tLrWocSCvtdpMOtZ30vqMkSXINcE3/cRRFya5du6b2IsxSOQS6ocQs72entjXr9nZqW7Nuz3vLX1uzbm+ntjXr9ry3/LU16/Z2aluzbs97y19bs25vp7Y16/a8t/y1Nev2dvK9afvaNkN043brbuADpCvo0qrGDwMeBvwr8EngiuzQy4Hb4nbr1rjdumvS+6Z5j9tNmR69UCJJknl3RZIkSZIkSWPaThV8AD8NvLlVjV9LWs33srjdur1VjV8GXNeqxr9KWn33koFzprGvEKKQBnvdXkI5ci4+SZIkSZKkPNpWAV/cbn0FeOaQ578IPHmNcya+ryii7OdSL6EcjTxUkiRJkiRJ29S2GaKr2YtIK/iWeg7RlSRJkiRJyisDvgIrZwFft2vAJ0mSJEmSlFcGfAVWzqbdW+r15tsRSZIkSZIkjc2Ar8Ci5YDPCj5JkiRJkqS8MuArsLJz8EmSJEmSJOWeAV+B9Sv4nINPkiRJkiQpvwz4Csw5+CRJkiRJkvLPgK/AnINPkiRJkiQp/wz4CiwK2Rx8DtGVJEmSJEnKLQO+AiuHtISvawWfJEmSJElSbhnwFVh/iO6ic/BJkiRJkiTllgFfgS0vstE14JMkSZIkScorA74CK5eyIbqL3Tn3RJIkSZIkSeMy4Cuw5SG6XQM+SZIkSZKkvDLgK7B+Bd+SFXySJEmSJEm5ZcBXYP0KvqUlAz5JkiRJkqS8MuArsOUKPofoSpIkSZIk5ZYBX4FFIQv4rOCTJEmSJEnKLQO+AitH6c+lpd58OyJJkiRJkqSxGfAVWDk4RFeSJEmSJCnvDPgKLFqeg88KPkmSJEmSpLwy4CuwcpS+/UuLVvBJkiRJkiTllQFfgZWt4JMkSZIkSco9A74CWwn4rOCTJEmSJEnKKwO+AouiNODrWsEnSZIkSZKUWwZ8BVYupW//4pIBnyRJkiRJUl4Z8BXYcgVfL5lzTyRJkiRJkjQuA74CW8gq+JyDT5IkSZIkKb8M+AqsX8G31LWCT5IkSZIkKa8M+AqsXIoAWHKRDUmSJEmSpNwy4Cuw8kI2RNc5+CRJkiRJknLLgK/A+nPwda3gkyRJkiRJyi0DvgKLyv0KPgM+SZIkSZKkvDLgK7Dy8iq6DtGVJEmSJEnKKwO+AiuXnYNPkiRJkiQp7wz4Cqwcpavodg34JEmSJEmScsuAr8CiyAo+SZIkSZKkvDPgK7CFclrB5yIbkiRJkiRJ+WXAV2AhKlHqdema70mSJEmSJOWWAV+BhSgiSnoO0ZUkSZIkScoxA74iM+CTJEmSJEnKPQO+AutX8LmKriRJkiRJUn4Z8BVZqUTU67JkvidJkiRJkpRbBnwFZgWfJEmSJElS/hnwFVmpRNTrWcEnSZIkSZKUYwZ8Bba8iq4BnyRJkiRJUm4Z8BVZqUQ56TpEV5IkSZIkKccM+AosRBGlXo+u+Z4kSZIkSVJuGfAVWalElLiKriRJkiRJUp4Z8BVYKJcpJ1bwSZIkSZIk5ZkBX5G5iq4kSZIkSVLuGfAVWLqKbpfuvDsiSZIkSZKksZXn3QHNUalEKemxlIR590SSJEmSJGliKvXmtcBzgAuAx3catU9nz3eAB4BD2aG/22nU3pHtezjwVuBM4D7gyk6j9oX19m0HVvAVWIgiyr2uc/BJkiRJkqSd5l3AU4GvDdn3w51G7XHZ9o6B598IvKnTqD0CeC1w3Qb3zZ0BX5GVSkRJjy5W8EmSJEmSpJ2j06jd2GnUbtvo8ZV682zgicCfZ0+9G9hVqTcvGrVvkn3eCgO+Akvn4HORDUmSJEmSVCjXV+rNz1XqzTdX6s2zsud2Ad/oNGpLAJ1GLQF2A+evs29bMOArslJkBZ8kSZIkScqbUgjhtoHtqk2c+/ROo/ZY4AnA3aTz6uWeAV+BhahE1OvSJZAklvFJkiRJkqRc6CVJct7Ads1GT+w0aruzn4vA64GnZbv2AOdW6s0yQKXeDKQVervX2bctGPAVWVbBB9DtGfBJkiRJkqSdq1JvnlypN08deOqFwKcAOo3aXcAngSuyfZcDt3UatVtH7ZtNz9dXnncHND+hvBLwLfUSytGcOyRJkiRJkjQBlXrzjUANOAd4b6XevB+4DHh3pd6MgAB8BXjxwGkvA66r1Ju/CuwHXrLBfXNnwFdkpRJRbyXgkyRJkiRJ2gk6jdrL1tj1+BHnfBF48mb3bQcO0S2wdBXdLgDdrgGfJEmSJElSHhnwFVkpGqjg6825M5IkSZIkSRqHAV+Bhai0XMHnEF1JkiRJkqR8MuArsujoRTYkSZIkSZKUPwZ8BRYGFtlwDj5JkiRJkqR8MuArsoFFNpyDT5IkSZIkKZ8M+AoshECUpJV7DtGVJEmSJEnKJwO+giuTBXwO0ZUkSZIkScolA76Ci8jm4LOCT5IkSZIkKZcM+AqulFXwLToHnyRJkiRJUi4Z8BVclP20gk+SJEmSJCmfDPgKrhycg0+SJEmSJCnPDPgKLsqG6FrBJ0mSJEmSlE8GfAUXOQefJEmSJElSrhnwFdzyHHwO0ZUkSZIkScolA76CK5NW7i05RFeSJEmSJCmXDPgKLgoBcA4+SZIkSZKkvDLgK7hSfxVd5+CTJEmSJEnKJQO+govSAj6WnINPkiRJkiQpl8rz7sCgVjXuAA8Ah7Knfjdut97RqsYPB94KnAncB1wZt1tfyM6Z+L4iWcgCPofoSpIkSZIk5dN2rOD74bjdely2vSN77o3Am+J26xHAa4HrBo6fxr7CKNEfomvAJ0mSJEmSlEfbqoJvmFY1Pht4InBZ9tS7gTe0qvFFwP5J74vbrXmQOekAACAASURBVFunfEvbyvIQXefgkyRJkiRJyqXtWMF3fasaf65Vjd/cqsZnAbuAb8Tt1hJA3G4lwG7g/CntK5Syc/BJkiRJkiTl2nar4Ht63G7tblXjBeC3SefI+7V5diiEcBVw1cBj9uzZM8ceTVivC8A9e/exZ890Pw579+6d6vXn1das29upbc26Pe8tf23Nur2d2tas2/Pe8tfWrNvbqW3Nuj3vLX9tzbq9ndrWrNvz3vLX1qzb28n3pu1tWwV8cbu1O/u52KrGrwe+BOwBzm1V43Lcbi21qnEgrbTbTTrUdtL7jpIkyTXANf3HURQlu3btmt6LMGOfLkcAnHzKKczivmb52s36fdqp9+brmM/2dmpbs25vp7Y16/a8t/y1Nev2dmpbs27Pe8tfW7Nub6e2Nev2vLf8tTXr9nbyvWn72jZDdFvV+ORWNT514KkXAp+K2627gE8CV2TPXw7cFrdbt05j37Tub7uKQjpGt+sQXUmSJEmSpFzaThV8DwHe3arGERCArwAvzva9DLiuVY1/lbT67iUD501jX2GUs4jXVXQlSZIkSZLyadsEfHG79RXg8Wvs+yLw5FntK5L+KrpdAz5JkiRJkqRc2jZDdDUf/SG6i73enHsiSZIkSZKkcRjwFVyUfQKcg0+SJEmSJCmfDPgKzjn4JEmSJEmS8s2Ar+BK/VV0DfgkSZIkSZJyyYCv4KJSGvAtOQefJEmSJElSLhnwFVw5q+Bb6hrwSZIkSZIk5ZEBX8Etz8G3ZMAnSZIkSZKURwZ8BRdly+hawSdJkiRJkpRPBnwFtzwHnwGfJEmSJElSLhnwFVyISpR6XQM+SZIkSZKknDLgK7pSiSjp0TXgkyRJkiRJyiUDvqIrRURJj8WeAZ8kSZIkSVIeGfAVXFiu4Evm3RVJkiRJkiSNwYCv6Eolol6XJSv4JEmSJEmScsmAr+giK/gkSZIkSZLyzICv6Eolol6PxZ4BnyRJkiRJUh4Z8BVdtsiGq+hKkiRJkiTlkwFf0UUlykmXJSv4JEmSJEmScsmAr+hKEaVej64BnyRJkiRJUi4Z8BVcKJWIkq5z8EmSJEmSJOWUAV/RlbJVdA34JEmSJEmScsmAr+iiEmWH6EqSJEmSJOWWAV/RZUN0lxIDPkmSJEmSpDwy4Cu6UolS0mOpN++OSJIkSZIkaRwGfEVXiij3ug7RlSRJkiRJyikDvqLLFtlYMt+TJEmSJEnKJQO+ggtRlAZ8VvBJkiRJkiTlkgFf0UVpBV/XfE+SJEmSJCmXDPiKrlQi6nXpJpC4kq4kSZIkSVLuGPAVXTYHH+BCG5IkSZIkSTlkwFd0AwGf8/BJkiRJkiTljwFf0ZUiop4BnyRJkiRJUl4Z8BVdVCJKugB0XWlDkiRJkiQpdwz4Ci6USgMVfL0590aSJEmSJEmbZcBXdKWVCj6H6EqSJEmSJOWPAV/RuciGJEmSJElSrhnwFV20ssiGc/BJkiRJkiTljwFf0R01RNc5+CRJkiRJkvLGgK/oStFMhujeuf8w+w8vTe36kiRJkiRJRWXAV3TRwBx8Uxyi+8I33cTvffC2qV1fkiRJkiSpqMrz7oDmK5RKlHvpEN3ulCr4er2Ezj0HOKl80lSuL0mSJEmSVGRW8BVdqUQpq+BbnNIcfPsPL9JLphcgSpIkSZIkFZkVfEVXWhmiO60Abu+BI+n1zfckSZIkSdIMVOrNa4HnABcAj+80ap+u1JsnAH8BPAo4BNwFvLzTqN2anXNDdvx92WXe2mnUfj/bdzZwPXAh8ADwM51G7cbZ3dFoVvAVXSlaHqI7rTn49h1MA75pLuIhSZIkSZI04F3AU4GvrXr+TcAjO43axcDfAH+yav8vdBq1x2Xb7w883wBu6jRqDwdeAry9Um8uTKnvm2YFX9FFs6jgW5zq9SVJkiRJkgb1q+sq9ebgc4eBvx847CbgVRu85POBi7LrfKxSb34deAbw/kn0d6sM+IouipYDvmnNwbevP0TXgE+SJEmSJG0fryCt4hvUqNSbvwXcDLy606h9pVJvngEsdBq1OwaO6wDnz6ab63OIbsGFUolSFux1pzxE1zn4JEmSJEnSBJRCCLcNbFdt9gKVevNXSSvyXj3w9Is6jVoVeCzwYeDvJtPd6TPgK7pSiXKSzcE3rSG6B63gkyRJkiRJE9NLkuS8ge2azZxcqTdfBTwPeFanUTvYf77TqO3JfiadRu0NwHdU6s0zOo3aPcBSpd48Z/AywO4t38mEGPAVXalE1JvuHHz9IbousiFJkiRJkuapUm9eBbwQ+O5Oo3bvwPPlSr35kIHHlwN3ZuEewDuBn872XQI8FPjQzDq+DufgK7pSiWi5gm86c/C5yIYkSZIkSZqlSr35RqAGnAO8t1Jv3g9cCrwO+ArwwWwBjgc6jdqTgOOBZqXePB7oAXcDzxm45K8Af1apN28BjgBXdBq1xRndzroM+IpuYJGNJefgkyRJkiRJO0CnUXvZGrvCGscfAJ444np3ApdNoGtT4RDdopvhEN1pLeIhSZIkSZJUZAZ8RXfUEN0pL7KRGPBJkiRJkiRNmgFfwYVSaWWI7hTm4Fvq9rjvkHPwSZIkSZIkTYsBX9FNeQ6++w4t0i/c6yaQWMUnSZIkSZI0UQZ8RVcqEfXSIbrTqLDrL7DRN61hwJIkSZIkSUVlwFd0A0N0F6cwRHfvgaNXjHaYriRJkiRJ0mQZ8BXdwBDdaaxyuzdbQfe4KP2oWcEnSZIkSZI0WQZ8RVcqUe5NbxXd/hDdsx58PDCdEFGSJEmSJKnIDPiKbmCI7jSGz/Yr+M7MAr5pDAOWJEmSJEkqMgO+ggulEqXe9Obgu7dfwfegrILPIbqSJEmSJEkTZcAnsunxpjQHX7rIxtmnpAGfc/BJkiRJkiRNlgGfWCAN3aY1B99x5RIPPqGcttF1iK4kSZIkSdIkGfCJqBSA6c3Bd/pJx7FQchVdSZIkSZKkaTDgE1FIA76lKczBt+/gEU47+biphoiSJEmSJElFZsCn5Tn4lqYyB98RTj95gYUoTK0NSZIkSZKkIjPgEwtp9jbx6rrFbo/7Dy9x2knHES0P0XUOPkmSJEmSpEkqb+XkVjX+duCZwEOBE9Y4LInbrd/aSjuarv7w2UnPj7fv4BEATj/5OMpTakOSJEmSJCkvKvXmhrK0TqO2qSxt7ICvVY2vAX4WiLKnwurOZM8lgAHfNpaNnp14dd2+A4sAWQWfc/BJkiRJkqTiqtSbU8vSxgr4WtX4KuCVWYPvBVrA/nGupfkrRRGlpDfx+fH2Hlip4Cv1Q0Tn4JMkSZIkSQVTqTenmqWNW8H3UmAJuCxut26YVGc0H6FUIkp6E6+u6w/RPfWkBQ480AWcg0+SJEmSJBXScpbWadRumPTFx11k40LgXwz3dogoIiJhccIB32AFn3PwSZIkSZKkArsQ+JdphHswfsB3P/CNSXZE87NSwTfpOfjSgO+0k46jnE3013WIriRJkiRJKp6pZmnjBnwfBi6eZEc0R+Uy5WnMwTewiu60VuqVJEmSJEnKgalmaeMGfL8JXNSqxj8xyc5oPqY1B9+9B1dW0S2X0o+ac/BJkiRJkqQC+k3gokq9OZUsbdxFNk4BrgHe2KrGlwF/B+wGhqY3cbt145jtaBaiiCjpTWUOvhMXIk48Llqu4Jt0iChJkiRJkpQDy1lapd5cN0vrNGqbytLGDfhuIF3WNwCXZ9taki20oxmY2hx8B49w+snHAbCQzcE36WHAkiRJkiRJOXADU8zSxg3ebswa004QRUS97uTn4DtwhNNOXkibsIJPkiRJkiQV11SztLECvrjdunTC/dAcTWsOvn0HjvCwM08GWJ6Db9E5+CRJkiRJUsF0GrVLp3n9bTl0tlWNXwL8KfADcbv1161qfDZwPXAh8ADwM/15/aaxr3CyOfgmucLt4cUuB450l4foWsEnSZIkSZI0HeOuojs1rWpcAX4SuGng6QZwU9xuPRx4CfD2VjVemOK+QgmlElGvN9EVbgdX0AXn4JMkSZIkSZqWDVXwtarx+dk/b4/bre7A4w2J263dG2ynBPwJ8HPA6wZ2PR+4KLvWx1rV+OvAM4D3T2lfsUQRUdKlO8Hwbe+BIwBW8EmSJEmSpMKp1JvLWVqnUesOPN6QTqO2oSytb6NDdDuky/Y+CvhS9nijSc1mVv64CvjXuN36RKsaA9CqxmcAC3G7dceq/pw/jX0b7OeOEqJSusjGBMO3fQfTgO+0LOBzDj5JkiRJklQgHWaTpcEmDt6dXXxx1eOJaVXjR5MuEfz0SV53q0IIV5EGj/3H7NmzZ449mqy9e/dy4uIipXKXBxaXJnZvt+y+F4Dk0H727NnD3XcfStvbd+9MXr+9e/dOvY15tbdT25p1e95b/tqadXs7ta1Zt+e95a+tWbe3U9uadXveW/7amnV7O7WtWbfnveWvrVm3t5PvTZs29Sxt0IYCvrjdqox6PCFPAyrALVn13jnAm4DXAEutanzOQMVdBdgdt1v3tKrxRPet7lSSJNcA1/QfR1GU7Nq1a2I3vS2cdDLlbo+EwKTurXRbF4CLzj+XXbvO5PBx9wO3cPKDTplYG+uZ9fs0y/Z2aluzbs97y19bs25vp7Y16/a8t/y1Nev2dmpbs27Pe8tfW7Nub6e2Nev2vLf8tTXr9nbyvWnjOo1aZdTjSds2i2zE7dYfxe3WuXG7VckCxJuAn4rbrT8C3gn8NECrGl8CPBT4UHbqNPYVSxQR9ZYmOj/eWnPwTXIhD0mSJEmSJG1yPO8c/QrwZ61qfAtwBLgibrcWp7ivUPpz8C1Ocg6+LODrr6Lbn4NvkvP8SZIkSZIkaRsHfHG7denAv+8ELlvjuInvK5xSRJT0JlvBdzDNSk89aQGAKMpW0Z3gSr2SJEmSJEnaQsDXqsYLwM8DPwQ8EjhljUOTuN3atkGiVir4ur2EJEkIIWz5mvcePMKDji9zfDkCYGF5iK4BnyRJkiRJKp5KvbnhLK3TqE1lFd2jtKrx8cAHgCcD66VBW0+LNF1ZBR9At5dQjrb+lu09cITTTl5YfuwcfJIkSZIkqagq9eZUs7RxF9l4BfAU4J9IE8frSZf6PR54NPBa4AHgt+J2a9ss5KHhQlRaDvgmVWG378ARTs/m34OVOfgmOQxYkiRJkiQpJzacpXUatU1naeOGbz8E3A+8IG63bsk6RNxuLcbt1s1xu/Vq4PnAf21V4x8csw3NSiki6k024Nt78AinnbwS8PXn4FtyDj5JkiRJklQ8y1lap1FbztI6jdpip1G7udOoLWdplXpz01nauAHfI4B/i9ut+7LHCUCrGkf9A+J26z3Ap4CfG7MNzUgoR0RJF5jMIhiHjnQ5vNhbVcGXLbJhBZ8kSZIkSSqeRwD/1mnUjsrSKvXmcpbWadTGztLGDfgWgG8OPD6U/Vw9OeAXgceM2YZm5agKvq3Pkbf34BGAoyr4+gHfogGfJEmSJEkqnqlmaeMGfHcA5w48/kb2M1513LcDEdrW0jn40gq+SQzR3XcgDfhOHxyiu1zB5yIbkiRJkiSpcKaapY0b8LWAiwYef4R0hY9fblXjEkCrGj8DeBpp8qjtbGAV3UkEfHuzgO+0gSG6IQSiknPwSZIkSZKkQlozS6vUmyWASr05dpY2bsD3XuC8VjX+d9njG4Cbgf8E3N6qxp8A3pd19A/HbEMzEqLS8hDdSczBt+9gv4Jv4ajnoxCcg0+SJEmSJBXRe4HzKvXm0CytUm9uKUsbN+B7O/Ai4D6AuN3qAd8PfB54CPD4rEPXxu3WdWO2oVkpRQNDdCcwB9+QCj5Ih+k6B58kSZIkSSqgo7K0TqO2ZpbWadSu2+zFy+P0KG637gbetuq5W4GLW9X4kcDpwJfiduueca6v2Urn4JvcEN1hc/BBGvA5B58kSZIkSSqaTqN2TJbWadRuBS6u1JvLWVqnURsrSxsr4Bslbreccy9vBufgm8AQ3WGr6AKUnYNPkiRJkiTpKJ1GbctZ2rhDdLWTRCXKvXSI7iTmyNt3YBGAU090Dj5JkiRJkqRpG6uCr1WNX7zBQ48AdwOfjNutveO0pekLUZlSVsG3OKE5+E45oUw5Ojo/dg4+SZIkSZJURJV6c9NZWqdR23CWNu4Q3euAzSQ1vVY1fg/wc3G7dfuYbWpKBufgm0gF38Ejx8y/B87BJ0mSJEmSCus6NpmlVerN9wA/12nU1s3Sxh2iez3wN6SrewB8Fvjb7LnPDBz3HuCDwH7SlUE+3KrGp43ZpqalFC0P0Z3EHHn7Dh45Zv49cA4+SZIkSZJUWGNnaZV6c90sbdwKvlcANwH/Arw8bre+MLizVY0fBfwRUAW+izShvB54NvALwK+P2a6mYJIVfEmSsO/AIo/+9m87Zp9z8EmSJEmSpII6KkvrNGpHZWmVenNLWdq4FXxXA2cBz14d7gHE7dbNwHOAM4HfiNut+4CfAA4A/2nMNjUtA6vobnUOvgNHuhzp9oZW8EWlwJIBnyRJkiRJKp6rybK01eEeQKdROypL6zRqm8rSxg34fgD4UNxu7V/rgCzU+xDw3OzxN4FPAReO2aamJEQlSlmw193iENp9B44ArDkH35Jz8EmSJEmSpOL5AeBDnUZtzSwtC/WWs7ROo7bhLG3cgO8cYCNJTQI8ZODx7cCxyY/mqxRRTrI5+LZYYbc3C/hOO2nYHHxhywGiJEmSJElSDk01Sxs34LsTuLRVjR+01gHZvmcAdw08fQawb8w2NS1Riag3mTn49h7sV/AtDGuGRYfoSpIkSZKk4rkTuLRSb66ZpWX7xsrSxg34/iZr4K9b1fjhq3e2qvFFwF8Bp2fH9sXAl8dsU1MSShHRcgXf1obQ9ofonjqkgs9FNiRJkiRJUkEtZ2mVevOYLK1Sb24pSxt3Fd2rge8D/gNwc6safxLokJYRVoDvBCLgq8BvALSq8SXAecBbxmxT0zKwiu7SkCG0vV7CR758D0+58AxKpXDM/kEHHlgC4MHHH/vRikqBpa5z8EmSJEmSpMK5moEsrVJvrpulVerNDWdpYwV8cbu1t1WNnwr8IenEf5dkW18C/C3w8rjduic752OMXzGoKQpReeQQ3X9u38VPXP9xrnvJJVz6yLNHXuvwYnqdE46LjtlXLlnBJ0mSJEmSiqfTqO2t1JsbytI6jdo92TkbztLGreAjbrfuAJ7XqsbnA08jTRQhnfzvw3G79bVxr63ZClFpYIjusQHcHfsPA3DPt46se63Di+l1TigfG/A5B58kSZIkSSqqTqN2B/C8Sr05NEvrNGpjZ2ljB3x9cbu1G3jbRo9vVePnAhfH7dZvbrVtTUgpWhmiO2QOvv2HFwE4vNRd91KH+gHfwrEBs3PwSZIkSZKkous0apvK0ir15nOBizuN2ppZ2jyGzH4/8Jo5tKs1hHXm4Nt/KJ1Xrz/8dpTlIboLwyr40oAvSQz5JEmSJEmSNmjdLM058ZRW8PXSyrthFXbLFXyL61fw9av8hgV85WyBDqv4JEmSJEmSJseAT0etors4bIjuoU0EfKOG6GZPDZvnT5IkSZIkSeMx4BMhWpmDrztsiO7h/hDd9QO+B/pDdIctshHSCj4DPkmSJEmSpMkx4BOUSkS9/iIbw+bgSyv4Dm0g4Du02OW4colSNhx30PIQ3SEhoiRJkiRJksZjwCdCFFFONjIH30YW2ehyQnn4xyoq9Sv41r+OJEmSJEmSNqY87w5o/kIUUeqtPQff/ZsYont4sTt0gQ1wDj5JkiRJkjQblXrzWuA5wAXA4zuN2qez5x8OvBU4E7gPuLLTqH1hK/u2Ayv4lK6iO2oOvkObqeDrrR3wOQefJEmSJEmajXcBTwW+tur5NwJv6jRqjwBeC1w3gX1zZwWfCFFpeYju6vDt8GKXB5Z6y/9ez+GlLieuEfCVI+fgkyRJkiRJ09dp1G4EqNSby89V6s2zgScCl2VPvRt4Q6XevAjYP86+TqN265RvZUOs4BNE0fIiG6vn4OsPz4WNr6J7wsIac/AF5+CTJEmSJElzswv4RqdRWwLoNGoJsBs4fwv7toV5BHwh27RNhFKJaLmC7+jwrb/ABqTVees5tNjleOfgkyRJkiRJ01MKIdw2sF017w5N2bpZ2kSG6Laq8XHAGcADcbu1d9Sxcbt1JXDlJNrVhEQRpWwOvqVVw2f78+/BJlbRXTPgC0PbkCRJkiRJ2oRekiTnjXHeHuDcSr1Z7jRqS5V6M5BW4e0mHYY7zr6xVOrN5Syt06iNzNI6jdqVrJOlbamCr1WNr2hV448CB4DbgP8xsO8HWtX47a1q/LCttKEZKJUo99LqvNVDdPcPDNE9dGR0BV+SJGnAVx7+sSpnAd/qNiRJkiRJkqat06jdBXwSuCJ76nLgtk6jduu4+zbbh0q9eUWl3hyapVXqzR+o1Jtvr9Sbm87Sxg74WtX4T0iXB34icIhjSwW/BLyA9Ka1jYVoZRXd1cNnByv4HlhniO5iN6GXsIFVdJ2DT5IkSZIkTU+l3nxjpd68DTgPeG+l3uyHcS8DXlapN78E1IGXDJw27r6N9mlqWdpYQ3Rb1fhHgR8HPpf9/CRwVPoTt1tfaFXj24BnMZBGahsqlSglabC31hx8USmsO0S3P0ffWqvoLg/RtYJPkiRJkiRNUadRe9kaz38RePIk921Epd5cN0vrNGpfyELJTWdp487B91PAt4Bnx+3WHoBWNR523OeAoTu0fYQookRCiWTIHHzpEN0zH3Qc93zryMjr9FfZXXMV3f4iG87BJ0mSJEmSimU5S+s0ansAKvXmsOPGytLGHaJ7MfBv/XBvhL3AQ8ZsQzMSorTirkwyZA6+tILv7AefwFIvYbG7dhXf4SPpvrWG6DoHnyRJkiRJKqiLgX/rh3sjjJWljRvwHQ/ct4HjzmJVuaG2oSzgi4DFVeHb/VnA95BTjgdWqvSG6Q/RPX6dOfgWnYNPkiRJkiQVy1SztHEDvttZp1ywVY0D8Cjgq2O2oRkJpfRjEJHQXT0HXzZE96wH9wO+ERV86w7RzSr4HKIrSZIkSZKKZd0srVJvjp2ljRvwfQCotqrxc0cc8yLSlUreN2YbmpV+BV8YMgff4UVOXIh40PHpdI0jK/iy8G/tRTbSny6yIUmSJEmSCuYDQLVSb04lSxt3kY3/kTX69lY1/i/AX/Z3tKrx6cDzs2MOANeO2YZmJavgGzoH36FFTjmxvBzajQ74+hV8zsEnSZIkSZI0YDlLq9SbR2VplXpzy1naWBV8cbt1C/Bj2fmvA/YASfbcN4E/IA0Pr4zbrd3jtKHZCctz8CXHzMG3//ASp5ywsDyv3qghuoc2OER3yTn4JEmSJElSgXQatQ1naZ1GbdNZ2rhDdInbrXcClwDvBO4HQrYdBt4DPDlut9497vU1Q/05+JJhc/AtcsqJC8tVef2FNIZZruArj15kY/UwYEmSJEmSpJ2u06itm6V1GrWxsrRxh+gCELdbnwdekC2ocQZpYHh33G5ZopUj/Qq+Mr2hc/CdckJ5uSrv0JG1A74Hsuq+tYbo9ufgc4iuJEmSJEkqok6j9nngBdmCGstZWqdR21KWtqWAry9utxLg7klcS3NQWhmiOxi+PbDU5fBij1NOXNjYHHxZdd/xawzRLS8P0TXgkyRJkiRJxdVp1CaapY0V8LWq8WnAY4Avx+3W7Wsc81DgQuCzcbt17/hd1LSFbEhtlPSOCt/uP7wEwCknDA7RXTtQ7od/a6+i6xx8kiRJkiSpeCr15nKW1mnUhmZplXpzOUvrNGqbytLGnYPvFcAHgXNHHHNudsx/HrMNzUjoz8FHclT4tv/QIgCnnLgyRHf0KrrrDNF1Dj5JkiRJklRMU83Sxg34vg/4StxufXytA7J9XwWePWYbmpVopYKvOxC+7c8q+B48WME3IuBbWUV3dAWfc/BJkvR/2bvzMEnuu87zn8jIs+7qQ+qWulspWZYzZBtbtgyI4TAwgHdrhmGMOR/AsPA8zMHAoIWhHvaZZ9Yww5bZwTs2LAPssmsbGPDjY/AMhTE7YGMuD7ZsCWNnypLVqa5Wn3VfeWfsHxGRR1UekVEZWdf79Tz1dFdmVP4iS9n64/N8DwAAAJwy/6OkF/ILc12zNPe5QFla0IAvLelZH9flJD0Y8AyMilvBF93XoutW8PkM+BpbdLvO4HP+ZAYfAAAAAAA4ZdIKMUsLGvBNSdrwcd2mpJmAZ2BEDMOQIhFFZLeFb5sFdwZfKqpk1Av4es3gc1t0o31m8NWYwQcAAAAAAE6VULO0oAHfXUkZH9e9QtJqwDMwSqbpLNloCd822yr4nI9KoUcFX6lfi67BFl0AAAAAAHAqhZqlBQ34PinptdmM9bXdLshmrK+R9Jh7LY44IxJR1K63zcdrLtmIKRX30aJbdZ5LRDt/rEyTGXwAAAAAAOBU+qSk16bnF7tmaen5xcBZWtCA7z9KMiR9IJux/tHeJ93HPiDJlvRrAc/AKLkVfJXWgK9RweevRbdQrikRjSjituLuFXUfpoIPAAAAAACcMo0sLT2/uC9Lcx8LnKVFg9yRlcv+aTZj/YqkH5P0oWzGWlZzUOAjks67N/0frVz2j4OcgdEyIhGZ9dqeCj5vBl9zyUap55KNetf2XIkZfAAAAAAA4HTKL8z9aXp+sZGlpecXu2Zp+YW5gbO0oBV8snLZH5f0E5JW3Jv4avfrHvexn7Ry2X8e9PUxWoZbwVer27JtJ+TzKvgmk9FG222vGXzFaq3rBl2pJeCjgg8AAAAAAJwy+YW5vllafmEuUJYWOOCTJCuX/WVJFyV9paTvcr+ekHTRymXfeZDXxoi5AZ/UnJG3WagoGYsoETUViRhKRCO9Z/D5rOBjBh8AAAAAADiN8gtzXbO0/MJc4CwtUItuKyuXrUn6G/cLx5UZkVl3Ar5q3VbUlDaLVU0lY41LkjGz0AliLAAAIABJREFU5wy+UqWmVI+ArzmDjxZdAAAAAABwOuUX5oaepR2ogg8nhxExZdpOdV61pYJvMtnMgJOxSGNTbifFSk0JXzP4qOADAAAAAAAYlgNV8GUz1n2Svl7S/ZKSXS6zrVz25w9yDkbAdJZsSFKt1pzBd99MqnFJKmaqUO4e8BUqNSWj/Wfw0aILAAAAAABOo/T8oq8sLb8wN1CWFjjgy2asd8jZ/OGVbBl7b8Z9zJZEwHfEORV8Xouu8+dWhxbdUrV7e63vLboEfAAAAAAA4JRJzy+GlqUFCviyGetJSf/SPfCjkrKSNoO8Fo6Ilgq+at1WpVbXbrmmqVQz4EvETG0UKh1/3Lbt/lt0mcEHAAAAAABOofT8YqhZWtAKvh+WVJX0zVYu+/Fh3QwOjxEx2wK+rWJVkjTVOoOvxxbdcq0u21bPCj7DMGRGDGbwAQAAAACA06aRpeUX5j4+7BcPGvC9TNJfEO6dIHtm8G1WnUq91gq+VNxUoUvA523X7bVF1znGYAYfAAAAAAA4bV4m6S/CCPek4AHflqSbw7wRHK72Cr66tkteBV/LDL6oqWKlLtu2ZRjtbeJeZV+vCj5JikUMZvABAAAAAIDTJtQsrfvAtN7+XNJrhnkjOGTR9hbdzYIb8KVaWnTd+XqdFm14AV+ixww+yangYwYfAAAAAAA4ZULN0oIGfD8n6eFsxvqRYd4MDo8RMRXxAr6arc2i26K7Z4uupI5z+LwW3WS0dwVf1Iwwgw8AAAAAAJw2Pyfp4fT8YihZWtAW3SlJ75D069mM9c2S/kDSNUkdS7OsXPYTAc/BqJgRRWtO1V6tbmuzsH8GXzPg617B169Flxl8AAAAAADgFGpkaen5xb5ZWn5hbqAsLWjA93E5a30NSd/ufnVjH+AcjEhrBV+lXm9U8E22btHtWcHnPJbq06LLDD4AAAAAAHAKfVwhZmlBg7dPuIfhpDAjMqvuFt3WGXxtLbpOeFesdgj43Ll8fSv4TGbwAQAAAACAUyfULC1QwGflsm8c8n3gkBkRU6bbots2g69lyUbKDe8K5f0Bn/dYv4AvGmEGHwAAAAAAOF3yC3NvDPP1gy7ZwEljRhpbdGt1W1vFThV83WfwlapewNf7IxVlBh8AAAAAAMBQEfBBUnsFX6Ve12ahong00laR17NF153Bl2DJBgAAAAAAwEgdePlFNmONS3pYzjYQo9M1bNE9BsyIIjWnLbfmtui2Vu9JzQq+UsclG+4MvmifFl3T0E6ZGXwAAAAAAOB0Ss8v9s3SRrVFV9mM9ZCkd0p6k3pXArJF9xgwzKjMWkGSVHWXbLTO35OaAV+h1xbdeL8KvohqzOADAAAAAACnTHp+MbQsLVDwls1YFyX9taTzkm64r3OP+9jLJZ1zb+avJVUGeN0/lnRBUl3SlqQft3LZz2Yz1sslvcd93Q1JP2jlsp93f2boz51KZqTRolurOxV8904l2y7pNYOvUcHXZwZfLGKoSosuAAAAAAA4RdLzi6FkaZ6gM/jm3Rv6BSuXvSTpI5JsK5f9e1Yue4+k/0HSi5IKkr5pgNf9TiuX/TIrl32tpHdIerf7+K9L+g0rl31E0ttbHg/ruVOnbYuuO4NvKrWnRTfqzuDrUMHnVfX1a9FlBh8AAAAAADiFGllafmGukaXlF+b+Xn5h7iBZmqTgAd+3SHpJ0r/p9KSVy37UvbGvlfQ/+31RK5ddb/l2WpKdzVj3SHpc0m+7j39Q0uVsxno4jOf83uuJY0Zk2k4VXqlS1065pqlke4Gn137bq0U32WfJRtQ0VKkxgw8AAAAAAJwqPbO0/MJcoCzNEzTguyLpaSuX9ZKeuiRlM1YjEbJy2Wcl/bmk7x3khbMZ673ZjLUk6eclfb+ky5JuWrls1X1dW9I19x7CeO5UMiKmzLoTvK3tliVJk12WbHRq0S1VvYCv90fKjESo4AMAAAAAAKfNFUlP5xfm2rK09PxiI0vLL8wFytKk4MsvKpJ2Wr73/n5O0q2Wx+9I+opBXtjKZX9AkrIZ661yWmf/dcB7HArDMJ6U9GTL91paWjrEOxqu1dVVSVKxWJRpO5+xF2+tSJKMSqHtva5tlCRJd1fX9/0OVta3JEnLt29qK9o55FtdXVW1XFSlVg/9d+i9r1EZ5Xkn9axRn8d7O35njfq8k3rWqM/jvR2/s0Z93kk9a9Tn8d6O31mjPu+knjXq83hvx++sUZ93kt8bDiy0LE0KHvDdkFMF57nq/vm4pD9oefyVknaDHGDlsu/JZqxfk3Rd0sVsxopauWw1m7EMOannNUmbITzXxrbtd8iZByhJMk3Tvnz58t7LjrXLly/rxuRko0W3EklIku6/54xa32tiuijpWcWTY9r7OzDjd2QY0svSV2QYHTc8S5Imxiqq2dv7fj4Mo/7vNMrzTupZoz6P93b8zhr1eSf1rFGfx3s7fmeN+ryTetaoz+O9Hb+zRn3eST1r1Ofx3o7fWaM+7yS/NxxIqFla0BbdpyRZLS25fyLJkLSQzVivzGasyWzG+llJr5b0jJ8XzGasmWzGuq/l+2+TtCInufyMpO9zn/p2SdetXPZ5K5cd+nOD/RpOkJYZfF6L7r4lGz1m8BUqNSWikZ7hnuTM4KvVbdk2bboAAAAAAODUeEqS1dKS28jS0vOLr0zPL06m5xcHytJaBQ34/kjSjKQ3SZKVy/6tpN+X9Kikv5W0LmeGXl3S23y+5rSk389mrM9lM9Yzkn5M0j9w5+P9qKQfzWasL8rZOvJDLT8XxnOnjjODzwnu1nadbcx7l2x4G3I7zeArVmp9F2xIzgw+SczhAwAAAAAAp0lblpZfmBtGltYQtEX39yR9TNJGy2PfJ2lB0ndIOiMpK+ltVi77l35e0MplX5T05V2ee1bSE6N67lRqqeBb3elcwRczDUWM5sbcVsVKvREA9hKLOBV+1botH5cDAAAAAACcBL6ztPzCnK8srVWggM/dPvvSnsd2Jf24+4VjxjCj+wO+PVt0DcNQMmaqWO1Wwde/INRsCfgAAAAAAABOg/zC3L4sLb8wN7QsLVCLbjZjXclmrDM+rpvNZqwrQc7AiJkRmXUnuNsoOC2606n9+W8qZqpY3l/BV6rWfbXoRk0n4KvVCPgAAAAAAMDpkJ5fvJKeX+ybpaXnF2fT84sDZ2lBZ/BdlfS/+7juFyW9EPAMjJARMRW124O7vRV8ktwKvk4tun5n8HkVfPurAAEAAAAAAE6oULO0oAGf4X75vRZHnRlRZE/oNtkh4EvEIh1n8BV8tuhGWbIBAAAAAABOn1CztKABn1+Tksohn4EhMCJmYwaf5CzU6BTYpWKmCh2XbPir4Iu6FXwVAj4AAAAAAIC9AmVpQbfo9pTNWBFJr5T0DZKuhXEGhsyMyGxp0Z1KxmQY+wPjZMzUna1S22O2bfveomsygw8AAAAAAKBNen7xQFma74Avm7H2lm29NZux3urjR39zsFvCYTAipqItLbpTqf3tuZKU7NCiW3K36qbi/iv4mMEHAAAAAABOsvT84r4sLT2/GEqWNkgFX2s5l63e/cAVSdclfVDSvxn0pnAI9lXwdf5oJKOmSpX2cM77nhl8AAAAAAAADSPL0nwHfFYu20hvshmrLundVi77Pw16II4mwzQVsX1U8MVNlWt11ep2YyOuN5Mv4aNFtzGDjxZdAAAAAABwguUX5hpZWnp+sS7p3fmFuVCytKAz+N4m6bPDvBEcMtNUtN4+g68Tb85esVLTeCLa+LskX0s2GjP4qOADAAAAAACnR6hZWtAtum+U9JYh3gcO2d4tulOpLi26bhtu6xy+YrXW9lwvMbdFlxl8AAAAAADgFHmjQszSggZ8T0iKD/NGcMjMiCJ2s6quawWfW6VXrDYDumJjBp+PCr4IFXwAAAAAAODUCTVLCxrwXZeUGOaN4HAZEVMR2Y0PRLcZfCk3xCuUWyr43Gq+lI+AL2oygw8AAAAAAJw6oWZpQQO+P5D0NdmMNT7Mm8EhMp2PQtT9REx226LbqUW34r9Flwo+AAAAAABwCv2BpK9Jzy+GkqUFDfjeJmlD0oeyGeuBId4PDolhOtV3boFd3xbdUrVTwNe/go8ZfAAAAAAA4BRqZGnp+cWhZ2lBt+j+kqTPS/oHkp7NZqzPSspLKnS41rZy2R8OeA5GxQ3eol7A13XJhrdFd/8MvkSUGXwAAAAAAAAdtGVp6fnFnllafmFuoCwtaMD3g5K8hCYu6Svcr05sSQR8R9ygFXydZvD5adFlBh8AAAAAADiFflAhZmlBA74fCvhzOKoiTnDXrODrFvC5M/g6tOj6WbJBBR8AAAAAADiFQs3SAgV8Vi77nmHfCA6XEfVZwRft0KJbdf7uZwZflBl8AAAAAADglMkvzIWapQVdsoGTxg3ezD4z+FJxt0W34xZdPwGfc0CVFl0AAAAAAIChCNqi25DNWHFJr5d0v/vQS5KesnLZ8kFfG6PjzeCLygnhurXbei26pZaArzDADD7TpEUXAAAAAACcXun5xY5ZWn5hLnCWFjjgy2asqKR/I+lfSJrc8/RWNmO9S9LPWblsNegZGKHGFl1bU6m4DMPoeFmi0aLbDPhKlUFadN0KPgI+AAAAAABwiqTnF3tmaen5xXdJ+rn8wtzAWVqggC+bsSKS/oukb5FkSFqTdNV9+kFJs5L+F0mvz2asf2jlsgxcO+K8Cr6pqBQfT3S9zgvx2mbweRV8Uf8z+GrM4AMAAAAAACFIzy+elfQnLQ+NSXpI0j2SPiTpAUkb7nPvyS/M/R/uz90j6b2SXiapJOmf5RfmPjGke/KdpaXnF/9hfmFuoOAkaAXfj0h6k6S8pJ+yctkPtT6ZzVj/WNIvudf8sKT/K+A5GBU3eHvbgxVNfNPrul7WcwZfvH+LbtRt0a0wgw8AAAAAAIQgvzC3Ium13vfp+cWfkvR1+YW51fT8oiT9ZH5h7vc7/OiCpE/mF+belJ5ffIOk/5yeX3wwvzBXGcJttWVp+YW5tiwtPb94oCwt6JKNH5BUkPQNe8M9SbJy2f8s6RvlpJ1vDXgGRsir4HsgXtPLzk90vS4ZdT4yxbaAry7DkOKmjxl8EWbwAQAAAACAkfphSb/p47rvlPRrkpRfmPuUpBuSvm5I99DI0vaGe+55B8rSggZ8r5L0cSuXzXe7wMplr0r6U/daHHURJ+Cza70rQDu16BYqNSWjZte5fa2YwQcAAAAAAEYlPb/4VXLaX/+g5eGF9Pzi59Lzi+9Lzy8+5F53VlIsvzB3q+W6vKQrQ7qVV0n6eH5hLt/tgvzCXOAsLWjAl1CzV7mXLfdaHHGGV31Xr/W8rhHwVdtbdP1s0JWYwQcAAAAAAA4sYhjG9ZavJ3tc+8OS3tuyuOL78wtzGUlfJunP1R78hSnULC1owLck6Ylsxuq6VcF97islXQ94BkbJq+Cr9g74zIihuBlRsdwS8FXrvjboSszgAwAAAAAAB1a3bftSy9c7Ol2Unl+ckNN2+/94j+UX5pbcP+38wtyvSHooPb941p3bV03PL15ofQlJ14Z0z0uSnkjPL3YNUNznAmVpQQO+j8opUXxnNmPF9j6ZzVhxSe9yr/lIwDMwQoa3AbdPBZ8kJWKRtgq+UqWmlM+Ajxl8AAAAAABgRL5L0jP5hbmcJKXnF6Pp+cV7vSfT84vfLum2G+5J0vsl/RP3uTdIul/Snw3pXhpZWnp+cV+Wlp5fPFCWFnSL7oKk75X0TyX9o2zG+j01V/s+JOcXeJ+kVUlvD3gGRsltne03g09y2nRbZ/AVKzWl4v4+SszgAwAAAAAAI7J3G21C0mJ6fjEhqS5pWdK3tjz/M5J+Kz2/+JyksqTvG9IGXWlPlpaeXxxqlhYo4LNy2ZeyGetNcpLNK5L29jobckoY32Llsi8FOQOj5W3R9VPBl4qZKpTbt+jOjvucwWcygw8AAAAAAIQvvzD3VXu+35H0eI/rb0v65pDu5aX0/KKvLC2/MDdwlha0gk9WLvupbMZ6RNJ3SHqjnLJFSXpJ0sclvd/KZctBXx8j5nOLriQl97Toelt0/fAq+JjBBwAAAAAATpP8wtyn0vOLPbO0/MJcoCwtcMAnSW6A9zvuF44xv1t0JadFd2W7+XkbZIsuM/gAAAAAAMBp5QZ4Q8/Sgi7ZwEkzUAWfqWLFCQJt21ZpgC26MXfWHzP4AAAAAAAAhuNAFXzuBt1vl1NWeElOv/B1OWWFH6RF9/gYtIKv4AZ8paoTCPreomt6FXzM4AMAAAAAAKeLu0G3a5Y28hbdbMb6Ckm/K+kB92Za/YikX8hmrO+1ctm/DnoGRmiQCr5oRMVKTbZtNyr5Ej4DvsYWXWbwAQAAAACAUyQ9v9g3S0vPL35vfmFu4CwtUMCXzVivkPT/SZqQMwjwfWqu9k3LWe37gKSPZjPWl1u5bC7IORidRgVfrdr32mTMVN12FmV4lXyDzuCjRRcAAAAAAJwW6flF31laen7xy/MLcwNlaUEr+H7OvaF3SfpXe1txsxnrZyX9oqSfkPQ29yZxlJnOR8FPBZ/Xjlus1lSsONf7ncEXZckGAAAAAAA4fdqytL2tuOn5xQNlaUGXbHyDpC9J+slOc/asXLYi6Un3mm8IeAZGaLAZfM61xXKt0aKbjPoL+AzDkBkxVPERJAIAAAAAAJwQjSyt05y9/MLcgbK0oAHfuKS/sXLZrmVY7nOfcq/FUTfgFl1JKlbqzYDPZ4uu5LTpUsEHAAAAAABOkXFJf5NfmOsaiLjPBcrSggZ8L0g65+O6s2r2E+MIG6SCL9GhRTcV91fBJzltuszgAwAAAAAAp0ioWVrQgO+9kr4um7Fe2e0C97k3SvqtgGdglEz/FXyNGXyVmorVwVp0JSfgo4IPAAAAAACcIu+V9HXp+cWuWZr73BsVIEsLumTjlyR9uaQ/zWasn5f0XiuX3ZSkbMaakvT9kv61pP8qZ0AgjjgjMvgMvkK5pmLZuT4xQItu1Iwwgw8AAAAAAJwmjSwtPb/485Lem1+Y25Sk9PzigbO0oAHfc+6f5yW9U9I7sxlr3X1spuW610t6PpuxWn/WtnLZlwU8F2EZoIKvMYOvWm9W8Pncoisxgw8AAAAAAJw6+7K09Pxi1ywtPb/Y+rN2fmGuZ5YWNOBLt/zdcP+c7XDdAx0eI9k5ghoVfLX+FXxtLbruDL5BAj5m8AEAAAAAgFMm3fL3oWdpQQO+BwP+HI6qRgWf/xZdJ+Bzrk8NEvCZVPABAAAAAIBTJdQsLVDAZ+WyLw77RnC4BpnBl+hYwTfADL4IM/gAAAAAAMDpkV+YCzVLC7pFFyfNIDP4ol7AV1ehwgw+AAAAAACAw0TAB0luBZ9h+KrgS8WbFXwlL+CLDjaDj4APAAAAAABgOILO4FM2Yz0k6WckfaOk+yQlulxqW7ls4HMwQqbpc4uukwsXWmbwDdSiaxraLRPwAQAAAACA0yM9v+g7S8svzA2UpQUK3rIZ6zFJH5c0oebmj276PY8jwohEfG3RbW3R9WbwJQZq0Y2oygw+AAAAAABwSqTnF0PN0oJW1r1d0qSkD0r6BUnPWbnsdsDXwlFhmrLrfir4WpZsVANs0Y0YqtKiCwAAAAAATo99WVp+YW5oWVrQgO8JSc9K+k4rlyWpOSH8VvB5YV6p6rToRgwpZvoPl0/Dko3f+e8v6m+uruqd3/3YYd8KAAAAAAA4fI0sLb8wN/RQJOiSjYqkpwn3ThifFXwJbwZfuaZCpa5kzJRh+A/4YmbvCr7bm0VtFiu+X+8o+m9fuK0PP33jxAeZAAAAAADAl4qkp8MI96TgAd9nJF0a5o3g8Pmt4EtEIzIMbwZfrdGy61e/GXz/+P/8S/2vH/78QK951BTc5SO75eoh3wkAAAAAADgCQs3SggZ8/17SE9mM9cYh3gsOm2nK9hHwGYahZNRUsVpTqVJTMjrYx6jXDL563daNjaKev3u8Rzp6y0d2y/1/nwAAAAAA4MT795KeSM8vvjGMFw80g8/KZf8om7F+QtKHsxnrVyV9RNI1SR3Lsqxc9lrwW8SoGKbpq4JPkpKxiArlmoqVupLxwSr4oj1m8HlLO5a3SgO95lFTdCv4dkpU8AEAAAAAcNrlF+b+KD2/+BOSPpyeX+ybpeUX5gbK0oIu2ZCc0sIbkv6V+9WNfcBzMCo+Z/BJzibdYrWuYrWm8fhg/3mj7gw+27b3ze4ruBVvy9vljs8fF6UqFXwAAAAAAKBNaFlaoOAtm7G+WtIfS0q6D61IOt49lfA9g09yAr5Sxdmie3Y8PtA5ZsRp6a3VbUX3bN/1ZteVa3VtFqqaHosN9NpHRbExg4+ADwAAAACA0y49vxhqlha0su7fyrmhd0j6d1YuuzasG8IhGrCCr1CuqlAefMlGNOKEetW6reieHy20BGJ3t4snIOCjRRcAAAAAALRnafmFuaFmaUEDvtdJ+qyVy/7UMG8Gh2uwCr6IVndqKlbrgQO+TnP4vAo+Sbq7VdbD9wz00kcGSzYAAAAAAECL10n6bH5hLpQsLegW3bKkZ4d5IzgCBqngi5oqlGsqV+tKxgbcouu25VZrHQK+tgq+47low7btxrIQAj4AAAAAAKCQs7SgAd9/l/TIMG8Eh2+QCr5U3NSWuyF20Ao+s9Giuz9MbK3gO66bdEvVumw3u6RFFwAAAAAAKOQsLWjA9/OSviybsb5nmDeDQzbQDL5II8QavEW3uWRjr5NQwVeqNH+HOyUq+AAAAAAAgJOlpecXQ8nSgs7gi0v6D5J+K5uxvlXSRyRdk9QxHbJy2U8EPAcjZEQiUtVfxVmyZTtGcu+mjD5al2zsdRIq+Lz2XEkqUMEHAAAAAABasrT0/GLfLC2/MDdQlhY04Pu4JFuSIek73a9u7AOcg1GKRn1X8CVaqvYGncFn9prBVzn+FXzFlvewwww+AAAAAAAQcpYWNHj7hHsYTpCBZvC1BXxBK/g6zOBrCcSWj23A13xfLNkAAAAAAAAKOUsLFPBZuewbh3wfOAoGnMHnSQ28ZKP/DL5ENKK7I2jRvbVR1Ef+7qbMiKFoJKKYaSgejSgRNfXVLz+nicTg/0RaK/hYsgEAAAAAAPILc28M8/VpnUXDIBV8yQO06MZ8zOC7fGZM+eUd1eu2Iu71YfiVjz2n3/7ktY7P/fOvf5l++lsyA79mW4suSzYAAAAAAEDIfAV82Yx1xf3rS1YuW2v53hcrl+2coOBoCVjBlxi0gs/HDL4rZ8b0/J1trRcqOjMeH+j1B3FttaBENKJ3/9CXq1qvq1Kra7dc04/9p8/q5nox0GsWq83fYaFCBR8AAAAAAKdNen6xkaXlF+ZqLd/7kl+YGyhL81vBl5ez1eNRSV90v/fbN8ySjWPiKMzgK7YEfJIzhy/MgO/WRkH3zaT0xMvONh6zbVtPRp/R2m450Gu2zhGkgg8AAAAAgFMprxFmaX4vvua+eGXP9zhJBqjga9uiGx1wi26PGXzeUopLsylJ0t2tkh65d3Kg1x/EzfWiXn1puu0xwzA0OxbT2m6ly0/1Vqo2Q70CSzYAAAAAADiNRpql+Qr4rFw23et7nAzBZ/ANVsEXM3vM4CvXFDGk+2ecgC/MTbpbxYq2SlVdnE7te252LK71gBV8bTP4WLIBAAAAAMCpk1+YS/f6ftgGK73CyWaasgO06Kbig27R7T2Dbywe1fnJhCSFukn35oYzY+++meS+52YOUMFXrDhVkIbRrEgEAAAAAAAICwEfGgxzkAq+5kcnGR3uDL5kzGwGfCFW8N1YL0hS1wq+zWKlYxtxP14F30wqpl0q+AAAAAAAQMgI+NBkOh3bfubwtbfoDvYxivaZwZeKR3RuIvwKvltuBd/F6U4VfHHZtrRRGLyKz6vgmx2Pq1ipBwoJAQAAAAAA/CLgQ4PhBm9+qvhaq/YG3qLbawZfpaZUzNR4IqqxuKnl7WBz8Py44QV8HVp0Z8dikhRok27RXbJx1t3+W6jQpgsAAAAAAMJDwIcm0wnq/FTwpeLNj05iwAq+XjP4iuWaUnGnkvDcRCLcGXx9WnQlBVq04bXonnEDvt0SbboAAAAAACA8BHxoGKSCL9FSwZcatIKvxww+p4LPuY/zk4lQt+je3ChqPG5qKrl/mfSMV8G3E6RFd0/Ax6INAAAAAAAQIgI+NA1Qwdc+g2/QgK/PDD739c5NxLWyXQptht3NjYIuTCdlGMa+57xwLlCLrjuDz3uNHRZtAAAAAACAEO0vXTok2YyVlPR7kh6VVJB0R9I/tXLZ57MZ6x5J75X0MkklSf/MymU/4f7c0J87rQxzgBl8bpWdGTEUMwds0e0yg69et1Wq1pWKOwHf+cmE6rYTsnlLN4bFtm3d3Cjq9Q/Mdnx+ptGiG7yCz2vzpYIPAAAAAACE6ahV8P2GpFdYuexrJH1Y0v/tPr4g6ZNWLvtyST8k6T9lM1YsxOdOp8jgFXzJ6OAfoWiXGXzecopUrDmDTwpnk+5moardcq3jBl3pgEs2KjUlohGNJ5z3QcAHAAAAAADCdGQCPiuXLVq57B9auayX+nxSUtr9+3dK+jX3uk9JuiHp60J87lQapIIvZkYUjRgDt+dKzSUbtT1BYsENwrwFHucnnYAvjDl8Nza6L9iQmtV3a4Eq+OpKxkyNuZWILNkAAAAAAABhOjIBXwc/IenD2Yx1VlLMymVvtTyXl3QljOeG/i6OE6+Cz0fAJzlVfEECPq+ld2+Lrlfp1pzBF14F30034LtvpnMF31QqJsMIuEW3WlMyFtF4nAo+AAAAAAAQviMzg69VNmP9rKSHJX2jpM4lViNiGMaTkp5s+V5LS0uHeEfDtbq62vh7qbArSbpx/boi5f7BVjwiRY2679+Hd9bK3R1J0vLKmpaWmh/Bq6tFSVK5sKOlpSXZu851z1+/o6Xzgy3aaH1fnXzh6ookySxvd73/ybipW2tbvt6Y8qm/AAAgAElEQVRf63lbO0VFZWt7w3nspdt3tbQ0vEUh/d7bMI3yrFGfx3s7fmeN+ryTetaoz+O9Hb+zRn3eST1r1Ofx3o7fWaM+76SeNerzeG/H76xRn3eS3xuOtiMX8GUz1k9JerOkv2/lsruSdrMZq5rNWBdaKu7Skq5ZuezKsJ/bez+2bb9D0ju8703TtC9fvjzcN33IvPdze3pGq5Iu3nuv4pcu9f25s5MvaCoV0yC/j8uXL2vNWJf0JU1MTbf9rPP4F3Xh3Bnn8fFdSV9SxUwOdEbrWd0Uv+CEma95+LIu3zvZ8Zqzk19SoRbxfbZ3Xd34kiZSMaUvXZT0guLjU4Hu389ZozDqzzvvjbOO0nkn9axRn8d7O35njfq8k3rWqM/jvR2/s0Z93kk9a9Tn8d6O31mjPu8kvzccXUeqRTebsZ6U9D2SvsnKZddbnnq/pH/iXvMGSfdL+rMQnzuVBpnBJ0nv/O7HtPDmVw98Tt8ZfO6GXq9Fd3l78DbZfhoz+Ga6F4jOjMUCLdkoVJwW3cYMPlp0AQAAAABAiI5MBV82Y12S9EuSXpD0sWzGkqSSlct+haSfkfRb2Yz1nKSypO+zcllv+0EYz51OjRl8/bfoStKj900FOqbrDL6Kt2TDbPw5kYiGM4NvvajJZFQTie7/BGbH4vr8S5uybVuGYfh+7WKlxpINAAAAAAAwMkcm4LNy2euSOqYoVi57W9I3j+q506pRwVcPt+LMq+Cr1toDvqJb6da6uOP8ZCKULbq3Nou6ON15wYZnZiymcq2u3XJN4z2CwL28LbqNJRsVKvgAAAAAAEB4jlSLLg7ZgBV8QUW9gG9PBV/BDcLG4s0w7dxEfOgVfLZt68Z6QRene+9vmR2LS9JAbbq2bTe26Kao4AMAAAAAACNAwIeGUVfw7ZvB57Xo7qngW90tqzrE0HFtt6JSta77ZnpX8M2OxSRJ67v+O7fLtbps26lCTEQjMiMGM/gAAAAAAECoCPjQNKIKvm4z+BpLNuLNj+W5iYRsW1rdGd6ijRvr7oKNPhV8MwEq+IoV53eXjJoyDENjMZOADwAAAAAAhIqADw3NLbrhtpR2m8FX6DSDz92ke3eIc/hubhQlqe8MvmaLrv8KvlLFew/O73IsYWqnTIsuAAAAAAAIDwEfmo7iDL5JN+Ab4hy+Wxv+KviaLboBKvjckHIsHm0ElwAAAAAAAGEg4EODEXUr547SDD63gm95e4gtul4FX58ZfI0W3R3/FXzee0g0Aj4q+AAAAAAAQLgI+NB0VGbwtQR8YVTw3XRn8N3Xr4Jv3KngG2wGX/t7GKeCDwAAAAAAhIyADw2j3qK7bwafN7+ubcmGU0W3PMQZfDc2ipoZiykVN3te583gG6xFt30GXypuaqdEwAcAAAAAAMJDwIemEc/gq3Wo4DMjhuJm+xZdadgz+Iq6MNW7PVdy5uglY5GBlmwUq+0z+MYTpgqVmup73isAAAAAAMCwEPChYVQVfIZhyIwYqnaYwZeKmTIMo/FYMmZqMhkdWgVfvW7r1kZR9830bs/1zI7FD1bBF3MWhnjViRhMsVLT0uruYd8GAAAAAABHGgEfmhoVfOGHUWbE2FfBV6zUGpVvrc5PJoZWwbeyU1a5VtfF6f4VfJKzaGOgCj4v4Is2K/gksWgjoN/4xAv6xnf8mdZ2hrdkBQAAAACAkyZ62DeAo6NZwRdui67ktOlW9szg2y3XlIrvz5zPTST03O2toZx7c8NdsOG7gi+m62v+K8hKlfYW3bG4W8HHoo1APn9jQ+VqXbc2i5odjx/27QAAAAAAjon0/GJeUklSwX3of8svzL0vPb/4cknvkXRO0oakH8wvzH3e/Zmuzx11VPChyavgqx5OBV+hUtNYbH/mfH4yobXdiio+ZwOWqjXd3Oxc8XVjvShJviv4Zsfi2ipWVfV5dtH93SXcFt0xd5EHizaCubbq/H94o+C/ihIAAAAAANd35RfmXut+vc997Ncl/UZ+Ye4RSW+X9O6W63s9d6QR8KFhVDP4JClmRvbN4CuWa0p22Gx73l20sbLtr03zN//iqr73d57V83e29z13y63gu+C7RTcmSVr3GTA1Z/B5FXzOn7u06A7Mtm1dd+fvEfABAAAAAA4qPb94j6THJf22+9AHJV1Ozy8+3Ou50d/p4Aj40GQ61XNhb9GVulfwpWL7P5LnJwfbpPvC3R1V67be/9TSvudubjgVfPdN+1+yIcn3oo1C2fndpfa06O7SojuwjUJFW6Vq4+8AAAAAAAzoven5xc+l5xd/Mz2/eF7SZUk38wtzVUnKL8zZkq5JutLnuSOPgA8No6zg6zqDr8OSjXMTTsjmd5Oud92HPvPSvtbaG27AN2gFn99FG16LrlfB5y3ZoIJvcEurhcbfNwZYdAIAAAAAOPEihmFcb/l6ssM1X5tfmPsySa+TtCxntt6JRcCHpsYW3dFX8NXrtkrVeqPirdWgFXxewHd3q6Q/f2657bmb6wWdHY933NbbiVfB53eLa7NF1/mn5QWWh1HB99dfWtFffWm5/4VH1FLLchMq+AAAAAAALeq2bV9q+XrH3gvyC3PX3D8rkv6DpK+RtCTpYnp+MSpJ6flFQ06F3rU+zx15BHxoGP0MvmbAt7fyrdU5dwbfXZ8VfCvbZZ0fdyrv9rbp3two+q7ek6RZ93XW/VbweVt0o14FnxNY7hxCwPczH/xb/fjvPi3btvtffAQtrRLwAQAAAAAGl55fHE/PL860PPQ9kj6bX5i7I+kzkr7PffzbJV3PL8w93+u5Ud33Qewvl8Lp1ajgG80W3db22YIbgKXiB5vBZ9u2VrbLesPlcT1875T+2xfuaG2nrNnxuGp1W7c3i7IuTvm+zxmvgs/nDL5SlyUbhRG36JardV1f21Xdlq6t7uqBs+MjPX8YqOADAAAAAAR0r6QPpucXTUmGpBck/YD73I9Kend6fvFnJW1K+qGWn+v13JFGwIeGZgVf+C260YihcrV5jtfC2mkG39lx/xV8m4WqyrW6ZlJRfeOrL+mvX1jRf3nmht76VWktb5dUrdu6b2aACr5GwDfYDL5E1Pldei3HO6XRVvDdWC/IK5D8dH7teAZ8qwUlohEZBgEfAAAAAMC//MLcC5Ie6/Lcs5KeGPS5o44WXTSNuoKvtUW34lXw7c+c49GIZsZiWvZRwbe841xzZiymN73qgiYSUX3gqeuSnNBLki763KArSbNjXouu3xl8dcWjEUUihqRmBd+ol2y82NLe+ukX10Z69rAsre3q0mxKM6k4AR8AAAAAAD0Q8KGhUcE3giUbUTPStmSjUOlewSc5c/j8VPB5IeCZVFRj8ajmXn1Rn3tpQ7lbm7rpbtAdpIJvKhlTxPDfolustG8CbgZ8o63gu9YS8D314upIzx6Get3W9bWCrpwZ03QqRsAHAAAAAEAPBHxoMkdXwReNGKp0msEX6/yRPD+R8FfBt+0EcTNjTiXgWx6/JEn6wKevNwK+C1P+A75IxNB0Kua7RbdQqTU26ErNJRsjD/hWdiRJr75/Wl+8va0Nn/d/VNzZKqlcresyAR8AAAAAAH0R8KHBcAO+UWzRNSNGWwXfbqNFt0sF32RCm8Vqo5W3m5WdZgWfJD3+wKzSZ8f0+0+/1NjKet+M/xZdyZnDN0iLbusm4EQ0oogx+hbda6u7MiOGvvU190mSPnPteLXpegs2Ls+OaXrMCfiO6zZgAAAAAADCRsCHpsYMvtEs2WibwVfuPoNPcir4JGllp3fQ5lX5zboVfIZh6C2vv6Tl7bI+/PRLMgzp3gEq+CRpZsx/BV+pUlMy2gz4DMPQWDw68gq+F1d2dd9MUl/50FlJ0lPHbA6fF8ZePpPSdCqmWt3Wzoh/hwAAAAAAHBcEfGhobtEdQYvugDP4zk86Ad/tzWLP173rtujOpppB4Ztfd0mG4WzCPTeRUDw62Mfeq+DzU0FW3NOiKzlz+HZKo6vgs21bS6u7euDMuKyLkxqLm/r0MZvDt7TqLES5NOu06Eps0gUAAAAAoBsCPjQd5gy+PgHfxWmn6u72Ru+Ab2W7JDNiaCrZfJ37ZlL66ofPtb3OIGbG4qrU/FWQFat1Jfa8h7G4OdIKvpWdsnbKNV0+M6aoGdFrL8/o6aX1tt/3Uddo0T3TEvAdszmCAAAAAACMCgEfGozI6Lbo7p3B11iyEe/8kbzgBnM3+wR8y9slnR2PK2IYbY+/5fXOso0gAd/smBMwrfVpD5a8Cr69Ad9oW3RfXHHCsQfOjkly5hAWK3V94cbmyO7hoJZWdzWVjGo6FWsEfOsFf3MQAQAAAAA4bQj40ORV8I2iRdedwee1vTa36HaewecFc7f6tOgub5d11p3X1+pbXnlBX/HgGf19696B73V2PC5JWuuzaMO2bSfgi+5v0R1lwOfNr7tyxgn4Xp8+I0n69DGaw3d9raDL7v17Ad8mLboAAAAAAHREwIeGUVbwRd15f14RX6HPFl1vMYafCr5zE/F9jydjpt73o0/oOx6/PPC9zngVfH1aRCs1W3V7/3sYS0RHukXXq+DzAr7HrszIMKSnjskcvkqtrpsbBV2ebQ/4mMEHAAAAAEBnBHxoGnEFn6TGXLh+M/iSMVNnxuO6tVHo+pq75ap2y7XGxt1hmR1zAsP1PhV83nto3aIrSeNxU4VKTfV6/yUdw3DNq+BzW3SnkjG94t5JfTq/5mtRyGG7sV5Q3XY26ErS9BgBHwAAAAAAvRDwoaFRwVcNP+Az3YDPm8PXbNHtHPBJ0oWpZM8W3RV3g+7ZDhV8BzHjcwZfyQv49mzRTcVN2bZUHMHvVZKure5odiymqWSs8djrH5jVna2Srq91D0iPCm+D7t4WXQI+AAAAAAA6I+BDU6OCL/wW3ZjpBHxVL+Dr06IrOXP4bm+UulbC3d0uSZLOhVTB169Ft1hxfm97l2yMx525gjulUQV8u7pydrztscfTs5Kkp47BHD6vApEWXQAAAAAA/CHgQ4PhBnyqHU4FnxkxGsFfJxemkyrX6lrt0irbrOA7nBZdr0IvsW+LrvN9YQSLNoqVmm5vlhrz9zyPP+At2jj6c/iW1tyAb08F33qfgBUAAAAAgNOKgA9NI53B53z0qi0z+FIxU4bRPeBrbNLtsmhjuVHBF1KLbt8Kvs4tumNeBd8IFm141W8P7An4Ls2mdM9kQp/OH/0KPm8L8KVZZwZfzIxoLG5SwQcAAAAAQBcEfGgY5RZdr4Kv2lLBt7e1da9+m3SXt8Jp0U3GTI3FTa31q+DzWnSjnSv4dkdQwXdtzwZdj2EYejw9q2dvb2mzeLSDsqW1gu6ZTLR9HqZTMW0S8AEAAAAA0BEBH5pGWcFn7mnRrdQaQVg3F6ediq5um3RX3CUYww74JKdNt1+LaLOCb0/Al/ACvvAr+F7cs0G31euuzMq2pc9eWw/9Pg7i+upuoz3XM52KUcEHAAAAAEAXBHxoGGUFX9St4KvsadHt5cJ07wo+b8nGsLfoSk6bbv8KPm9RSPs/q1Eu2fDaW/dW8EnS42lnDt9T+aM7h2+3XNPKTlmX3fZcDwEfAAAAAADdEfChaYQVfKYbJnoVfMVyTck+FXwX+s3g2yppZiymmDn8j7WfCj5vE/DeFl1vM3ChMoIKvpUdxc2ILrjtzK1eed+UkrGInrp2dOfw3dpyfsedKvg2i1XZducNyifFynZJP/X+Z7TihtUAAAAAAPhBwIeGw6jg82bw7VZqSsV6fxwnElFNJqNdK/hWdso6Oz786j3JqeDbLlVVrnb/3ZS8GXx7KhFHWcF3bXVXl86kFInsX1YSMyN6zaUZffbaemO5yVFzc9Opkrw8uz/gq9VtbZfCD0kP03995oY+8NR1ffzZu4d9KwAAAACAY4SAD02HOYOvXGtsm+3l4nRStza7b9ENY/6e5FTwSdJ6oXubbrHq/N4Se4LKRgVfyEs26nVbS2uFfRt0Wz2entVuuabcra1Q7yUoL+C7dGZ/i66kvlWUx93TS858xFFsXAYAAAAAnBwEfGjyKviqIwj4Wmbw1eu2StV63xl8knRhOqVbG8V9rZqVWl3ruxWdmwwr4OsfMHVbsjHuLtkIO7S5tVlUuVrXA2fHu17z6MVpSdKX7m6Hei9B3djqXsEn6cTP4Xvm+oYknfhKRQAAAADAcBHwocEwDMk0ZdfDb99sncHnVb7tDcY6uTiVVKFS02ahPQBZ9Tbohtai67zu2k6PCj6vRTfauUU37Aq+a+6Cjb3z61qdcX8/R7US7uZGWWbE0MXp9hmC027AunmCA7713bKuLu9IkraLBHwAAAAAAP8I+NDGiESk2ugq+Kp1W7vlzttnO2ls0t0stD1+d8tZShBai+64EzCt+arg69yiG3YF37UVJ+Dr1aLrBXyrPYLKw3Rjq6z7ZpKK7lmUchoq+LzqPUnaoYIPAAAAADAAAj60M82Rz+DzKtv8zuCTtG/RxrK7dTSsFl2vgm99t38FXyreuYJvN+QlG14F35Wz3QO+ZlB59AI+27Z1c7OsKx0CytMQ8D19bb3x9+0RLGQBAAAAAJwcBHxo41TwjW6LbqVW7zq7rhOvgu/WnoBvZdsJrMLaoust2ehZwee1Gu9p0U3GIjIMNSoVw/Ki16I72yPgGzu6FXxruxUVKvWO938aAr5nrq8rZhoyDCr4AAAAAACDIeBDuxFV8LXO4Cu4AZ+fJRsXp53tqqOu4Gsu2ehRwVfuHFQahqGxmBl+i+7qru6ZTOyrIGwVMyOaTEaPZAXfUo8Zgo0tuic04LNtW08vrevRi1OaiEdZsgEAAAAAGAgBH9qMuoKvbQZfzMcMvimvgq99Bp8X8J0PaQZfY8lGr4DPreBLRPe/j1Q8Gv6SjZUdPdCjPddzZjyu1Z2jF5QtrTkB36XZ1L7nTnoF39JqQas7Zb328ozGEwR8AAAAAIDBEPCh3WHM4Kv4n8E3lYoqFTP3VfA1WnQnwmnRnUpGZUaMPks26opHI4q44WWr8YSpnRADvs1iRWu7FV05M9732tmxeM9twIdladUJbTtV8E2d8IDv6evO/L3XXplxPisEfAAAAACAARDwoZ15CDP4vNbWHq2lHsMwdHE6uW8G393tksbipq+QMAjDMDSTivVZslFTskP1nuSEl7shtuh6G3Q7LajY68x4XKu7Zdm2Hdr9BOFV8HWawRczI5pIRLV5UgM+d8HGay7NaCIZI+ADAAAAAAyEgA9tjIgpu3Z0Z/BJzqKNvQHf8nZZ50Jqz/XMjMX6VPDVui4KGYuboS7Z8Dbo+m3RLVfrQ72fUrWmz1xbO9BrLK3uKhk1dK5LFeZ0KnZiK/ieub6uqWRUD54b10TC1BYBHwAAAABgAAR8aGdGpBEEfJ1n8PkP+LZK1bY5ZSvbpdDacz2zY/E+FXz13gFfiKHNtR4LKvY6Mz78Tbrv+9SS3vyrf6Vnb20Ffo2l1V1dmIzLMPa3OEtOm+5JDPgqtbr+7qUNvebyjAzD0Hg8qp1S9chVWAIAAAAAji4CPrQxzKjs+ghadFtm8BW9Cj4fLbqSdHHaW7ThVPHV67ZWdkZRwRfX+m6la/BSrNa6hpRjcVO7lVpooc2LK/4r+GbHhh/wvXB3R5L00vpuoJ+v1W29tF7QxanuIe10Kqr1HhWUx9Wzt7ZUqtb12OUZSdJEIqq67QTGAAAAAAD4QcCHNs4W3VG06LoVfLV6Y7us/wo+Z8uqF/CtFyqq1e3QA74z4zFV67Y2C50r8UqVupJdNgGPx6OyQwxtllZ3NRY3dXa8fxXjmXFnYcVqj2rEQd3edP5brAXczntjvaBKzdb9070Cvpg2ixXV6yersu2zS+78PS/gSzpzJNmkCwAAAADwi4AP7Ua1RdedwVdtncHnt4Jvyqngu7nhbF1d3i5JUtfZbcNy1g0QV3ZKHZ8vVGpKdKvgSziP74S0aOPF1R1dOTPWtb21lVfBN8xNuo2AL2BoeHXZqQC8MtM9pJ1OxWTbOnHz6RoLNtyAbzxBwAcAAAAAGAwBH9oYo9qi29KiG2QGn9Ss4GsGfOFW8HnVcStdgrHeSzac0KYQwqKNSq2uG+tFX+25Ujgz+G5vOv8NgrbQ5lecgO9yn4BP0onbpPvM9XVdmk01Pr8TbsDHJl0AAAAAgF8EfGgTmZxSdXU19AH/rUs2gs7gu7npBXxOUBV6wOdWCK5s76/gs23nfSSjnf9JjcXDq+C7sV5QrW7rio8FG5I06wZ8Qavt9qrXbd3Z8tqlg72mN8OvV8A341YenqRFG5vFir50d1uvdav3JGnc/axQwQcAAAAA8IuAD22SmVeovrGh6s2boZ7TNoOvMlgF35nxuOJmpFnBt+UEbmFv0T077rXo7g+xqnVbdVs9t+hKalQrDpO3QddvwHemsWRjOEHZ6m5ZlZoTCK8FrOC7uryjRDSi8xOxrtdMuRV8Jyng+9z1Ddm22gK+iaTzPqngAwAAAAD4RcCHNolMRpJUzGZDPadtBl+5JjNiKGb2nx8nSYZh6N7phG66AZ83E290FXz7A75S1Qm4ui3Z8Fp0d0vDD/juuO2x3vKRfqZSMUWM4c3g8+bvSdL6AWbwPXhuXJEeMwS9Ft2TtEn3aXfBRlvAl6CCDwAAAAAwGAI+tElaj0qSitlcqOe0zuArVGpKxUxfCyI8F6dSuuUt2dhyQqXzIQd8XoDYqUW3VHXmFvav4Bt+aOMFnGd8bNCVnOrJmbH40LbotgZ8Qbbolqo1XV/bVfrseM/rpk9gBd/TS+syI4Zedf904zGWbAAAAAAABkXAhzaJR14umeYIKvicMK9Scyr4/M7f81yYTmptt6Jipabl7ZJipqGpVDSMW23wts8ud6h8K7ktqt3ajBsVfCG06Hotw4NsEZ4diw2xgq8ZeAap4Fta3VXdlh48f7oCPtu29fTSujIXJtuC4XGWbAAAAAAABkTAhzaRREKJhx5SMfuFUM/xZvDV6vVGBd8gLrZs0l3eKevseGKgCsAg4tGIppLRnhV8iS7vYzwR3pINr2X47AAVjGfG40NbsuHNQrx3KhFoBp+3YOPBc6cr4Lu5UdTdrVJbe64kTTYq+IYfBgMAAAAATiYCPuyTfNRS9cZN1dbXQzujbQZfgIDvghfwbRa1vFXSuclwF2x4zk0ktNqpgq/Rott7i24hhAq+1Z2y4tFIY/uqH7Njca3tVlSvH3xbsrdB9xUXplSo1Bpbkf26uuwEfA+dsoDPm7/3mj0BX6NFt0gFHwAAAADAHwI+7JOwLElSMRfeHL62GXzlmpIDtuh6FXw3Nwpa3i41NtyG7exEvPeSjWjvFt2dEKqyVrZLOjceH6iC8exEXLW6ra0hhEi3NoqKRyN68KyzxXfQJRhewNevgm8q6fwON09YwPdYl4CPFl0AAAAAgF8EfNgnmXEDvi+EN4evbQZfpaaxgSv4nI2xX7qzo1K1HvoGXc/Z8YRWd8uq7al8871kozL80GZ5u6wzA8zfk5rzBIexaOP2Zkn3TiU06y75GLT194XlHU0lo32XhETNiCYTUa0XhtNafJiqtbo+8cW7mkhE9dD5ibbnJrwKvhDauQEAAAAAJxMBH/ZJWhlJUjEXXsDXNoMvwJINr4Lvcy9tSNLIWnTPTsRl2/tDrP4tuu6SjRAq+FbdGYSD8MK01Z398wQHdXuzqHsnk43QcNCA7+ryjh48P+GrAnEqFTsRLbrv+pPnlLu1pe9+w+XGvwWPGTGUipm06AIAAAAAfCPgwz7m9LRi99+vUoibdL0ZfJWarVK1PvAMvnMTCZkRQ3/nBXyjatF1g7G9bbreFt1uFXxhLdnYLVdVqNQa9+VXo4Jv52BhWbla18pOWfdOJzUz5szIG6RFd6tY0d2tUt/5e57pExDw/dWXlvXLH3ter7xvSj/9pld0vGY8EaVFFwAAAADgGwEfOkpYGZVeuKp6sRjK63sz+LwZcN2CsW7MiKF7JxNacRdejK6CzwkSV/ZUvnkVfN2CSm8237CXbDQ36A72/r0KvrUOC0MG4S3YCFrBl1/eldR//p5nOhXTRoBNvUfF6k5ZP/m+p5WKmfrl73lMiS4zGycSprYJ+AAAAAAAPhHwoaOkZUm1mkrPPRfK65uGF/A5Yc3YgC26UnOTrqTRzeCb6FzBV3YDvkSXFt1IxNBY3NTOsAM+N6A7M2AFozcv76Az+G5vOkHnhelEI+AbpILv6oq/BRue6VRMW6XqULb/jppt2/rp9z+j25sl/dtve9W+2XutJpLRoVd7AgAAAABOLgI+dJS0HpUU3qKNSMRQxFCjSmnQGXySdNFdtCFpdFt03XNWtvdW8PVu0ZWcELMw5NDGm6E3cAXf2HAq+G5vuhV8U80W3UFe8+rdwQK+mbGYbFtD2f47ah/42xX9Se6O3vzY/Xrz6y71vHY8HmUGHwAAAADANwI+dDSKRRvRSKQR8A3aois5oZJnVC2657wKvp29M/jcJRtdWi4lZ9HGzpCXbCy7lYTnBt2iO+6EcatDDPiaW3QHqOBb3pY0WAWfpGO3SffvXtrQr/7VTT14blw/922v6nv9RGL4nxUAAAAAwMlFwIeOohcuyJyZUSmkCj7JmcPnVWINumRDam7SNYxmRVrYvNl1y3tadIuV3lt0JbeCrzLc0GY1YIvuRCKqmGkMvPF2r1stAd943FTMNLQ+wGteXd7RvVMJjSeivq6fcgO+47Roo1Cu6V/87mclSb/8PY9pwsd7HU9EVa7VG63fAAAAAAD0QsCHjgzDUPJRS8UvflF2LZxKIjNiDGUG3+xYXFFzNB/lmbG4IkazNdbTb4uu5LzHYW9G9VqFB92iaxiGZsfiB67gu+PO4Lt3KiHDMDQzFvcdGtq2rReWd5Q+6696T2pW8B2ngO+TV1d0dXlHP/D6e/Sq+6d9/cxE0gkB2aQLAAAAAPCDgA9dJTKW7EJB5RdfDOX1oxFDFRDOfwwAACAASURBVDcYO0gF36DtqQdhRgydGY93XbLRK+AbT0S1e0S26EpONeIg7bSd3NooajIZ1VjcCaRmx2K+l2ys7JS1VazqofMnO+DzKhofPpfsc2WTV+UX9ibdQrmmSo0qQQAAAAA47gj40FXSsiSFt2jDjDQ/fskDVPCNaoOu5+x4Yv8MvsaSje7/pFIxU7vlqmx7eBtgV3bKSsXMRsA2iGFU8N3eKupCyyzEQSr4ri4PtmBDOq4Bn3OvU0n//43G4+EHfLZta+5df66f/dDnQjsDAAAAADAaBHzoKvmoE/CVQlq0ETONxt+DVPB5m1tfdn5imLfV19mJuJb3bdHtv2RjPBFV3W5eOwwrO6XGXMBBnZmIa6NQUfUAFVy3N4pty05mx2LaKFRUr/cPMZsbdP3/9zvWAV/C/2d83L02zBbdu9slvbC8o6eX1kM7AwAAAAAwGoOX/eDUiKfTMpLJECv4mgFfkBl8MTOij/7Lr9XkAJVRw3BmPK6tYlWlak0JN9Ar1eqKRyOKtLynvVLue9wt1wJtDe5kdbus85PBKhi9xSTrhUqgKsjtUlU75dqegC+uui1tFiua6bP45IUAFXwzY8cv4PPudTLp/7+595kOs4Lv+dvOBuPrawXZti3D6P7ZBQAAAAAcbVTwoSvDNJV4xSMqZrNDbSv1RFvCsKCB171TyUDtqQfhhWFrO82QqVS1lYz2/uc0Hh9uVZZt21reKetswBblWbfyby1gm+6tDW+DbvN8L9TzM9vv6vK2IoZ05cyY7zMbFXwHnB24U6rqzvbB2pP98mbwTQ5UwRd+wPfcHSfgK1RqB27VBgAAAAAcLgI+9JS0LNXW1lS9c2for926+TZIi+5h8TbWtrbplqr1viGlF0QOa9HGTrmmcrUevEXXrYYLGu7c2XQCPm8WouS06EryNYfv6vKOLp8ZU7xPMNpqMjmcCr5f+MOs3vq7X1RhyEtPOlkvVJSKmUoM8D69gC/MFt3n7mw1/n59rRDaOQAAAACA8BHwoadkxlu08YWhv3ZrBV8qQIvuYfEq5loXbfgL+LwW3eGENituwBhkg67UrOALGvDdcgO+eybbW3SlZtVaN/W6rfzK7kDtuZLT1j2ZjB444Mve3NR2ua6/u7FxoNfxY3230mgt9qu5RTe8API5t0VXIuADAAAAgOPuSM3gy2asd0n6VkkPSHrMymWfdh9/uaT3SDonaUPSD1q57OfDeg5NzUUbOU1+/dcP9bUPOoPvsHiB2kpbBZ+tZKJ3Xj6WGG4Fnxcwng1awecFfD633u51e9N5/60VfF6Q1dq+3MmNjYLK1frAAZ/ktOkeNOBbcgOtp6+t6w3pMwd6rX42CpVGa7FfEyOo4Hv+zrbi0YjK1bpeWt8N7ZwgPvr5W/rDz93UL77lyxpzLgEAAAAA3R21Cr4PSPpqSS/uefzXJf2Glcs+Iuntkt4d8nNwJR55RIpEQlm0MYwZfIfBC9RWtges4Is1l2wMg3f+2fGAM/jGDjaD7/bm/hl8jbl+fULDq+6CjYcOIeArVmq6u+WEk6PYILu+Wz5ABV84Ad/KdkkrO2U98dBZSUevgu+DT13Xh5++of/3L/OHfSsAAAAAcCwcqYDPymU/YeWy11sfy2aseyQ9Lum33Yc+KOlyNmM9HMZzYb234yqSTCr+0IMqZkMI+I7rDL5OLbq1upJ9Ko3GE+G06J4J2KLbqODrU23Xze3NoiKGdL5lyYc3g2+9zxKMq40NuhMDnzszdrCArzXMCjvgq9dtbRQqmkkN9t8o7CUbz7sLNr7qZWcVNyNHLuB7ad25n1/+k+caQTIAAAAAoLsjFfB1cVnSTSuXrUqSlcvakq5JuhLSc9gjaT2qyvXrqm1uDvV1vRZdM2IoZhp9rj46urbo9mkzTsW9tsvhtuieO2gFX8AW3VubRZ2bSLQFtTM+X/OFu27Adz5YBd9WsapaPdhm5+trTjtq3DT00nqhUc0Xhq1SVXVbA1fweWFwWC263gbdRy5M6v7ZVON3clRcXytoMhnVTrmmt38kd9i3AwAAAABH3pGawXcUGYbxpKQnW77X0tLSId7RcK2urva9pnzxoiTp2sc+pujrXje0s6plJwRKRg1dv369048M7axhsm1bsYih68sbjc9CqVqXXSn1/Gxsrzuh1kt3lrW0FDzQ9N5b/tb/z959hsdVmPnf/57pTZpRt2Q1y5YtGXdjgwumE4MDJEBIgQApm/0ngfRC2M3uJrt54rAbsptNQjYJSUgWCJsECMGhmG7AxgYbV8lFsmwVq4/6aOp5XsycURu1mVGxfX+uS5eN5sw5Z0aSwT/u0ha+dlcrtbXxha8Wg0JDW9eo9z3W+9jQ3kua1TDkuYFI6NYw6L2JpaKuDZNeIdDVQm33wHsxka+bPhj+vqmoqsFpmfwfYQerw+/b6lwLO+s8vLjvOBvnOSd9nolo6AyHh7pA/6S/J406hdaO7rj+vBnvWvuqzgDgCHSTYVE43NjH6dOnUZTJf18m+2et1xek0+PnfYtcdHiCPLGvnqtLLCyZY5+S643lXL3WdF9PXtvZd63pvt65eq3pvp68trPvWtN9vXP1WtN9PXltZ9+1pvt65/JrE7Pb2RDw1QK5FWXlhvLKikBFWblCuNLuNNA1BY8NoarqA8AD2j/r9Xq1oKBgal/xNBvv9Xivfz/Vv/wluiefIv+GG+IKAWJdy25rAHqwmY3j3kOi10q2zJTj9AV1FBQU4A+GCKkHSEt1jHlNk7MfqKLdb0j43goKCvArrQAsKS2Oe4ZhhuM4npAu5v0EgiEONPSyLD9/xNc8FFJp6zvI0oL0Ec9NsVTgZezXeKbnBCVZDooKRxbNjvfe5GX1AO040rIpiGOGX8+hcPXa5sVZ7Kw7Tb1nar7/ANxKB3CUgpwM0tNNk7qOw1JBQIn/3sZ6XqOnHptJz+ryEhZU9vJOXQ+OjDnRtu1kXmuyKhvDYfWiuZncuHIu7/vR6/xsVyt/+fwidJGq3+n8M/hcvdZ0X09e29l3rem+3rl6rem+nry2s+9a0329c/Va0309eW1n37Wm+3rn8msTs9esb9Etr6xoBvYCt0c+dTNQV15ZcWIqHpv6V3T2MZeW4rzpg/Tt2kXPK68k7bzGSGvn2TR/T5PhMNEaWXLR7w+33FqMY/845aRamJNqYd/p5Mx9a+v14TAbElpQkmY30j7Kko3H36nl809W8erRlhGPtff5CITUIQs2oue0mXCPMYPPGwhS5+6jOGPy4RwQ3Ugb7xy+OrcHRYF1xalYjLopncOnzSKcbIsuhOfw9SZpXuNwx5t6WJDtQKdTyE+zAsyaNt36yDzAuWlW5mc5+OTGeRys7+SP7547ldNCCCGEEEIIkWyzKuCrKCv/n4qy8jogH3i+oqxcC9z+Hvj7irLyY8C9wCcGPW0qHhPDZH3xiyg2G80/uB/VF9/MtuG0GXxnY8CXbjdHgzFPNOAb/3WsKHBxrKk7KbPV2np8cVdcadJsplG36O6qDpd6P3eoccRjjZ3hxQdzUi0xzmmkY4wZfLXtfYTU+ObvQRICvvY+clIsWI06luQ52V/XQSjOeX7j6Yjco8s6+YDPYTYkbV7jYJ19fpq7vSzIDi84yU+zAQPB2kzTFmxo93XPFQvIdJi5/7mjCS1XEUIIIYQQQohz2axq0S2vrPj7UT5/FFg3XY+JkYzZ2WR+5u9o+c//wv3YY6TfeWfC5zRoAd84yylmo0y7CY8/SJ8vgNcfAiYW8C0vcPHc4UYO1XdyUUlGQvfQ1uslz2VN6BwZdhO9viD9/uCI+997yg3AS5VNBENqNJAFaO4OB3w5MQI+l83E0abuUa8ZXbARR3stJKeCT7v2igIX75xyU93aGw28kqkzEnQ6bUZgcqGuw2ygtSf5VXUnWsJfm9LsFIBBFXyzI+DT7mNu5Hs7xWLkm5sX8fU/HeDHLx3nruUpM3l7QgghhBBCCDErzaoKPjG7pd91F4a8XFp++jMCbnfC5zubK/gGNun6Blp0DeP/OK0ocAEk3BaqqirtvT4yEq3gizy/Y1hLbVNXP/UdHvQKtPb4RtxvY2R5RI4zdgVfvz8UfV+GO9kaDvhK4gz4XNbIPccR8PV6A7T1+qKh1orC5Hw9RhNt0bVO/utkNxumZIvu8abwDMLSYRV8s61FN9c18L1186p8lhe4ePitGl485qahw4OqTk3VpRBCCCGEEEKcjWZVBZ+Y3XQWC9lf+SoNX/sarT/9GXP+8R8SOl90Bt9ZWMGX4QjPnmvt8WLQhV+HZQKvY1m+E52SeKDU1R/AH1TJsI+cgTcZ6bZw8NTe62POoLBOq97bUp7O00fa2X6kidVFadHHm7q0Cr6R13dFzunu85HrHFlhmKwKvq44Aj6t/bMgPRxqLc8PB3z7azu4ZXV+XPczlmiLrs1IcPSixpgcZgMef3BE9WSijjdHAr6ccMCXnWLGqFdmUQVfHzmpZsyGgZ8nnU7hOzdcwC0PvsV3ttfyne21pNtNXJCXypK5Ti5bmJVwRawQQgghhBDi3FF87zYL8AdgMeABmoHP1mzdcqL43m2vAkVAZ+Twh2u2bvlR5HnZwO+A+YAX+FzN1i2vT/Ptx0Uq+MSkpG65Duvy5bgfewxvVVVC5zqrK/jsgyr4AloF3/ivw242UJqdwv4EA762nnAFXbojORV87mEz896NBHy3LMskK8XM9iND5/BpAV/sGXyRc/bGDuCqWnpw2YzRkHSyEmnR1arUtAq+/DQrmQ7T1FfwxbFkw2EO//+XZC/aON7cg9mgi1bu6XQKc13WWRPw1Xd4ou25g60ocLH9K5fyjcvncvvFhRSm29h9sp0HX63i4w/txhtI/rxCIYQQQgghxFntF8Cimq1blgN/AX416LEv12zdsiLy8aNBn98K7KrZuqWU8K6GR4vv3Tb5v9DNAAn4xKQoikLOt+6FYJCm++9P6Fxn8ww+rUW3vXdQi+4Eg8oVBS4aOvtpjoRk8dAWfCTaoqst6Wgbtmhj72k3qRYDRelmrirPpqqll+qWnujjTV39mAy6aNg2WJo9/LnRFm1Ut/YyPyv+eXeZKSZ0Cpxq6530c2vbIxV8kXBLURRWFLioONM1aktxIjo9Pkx6XVwhtj0S8PX0JzfgO9HUzfwsx5CqwLlpVurcfTPe9trvD9La44uGj8PNy7Rz/eIM/u0DS3nq8xs4/J338fGLi/AFQzR0xP/zJIQQQgghhDi31Gzd0l+zdcvfarZu0f6SswsonsBTbwV+HjnHHqABuHRKbjLJJOATk2ZdsYLULVvofe11et54M+7znN0VfJEW3V4v/dElGxP7cdLmvu1LoGqstSccnmXGWQWnGai2GwjjvIEgh+q7WFWUhk5RuKo8B4AXK5qixzR2eZmTakFRRraODrTojqywc/f6aO/1xT1/D8BmMnBBnpPdJ9snvf12oIJvIEBanu8iEFI53NAV9z2NpqPPj9NmjPk+jcdhDv9cJHMOX3e/n4bO/mh7ribfZaPXFxwxi3G6RRdspE1seYxBr2PRnPDSjdPts2OGoBBCCCGEEGJW+iLhKj7N1uJ7tx0svnfb48X3bisBKL53WwZgrNm6ZXALWw1QOH23GT8J+ERcsr/6FRSzmdYHH4z7HGf3DL4YSzYmGFQOnvsWL62CLz1JFXztgwK+Q/Vd+IIhVhWGZ+5tWJCJ1ajnxSPN0WOau/pjzt+D8JINGNn2C1DdGq4CnJ/gxtp18zNw9/nH3NYbS227B50ydIHDVC7a6PD4ccWocpyIaAVfEgO+qsj8w9Jh77/WsqzNKJwKwZBKd//YAaJ2/VgtuqMpjMxTrJWATwghhBBCiPOJTlGUukEfXxntwOJ7t90HLAC+FfnUx2u2bikDlgE7gGem/nanngR8Ii7GvDxsq1fTf/gwajC+1katgm+iwdhsolXwtfV48UQDvon9OC3McWA16hMKlLQZfBkJz+AbGcbtOx2ev6cFfBajnk0LM3nnVDvtvT68gSBtvT5yYszfg4GqwFgtulXNiW3Q1Vxckg7Aruq2ST2vrqOPXKc1Gi4DLMufwoCvzx/X/D0AhyUyg8+bvNbh45FAdEF2ypDP56eHA7Wp3KT789eqWP/9l0dt3R58/fwJVvDBwMIUCfiEEEIIIYQ4r4RUVc0f9PFArIOK7932NeAm4NqarVv6AGq2bqmN/KrWbN3yE6Ck+N5tGTVbt7QBgeJ7t80ZfArg9JS+kiSRgE/EzVxehtrfj+/Uqbier83gs52FFXxWkx67SU9brw+vf+JLNiDcVrg038mBuk6Ck2wx1bRFZ/Alp0V3cAXf3tNudAosL3BGP3dVeQ4hFV6ubKalOxwujhbwuaIVfCOrtaqSVMG3pjgdnQI7qyYX8NW2e0a0fzqtRkqy7AkvPhlOVVU6PT6c1vhCWEe0gi95bbMnhm3Q1Wgty1O5aGNPTTvd3gCH6kdvha6PXH8yAd9clxVFgdopDCeFEEIIIYQQZ5/ie7d9BfgocHXN1i0dkc8Ziu/dljPomJuBpki4B/BH4P9FHlsDzAVem9Ybj5Nhpm9AnL0sZWUAeCsrMZeUTPr5Z/MMPghvsA236IZn8Jkn8TpWFLjYfbKd6pYeSnNSxn/CMG1JatE16nWkWAzRCj5VVXn3lJuFOSmkWIxokdcVZdnoFNh+pJF5meEwKNYGXRg012+UCj6DTom2VcYrxWJk6Vwnb0fm8Ol048+46+r30+nxRxdsDLaiwMUTe+tp6/HGvd13uD5fEH9QjbuCz27SAr4kVvA192DUKxQNe/+1QG0qA76qyJKWijNdbCzNjHnMQIvuxL8/TAYduakWmcEnhBBCCCGEiCq+d1s+8EOgGnil+N5tAF7gCmBb8b3bzEAIaAVuGPTUbwK/L75323HAB9xes3XLzA4rnyAJ+ETczIsWAdBfUUnqdddN+vkGbQbfWRrwZdjNnOn0RGfwTeZ1rCgYWLQRV8DX4yXFYsBkSLwIN91uor03/OdVQ2c/TV1erizPGXJMhsPM6qI0Xj/WyuYl4Wrl7FFm8NlMekx6XcyFDdWtPRRm2Ia0yMbr4vkZ7K/rpKKxiwvynOMeP1Z1mBbw7a/r4IqynBGPx6PDE379sTYNT4Q2g2+ySzYe33Mab08ndxQUjHjseHM3JZmO6M+eJjvFglGvTFmLbr8/GA0PKxpHr+Crc3vIsJsmPZezIN1GZePk5jEKIYQQQgghzl01W7fUAaNVglw4xvOagGum5KammLToiriZ581DMRrpP1oZ1/O1Fl3LWdiiC5AZqeCb7Aw+gOUFiS3aaO/1JbxBV5NmM0W36O49FZ6/tzoyf2+wqxfn4PEHeWJvPTB6BZ+iKLhsxhEVfP5giNNtfczPSqw9V3NxSQYAu6rbJ3S8NqOtIEb1oBa4vlfbmZR7g4EZhPEu2UixTH7JRq83wLefOsy/bq/lZGvvkMf6fAHq3B4W5Ix8//U6hVyndcoq+KpaelAj3egVZ0YP4urdnkm152oK0m10esIVmkIIIYQQQghxPpKAT8RNMRoxl5birTwa1/O1Fl3bWVzBFwipNEdm0k1mWUie00JWijnuxQ6tPT4yEmzP1WTYTbT3+aLtuQCrikYGfFdFqvp2HG8FRp/BB+HQcHgF3+n2PgIhlZKsxBZsaNYUp6PXKRNetFE3RgVf2ZxUTAZdUhdtdEZef9wtunFs0d1V3YYvGMIfUvn2U4dQ1YEZj9UtvajqyA26mvw0K/Vuz5DnJIu2vdeoVzjR3I0vEBpxjC8Qoqm7f8SMxImQTbpCCCGEEEKI850EfCIh5rIyAs3NBNonVkU1mFEfmcF3llbwaRtsGyJzwyYT8CmKwooCF5WN3Xh8k5uxFlJV3H2+hOfvadLsJnyBEH2+IPtOu0m3myjOGFnlVpLlYP6gcG6sgC9WBV9VZMFDsir4HGZDeA5fdduElpXUjrGh1WTQcUFeKvtrOyYccJ1q6x3zutEWXVt8Xye7Ofz9NJkW3deOtQCwaq6dN0608vT+huhjx5vDlXOl2bFbwvPTrHR7A3R5JtcSPBHaco9LSrPwB9XoPL7BznR6UNXw0ozJKohsAZaATwghhBBCCHG+koBPJMRSFp7D562cfJtunsuKTgn/ejbSArb6aMA3uR+nFQUugiGVww2Tawvt9gYJhtSkLYPQXseZTg+HG7pYVehCUWKPKrh6cXj+XqrFMGYwm2Yz0enxDwnAqiMto/OTVMEH4Tbdrv4AFWdGn+umqXN7MOiUUVuLVxS46PT4qWkbPyTad9rNZf/xKn/eWzfqMVoFY7wtuo44KvheP9bCXJeV724uIs1m5F+fqYi2rR5vir1BV6Nt0p2KbbRVLT0oCly3NBcg5tdrYEbi5BewRCv4ZJOuEEIIIYQQ4jwlAZ9IiHlReJNufxxtutctyWXnt65kXmbyAp/ppM3Ai1bwGSZXiTgw921ybaEdkQqrZLXoaltvXz3aQiCksjLG/D3N1YuzAZjjHL16DyDNbkRVoWvQTDStgq8kMzkVfADr5mtz+MZv061t7yPXZRmxYEIz8PVwj3uuvx08g6rC0TEWO3R4IjP44mzRtRr16JSJV/DVtPZS09bHpYuycFoM3HddOa09Xv7j+fDP5vHmHvQ6heKM2D9vU7lJt6q5h/w0KysLw+9xrIUY2nXjquCLhIKySVcIIYQQQghxvpKATyQkWsEXx6INnU4Zs81zttNadP1BFaNOQacbbUFPbEvznShKeJPuZLi1gM+RnIAv3R4OoF6qaAZg1RgB34qCNIozbCzOTR3znK5IaDi4TbeqpYd0u4m0JAWTABcWpWGYwBw+VVWpd3uiQVDMcxWnA/D6sdZxz7X9SBMQrnocTXQGnzW+16soCnazYcIVfK8fD7fnbirNAuCW1fmsnZfO/759ivdqO6hq7qE4wzbq5mWtci7Zm3SDIZXq1l7mZzkozrBjMepiVvDVRYLy/PTJB3xZKWbMBh217VOzJEQIIYQQQgghZjsJ+ERC9E4nhrzcuCr4znYZ9oEWWbNhcuEeQKrFyPwsx6Q36br7woFP0mbwRcK43TXt6HUKywucox6r1yls+8Il3H/L8jHPqbWluiMhl6qqVLX0JrU9F8KLKJblO3n7ZPuY8/C6PAG6vYExN7TOdVlZnu9k+5Em+v2jz0WsaumJtvHWd/SPepzWouuMs4IPwm26Pd6JzWh87WgLBp3C+gXhqkZFUfjeB5Zg0Cnc++cD1LT1jjp/D6augq/O3YcvEGJBlgO9TmFRTkrsgC8SLMZTwacoCgXpNpnBJ4QQQgghhDhvScAnEmZZVIa3qoqQzzf+weeQzEEVdOZRqqLGs6LARZ3bQ2uPd8LP6egPRq6f3Bl8wZBKeW4KNpNhzOPtZsOoVWAaLTTsiFTwtff66PT4k9qeq7m4JIPu/gBHGkafwzewYGPs+W7vX5ZHjzcQXVYRywuR6j2TXseZjtHDsA6PD50CKeax38+x2M2GCbXoegNBdla3saoojVTLQKBYmpPCZzaVUNnYTUgdff4ehJemGHRK0gM+bcHG/Mj23vLcVFp7fDR3Dw1H690enFYjKZb4AtHCdBt1bg+hCSxcEUIIIYQQQohzjQR8ImHmskUQCOCrqprpW5lWg1tN4w34lmtz305PvIqvI9kVfIPOs3qM9tzJ0ObOaRV80QUb2cmft6jN4dtZPXprrVYdVjBO++d1y8JLILYdODPqMS8eacJhNrBpYRYtPV58gVDM4zr6/Ditxkm3bg/mmGDA926Nmz5fkEsXZo147O7LS6Ove0H26AGfXqeQ67JEl8Yki7Yxd8GggA+g8szQOXz1HZ64qvc0BWlWfMEQTd2jV1UKIYQQQgghxLlKAj6RMEtZORDfoo2zmVGvwxlpRY2nRRdgZSTg2183iYCvP8kz+GwD51lVlJyATwsNtQo+bcHG/KzkV/CtLkrDqFfYVd0+6jHabLbxKvjmuqysKnTxYkXsNt2Wbi/7aju4dGEWxRk2VBWaumIHSp0ef3QWYbwcZgM9/eMHfFrFYayAz2rS8++3LGdloSsaho4m32VL+gy+E8O+9mVzwm3Cg9t0A8EQZzr7mTtGC/V4CrRNujKHTwghhBBCCHEekoBPJCy6aKNy8os2znZayBZvBd+iOSmYDbpJbdKNzuBLMDzSpFqNaEVmYy3YmIy0aAVfOODTKvhKpiDgs5kMLM93sedkO4Fg7Gq6aAXfOAEfwJZlefT5grxS2TzisZcrm1BVuGpxNrmRarOGUSretAq+RNjNenp9AVR17LbT1461kOkwjbr85OKSDJ783AayU8ZeapOfZqW7P0DnoO3Hiapq6SXdbopWnJZF7nFwwNfU7SUYUseckTiegYBP5vAJIYQQQgghzj8S8ImEGQsK0Nls9J+HAV9mZNGGWR/fj5JRr2NZvpM9Ne2cjIRg4+noD+CyGTHEec3h9DoFl81EVoo5oYBlsIEtuuGgqKq5B6NeoSBJ5x/u4pIMur0BDo8yh6/W7cGk15GdMv7cwi1Lw226zxwc2aa7/UgTep3C5YuymesKh2UNo2zS7fD4oq3K8bKbDYRU8Iyx9KOpq5/Kxm42lWYl1A4Myd+kq6oqJ5p7hixXcVqNzHVZqRjUolvXHv+CDU1hJOA7LQGfEEIIIYQQ4jwkAZ9ImKLTYV64EG9l5biVRucarYLPFGeLLsCXr16INxDi7kf34g2MvzHV3RcgI0nz9zSfvXQ+X75qIYqSWECk0bbodgyq4CvKsCctlBxOaz3dVd0W8/E6dx9z06wTCsDmOC2sKU7j5Ypm+nwD7bEeX5Adx1tZU5yGy2Yi16lV8I1s0e33B+n3h6LvQ7y0BR1jtelq7bmbYrTnTlayN+m2RZarDJ/9V56bSlVLT/T7XZv7N14L9ViiFXxJbjEWQgghhBBCiLOBBHwiKczlZQQ7Owk0Nc30OmYSxwAAIABJREFUrUwrre0w3hZdgPXzM7nn8gUcbuji+38bvwqyoz9Ahj05G3Q1f7ephI9dVJi08xn0OlIsBty9fnyBEKfb+4ZUcSXbqsLwHL6dMQI+VVWpc3smVZ34/mV5ePxBXh7UprvjeAveQIirynMAyBujRVdrcU10Bp9dC/jGWLTx2rEWFAUuKc1M6FqQ/IBv+Pw9TXluCoGQGn283q0FfPFX8DnMBtLtJmnRFUIIIYQQQpyXJOATSWFZVAZAf0XFDN/J9MpwhIM2SwIBH8AXrixlbXE6v32rhhcON456XDCk0ukJJm3BxlRKs5lw9/k43d5LMKROyfw9jdWkZ2VBGntOtg+pugNo7/XR5wtOKjy6dskcFAWe2T/QpvtiRTi8vnpxOODLsJsw6XWc6RxZwdcRaU1OfAZfOODr9cau7AyGVN443srSuc7o92Ii5kYDvuSEZNGAL0YFHxBt09UCxURadCG8SVeWbAghhBBCCCHORxLwiaSILto4en5t0s2MLtlIrLXVoNfxXx9dQZrNyNf/dCDasjicu8+HykDl4GyWZjPS0efnRHN4tuBUbNAd7PrlufT6gnxv29CQuc49+fbP7FQLF81L55WjzfR4AwRDKi9VNLMwx0FRRrgSUadTyHVZYlbwaa3Jic7gS7GMXcG3v66DTo8/5vbceMxJtaDXKdGKukRVtYQDvgUjKviGLtqo7/BgN+kTfr8K0m00dvXH3IAshBBCCCGEEOcyCfhEUpgXLgRFob/y/Ar4tFbZRFp0NblOK//xoeV0evx88bF9MTfCtveGg6NkVGtNNVekgq+6NRzylExhiy7AbRcVsa4kg0fePs1LFQOt4tpMtsm2f25Zloc3EOKliibeq3XT1uuLVu9pcp2jBHzRFt0EK/hMYwd8rx1N3vw9CAfNuU5LUlt0zQbdiMq8onQbVqM+GvBpMxITnQGpzeEbLSAXQgghhBBCiHOVBHwiKXQ2G6aiIrzn2Sbd6JINfXKWU1xZnsOnNs7jnVNufvTisRGPt/Z4gYHKwdkszWbEGwhFN9vOz5zaCj6dTuGHty4n1WLgm38+EH2vtLBKC38m6tolc9Ap8MyBM7xwJBwYavP3NHlOK139gREBXGekRddlTc4Mvt7RAr5jLaRYDKwscCV0ncHy06xJa9GtbumlJMsxYrmJTqewaE4KFWe6CIVUGjr6E1qwoZFNukIIIYQQQojzlQR8ImnMZWX4Tp0i1Hf+/OW6IN2GXqeQ5UisUmuwb24uY1m+k5+9WsUzBxqGPKZV8J0NLbragol3a9xkOkw4E6xmm4g8l5XvfXAprT0+7v3zAVRVjS5dmGwFX6bDzLr5Gbx2tIVtB86QlWJmef7QIE1btHFmWMVYhyf8dUr0NTvGWLLh7vVxoK6DjQsyk7qdOD/NRld/ILooJF693gD1HZ4RG3Q15bmpuPv8HG7owhcMJTx/D6AgEhLWjRLw/d+eWv7tmSMJX0cIIYQQQgghZhsJ+ETSWMoWgariPTay8uxcNddl5bkvXsKNF2Qk7Zwmg46ffHQVmQ4z9zy2j1+/cTL6WFtPpEU3yVt0p0JaJOBr7Oqf0gUbw12/PI8PrMjjxYpmHttdS53bg9mgIyuOtuYtS/PwBUPUuT1cVZ49ohIt12UBoGHYoo2OaAVfggGfZfQKvreq2gipyWvP1WhVcM+PsexlIk62hmcvDp+/p1mcmwLA9kg7dSIbdDVjVfD5gyF+8Fwlv3rjpGzaFUIIIYQQQpxzJOATSWNeFF60cb7N4SvNSUnKDL7BCjNsPPHZ9ZRk2vnuM0f4t2eOEAqptEVn8M3+Cr40+0C4NdULNob7zo1LmOuy8q/PHOFwQyf5cc5327xkDvpIqDd8/h4MVPANn8M3MIMvsa+Tw6wHYlfw7TvtBmDtvPSErjHchy7MZ06qhfueOMirR5vjPs/ABt3Ysxe1RRvbI+3Pc5MQ8OW6LOgUYm7SfeN4a/Tn55UEXpdIjrdOtNLVn1iVqBBCCCGEEGKABHwiaSzl5QD0Hz2/5vBNlYJ0G3/+7HrWFKfxqzdOcs8f9kVbQTPOohZdgPlTvGBjOKfVyA9vXU5/IEhrjy/u+W7pdhOXL8rCZTOyfn7miMfznLFbdLUZfKmRCrx42cdo0d1f10GKxcC8jOS+t7lOK7/71FrsZgOf/d+9vHvKHdd5tIBvtBbdRXPCFXzaoo1ktOga9TpyndaYFXxP7qsHwKBTeLlSAr6ZdLihk4/96m1++Xr1TN+KEEIIIYQQ5wwJ+ETSGHJy0DudeCsk4EsWl83E7z91EdcumcO2A2f447t1KCReGTYd0mwzV8EHcHFJBn+/aT4ABenxh0cPfHgFz37xEixG/YjHtBbd+o5hLboeHykWQ8Kz8UZbshEIhjhY38myfOeItuFkWJiTwm8+sQaAT/52D8eauid9jqqWHnQKFI8SQKZYjEO+LslYsgHhNt3a9j5UVY1+rscb4IUjjVxYlMZFJensrGrD4wsm5Xpi8t460QYQXcAjhBBCCCGESJwEfCJpFEXBXFZG/7FjqKHQTN/OOcNi1PPTj63ikxvmAeC06qNto7NZ2qAQsmSaK/g0X7l6IfdcsYDbLy6K+xypFiO5ztgBYarFSIrZwJnOYS26fX5cSVgqYjdpAd/QMOpYUw/9/tCIpR/JtKowjQdvX0WvN8AdD+2e9GbdE809FKTbYgajmvI54TZds0GXtM3QBelWur1Dl4Q8f6iRfn+ID6ycy+WLsvEGQrxV1ZqU64nJ21UdDvjiCY6FEEIIIYQQsUnAJ5LKUrYIta+P7uefJ9TfP/4TxITodAr/dP1i7r9lGZ+5eM5M386EaAGXSa9LWnXWZJkMOr56zSLKIkHSVMh1WTgTY8mGy5p4YKXXKdhMerqHVfAdqOsAYHnB1AV8AJctyuaHty6nqbufOx7aTVuPd0LPCwRD1LT1jlu5qc3hmxvnjMRYtEUbg+fwPfVePUa9wpaluVxRlg2Q1Dbdvafd7KlpT9r5zmXBkMruk+H3qs7tiblARgghhBBCCDF5EvCJpLKuXg1A/Ze/wrG1F3Hqrk/Q+j+/wHPwIGpQWuISdeuFBVy/OHkbe6eSVsFXnGk7KyoO45XnstLQ4RnSEtrpSU4FH4TbdIeHIPsjAd+KKQ74AG5cMZd/uf4Cqlt7ue/JgxN6zun2PvxBddT5e5ryyCbdZMzf0xQM26Tb3NXPmydauXRhNml2EyVZDoozbLxS2Tzka5aIrzz+Hp97ZG/SzncuO9LQRbc3gN0UruzUZjUKIYQQQgghEiMBn0iq1GuuYd6TT5D99a9hW7MGz3vv0fKjH1HzoVvx/ug/Z/r2xDSymfTkp1lZU5zcLa+zTa7TijcQoj2yodUfDNHjDeC0Jifgc8QI+N6r7SQn1UxOqiUp1xjPneuLuaIsmxeONFEbY4HFcFUtvcD4y1UuyHMCo8/pi4cW8NVGWoqf3t9ASIUPrpwbPebysmwaOvs5moQW0a5+PzVtfbR0e6lzj9zeK4baWR1ujb5pVT5AUr4GQgghhBBCCAn4xBSwlJeT8alPUfjQr1i4+20KH34Yy5IlBF58kWBn50zfnpgmiqKw/cuX8s/XXzDTtzKl5kYWbTREFm1os9+SVcHnMBuGbNH1+IIca+qe0vl7sdy1vhhVhd/vOjXuseNt0NUUpNv41R0XcvcVC5JyjwAFaUMr+J56r54Us4Ery7OjxySzTbfyzEBA9V5tR8LnO9ftqm7HqFf4yNoCAI5LwCeEEEIIIURSSMAnppTOZMJ+0VrSPvoRCAbpfvGlmb4lMY2sJj0mw7n9x4y2gKMhsmijoy8S8CVhBh+A3awfEvAdbugkGFKnfP7ecBsXZFKSZefxPbXjbqCtagkHfBPZnnzV4pykViJmOkxYjXpq2/s40dzNofourl06Z8iyj7Xz0rGZ9LyShIDvcMPA/7SQgG9sgWCIPSfbWZ7vomxOKiaDjmNN0qIrhBBCCCFEMpzbf/MWs0bKlVeCXk/X88/N9K0IkVS50Qq+cMA3FRV8g1t0tRBpOubvDabTKdy5rphOj5+n3qsf89gTzT1kOky4bMkJOSdDURQK0q3Utvfx1L4GAD4wqD0XwGzQs3FBJu+ectPR50voekcaugCwGvUS8I3jyJnw/L2LSzLQ6xQWZDmkgk8IIYQQQogkkYBPTAu9y4V+1Sp639pJsEP+EizOHdqCCG2TbqcnHBglawaf3WzAH1TxBsJVc/vrwhVjS+Y6k3L+ybh5dT4Os4Hfvlkz6kKJUEilqqWHkglU702VwnQb9R0entxXz5xUCxfPG7mY5oqybEIqvHasJaFrHTnTxZxUCxcWp3GovhN/MDTm8Z/4zW42/uBlHny1Kjq38Xyxq7oNgItLwl+PhTkOGjr76e73z+RtCSGEEEIIcU6QgE9MG8OmTRAI0P3SyzN9K0IkzRzn0Aq+aItukqrXHGYDAL3eSMBX20FJlj1pAeJk7+WW1fkcbepmV3V7zGN+uaOa7v4AqwrTpvnuBuSn2fAHVeo7PNy4Ig9djC3OlydhDp8vEOJYUzeL81JZWeDCGwgNmck3XHN3P68cbaHO7eEHz1Wy7vsv8fU/7udQfTi09QdDvFfbwUNvnORzj7zLuu+/xLeemNjm4ukSCqn8YfdpPv/IXrY+W8mf3q3jvdqOCYV02vy9VUXh6tPSnPAW5eOySVcIIYQQQoiEGWb6BsT5w7BhPd4f/5iu557DdfNNM307QiSF2aAn02GOEfAlr0UXoKc/gEJ4ecRNw1pOp9Md64r47Vs1PPxWDevmD62M21PTzv3PH2VBtoN7krg4Y7IKI5t0YWR7riYn1cKSuam8dqyFYEhFHyMEHM+J5h78QZUL8lJZURgOrfbVulmaH7u68o3j4Q2yW29aitWk5+G3avjju3X88d06itLMNPUcot8frgBUFEgxG3hs92luu6hwRio2hzve1M23njjIO6fcMR/Pc1r4zo1LuHpxzojHBs/fs5nC39MLtYCvqXtGA2EhhBBCCCHOBRLwiWmjpKRgX3dxtE1X75reGWJCTJU8lyXaotuhzeBLYosuQI83QHVruNJp2SgB0nQoyXJw2aIsXjjSSH0k1ARo6/Fy96N7Mel1PHjbquh9z4SCSMBXNieF8tzUUY+7YlE2P375BPtOu7mwOH3S1zlyJjx/b3FuanSr8XunO7hjXezjd0QCvivKsslOtXDjirkcrOvk4Z01vFLRyOqiNFYXpXNhURorC13UuT1c+187eGD7MX5915pJ31+y9PuD/OzVKh589QSBkMqd64r40lULaev1cqK5J/rxUmUz9z15kI0LMrGa9EPOMXj+nmZhTriN+2ijVPAJIYQQQgiRKAn4xLRK3Xwtva/voPull3DdfPNM344QSZHrtHCovpNAMERnZGmDM0kVfFpQ1usLsL823Mo53Rt0h7tzfTGvHm3h9ztPcdsSO6GQypcef4+mLi8P3Lo82no5Uy7IS8Wk13HbRYVjHnd5WTjge7myOa6AT9uguzgvlQyHmaIM26iLNkIhlR3HWymbk0L2oK3BS/Od/MeHllNbm05BQcGQ55TnGnn/slyeOXCGd0+5WV00vVVuqqry5ok2/ukvh6hu7aVsTgrfv2kpKyPVdml2EwuyB77Wv9tZwz/95TC/eeskn7tsaAXn8Pl7AAVpNixGHcebZdGGEEIIIYQQiZIZfGJapVx5BRiNdD0r23TFuSPPZSWkQlO3N1rBl6wZeSmDKvgO1HVg1CtjVqVNh0tLs5iXaecPe07jDYT46Ssn2HG8lY+sKeCmVfkzem8Q/nrs/aeruf3iojGPW57vIsNuinsO35GGLlLMBgrSwhWDKwpcVLf20tk3ch5dZWM3rT1eLinNnNQ1vnTVQnQKPLD9aFz3GI/a9j7++6XjXPHD17j9obep7/Dwjc2L+Os9G6PhXiwfWVNIQbqVn79aNeI90ObvDQ4pdTqFBdkOjskmXSGEEEIIIRImAZ+YVnqnE/v6dfTu2kXAHXuOkxBnmzxneJNuQ4eHjj4/NpMes0E/zrMmxj5oBt/+ug7Kc1OxGJNz7njpdAp3rCuio8/PD1+r50cvHqNsTgr/csMFM3pfgznMBhRl7Ll6Op3CpYuyqGzsjs5QnChVVTlypovy3NToEo8VkcrK9+pGVvHtOB7e1rtpYdakrrMg28EHV+bz5ok23qpqndRzJ6PfH+T/3qnlI7/YySX3v8IPtx+jy+PnExuKeeHLm/jcZQsw6sf+TwaTQcdXr15EV3+AB1+rin4+EFLZc7KdFQWuEa27C3NSaOry0umRTbpCCCGEEEIkQgI+Me1S37cZAgF6Xnpppm9FiKTIcw0K+Dz+pM3fA7Cbw4HIsaZuWnt8Mzp/b7BbVudjN+l5ttKNzWTgZ7etmvHgMR5XRLbp3vzgW/zzXw7xxvFW/MHQuM+rc3vo7g+wOG+gmjIa8J2OFfC1YjboWBNHK/AXryzFoFN44IVjqKo66eePp8cb4OMPvc03/nSAvac72LI0l4fuvJBd913JP19/AUUZ9gmf64bleZTNSeE3b56kMTKX8kSrZ8T8Pc3gRRtCCCGEEEKI+EnAJ6ZdtE33uedn+laESIpcV3im2pnOfjr7fDhtpqSdO8USruB780S4ektb5jDTUixGPnRheGbc1puXUpLlmOE7is+1S3L5whXh6rSHd57i9ofeZtW/bucLj+3jUGPvqM873BBZsDEo4Fscmf33Xu3Q6mSPL8jumnbWzkuPKwQtzLBx65oC3jnl5rVjLZN+/li6+v18/KG32VPj5s51Rey57yp+etsqrizPGbdiLxadTuEbmxfhDYT48cvHAdhbF16iETvgC3/fHGuSRRtCCCGEEEIkQgI+Me2ibbo7d0qbrjgnzJ3SCr5wwLe/LrzQYcUML9gY7N5ry/jNh0t5/7K8mb6VuOl1Cl+5ZhGvff0ynv/SJr52zUJKMu08vb+Brzx9kl5vIObzjmgLNgbNQzQb9JTnpfJebceQSrvdNe34AiE2lU6uPXewe65YgMmg44dJrOLr6PNx+6/eZt/pDj572Xz+5YYLkrIc5vJF2awpTuPxPbWcbO1lX0MvRr3Cqhjz+0ojSzomO4fv+89W8PGH3k74XoUQQgghhDhXSMAnZkTq5mshGKT7xRdn+laESFimw4xBp1Dv9tDp8eNK0gZdALspHPAFQyoOs2FWVcpZjHoWZFpn+jaSQlEUFs1J4e4rSvnL3Rv5l+sX4/GHeP5wY8zjj5zpwqBTKM0Z+vVYWeDC3efndHtf9HOvR6ruLlk4uQUbg+U6rdx2USEH6zt54UhT3OfRdHgCfOyXb3OgrpMvXFnKN963aNyZhROlKArf2FxGMKRy/3OVHGjojTl/D8LhuM2kn9Qm3WBI5fE9tew43kqdu2/8JwghhBBCCHEekIBPzAitTbdb2nTFOUCvU8hJtVDZ2I2qktSAzxGp4ANYMjcVvS45IYwY2w0r5mLQKTyxtz7m40cauijNSRmxTCU6h692YA7fjuMtZKWYWRSZNxevz142H6tRzwMvHCMUir+Kr7XHyxefqubImS6+ds1CvnL1wqSFe5o1xelcWZbNs4ca6fOHYrbnQriltzTbwdHGibfoHmnooiOypXdPTXtS7lcIIYQQQoiznQR8YkboU1NxrF9P765d9O3bN9O3I0TC5rqs1Ec2sTqtyZvBZx8U8C2fRe2557p0u4l1RSm8WdXKmc6hG3bdvT4aOvuHtOdqtIBvX2TRRmNnP8eaerikNDPhEC07xcId64s42tTNy5XNcZ2jpdvLR36xi+r2fr51bRl3X1Ga0D2N5WvvW4T2kkcL+ABKc1Jo7fHi7vVN6LxvnBjYJrz75MyNeahq6aGxa2L3LIQQQgghxFSTgE/MmLTbPgaqyqmPfoy6e+7Be+LETN+SEHHTFm1Aciv4TAYdJkP4j+oVs2TBxvlic1kaqgpP7WsY8vkjZ8ILNi7IGxnwFWXYSLMZoxV8O46H23MTmb832J3ritEp8Pg7tZN+bmuPl4/9chcnmnu4Z2Muf3/p/KTc02jKc1P58IUFuKz6mPP3NAOLNibWpvvmifBG4pxUM7tPtiXlXifrcEMn7//xG9z3bM2MXF8IIYQQQojhJOATM8axaRMlT/+FlKuvonv7i1TfcCMN37oPf33sljghZrM818AsumQu2YCBNt1lUsE3rdYVpeCyGXlib92QxRZHYmzQ1SiKwvICF0cauvAGguw4Hq4221ga//y9wfJcVi5dmMXLlc00d/VP+HltkXDveHMP/7ilnFuXJydwHM/3PriUP368POb8Pc3CSOvysebx23T7/QMbideVZFDV0ktbjzdp9zsRLd1e/u7hd/D4gxxv7aexc+JfByGEEEIIIaaKBHxiRpkXLCD/v/+b4sf/gG3NGjqffJKqzdfS/F//hRqIvb1SiNkozzk1FXwAKRYDmQ7TkGuIqWfU67hheR7Hm3s4VN8V/fzhyAbd8hgtuhBu0/UFQxxu6OKNE61ckJdKpsOctPv68JpCgiGVP+2tm9Dx7b0+bvvV2xxr6uEfrivn05eUJO1exqPXKViMY/+nhhbwHZ9ABd87NW58gRAbFmSyZl46AHtqxm7TVVWVYAIzCwfzBoL8v/99l4bOfq4qzwHg9UiVphBCCCGEEDNJAj4xK1iXL6fwt7+h4KFfYZo/n7YHf86pj9+Bv6Fh/CcLMQsMruBL5gw+gG9uLuPfPrAk6YsQxPhuWpUPwJ8HhWlHznRRkG7FOUql5spIO+qjb5+mvdfHJUlqz9VcWZ5NpsPE43tqh1QWxuLu9fGxX+6isrGbb11bxt9tmr5wb6JynRZSzIYJtehq8/c2LshkbbEW8I29aONzj+xly4930O8PJnSfqqryrScO8u4pN5/ZVMIPbl6KwsCWZCGEEEIIIWaSBHxi1lAUBceGDcz7v8dJv+suPPv2Uf2BD9K1fftM35oQ48p1DmrRTXIF33VLc9m8JDep5xQTszzfSUmWnaf3N+APhuj3B6lq6Y25YEOjzUp8cl943MCmJLXnaox6HTevyudUWx+7qkcPtzr6wpV7lY3dfGPzoimfuRcvRVFYkOPgeNP4LbpvnmglzWZkcW4qC7IdpNtNYwZ8zd39PH+4kcrGbn704rGE7vOXO6p5Ym89ly/K4puby8hwmFmYZeWNE61JqxAUQgghhBAiXhLwiVlHMZnIufeb5P/8QRSdjvp7vkDjd/+VkHd65ywJMRl5g5ZsjFbZJc4+iqJw86p82nt9vHa0haON3QRDKotznaM+x2kzUpJpJxhSsRh1rC4efcFEvG5dUwDA43tOx3xcVVW+9scDHDnTxdeuWcjnLluQ9HtIpoXZKbT1+mgdY56eu9fHoYZO1i/IRKdTUBSFC4vSOFTfSY839kiHZw82ElLDbe6/fL2a/ZHlJ5P1cmUT33+2ktJsBz/+6Er0unA17drCFDr6/Bys74zrvEIIIYQQQiSLBHxi1kq57DLm/eUpbGvX4n70UWo+/BH8Z87M9G0JEZPTasQWWSSQ7Ao+MbM+sHIuAE/sqxtzg+5gKyILUS4uycBsGH3BRLzmZzlYW5zO3w410tnnH/H4n/fW82JFEzeuyOPuK0qTfv1kK53AJt23qtpQ1XB7rmbtvHRCKuw9FXsO31/3N2A16vn9py5Cr1P4xp8O4AuEJnVvlY1dfOGx93BZjTx05xpSLAM/32sLw/c9U226qqqO26YthBBCCCHODxLwiVnNmJND4W9+Tebdd+OtrKTmY7fhra6e6dsSYgRFUch1WjDpdViNyQ90xMyZ67KyriSDF48081ZVGxB7g+5gKwrDAV+y5+8N9uE1BfgCIZ56b+jm8YYOD995+jDZKWa+c8MFU3b9ZBpYtDF6m+7g+XuaNWPM4avv8PDOKTdXLc5hRYGLuy8v5WhTNz995cSE76uhw8Ndv96DNxDkZ7etpjDDNuTxJTl2HGbDjAR83f1+Nv7gFe578tC0X1sIIYQQQsw+EvCJWU/R68m6+/Pk3f8DAs3NnPrYbXgOHpzp2xJihPBmzzRZhnEOunl1Pr5giGcONOCyGckdZ6PxB1fO5Z4rFnDrhflTdk/XLc0lxWzgsd2no1VcqqryjT8doNsb4Ac3L8NlS+7Cl6myaE444Burgu/NE60UZdgoSB8I2S7IS8Vm0rP75MiAb9uB8JKm9y8Lz6/87GXzKZuTwk9fOUHFma4Rxw/X6fFz129209jVz398aDnr5meMOMagV1g3P4N9tR109Y+spJxKv9t5ivoOD4/tPs0zB2QhlRBCCCHE+U4CPnHWcN5wA/k//Qkhj4fTd95F786dM31LQgzx3RuX8MinL57p2xBTYPOSOViNelQ1HCqNF+KmWIx89ZpFQ9o5k81q0nPjyjwqG7ujM+D+d9cp3jjRykfWFHB5WfaUXTvZslPMpFoMo1bwnW7r43R7HxsWDF1YYtDrWF2Uxr7aDryBoVty/7r/DClmA5cuDFdRmgw6/v2W5ajA1/+0n0Bw9Fbdfn+Qz/zuHY419fCta8u4ccXcUY/dtDCLYEjlrUiF4XTo8wV46I2T5DotZNhN/MOThzjT6Zm26wshhBBCiNlHAj5xVkm57DIKf/0QGAzUfubv6Xru+Zm+JSHEecBhNrB5yRyAMTfoTrePrCkE4A97aqlp7eX/+1sl+WlW/vH9i2f4ziZHURQW5qRQ0dgVsxIuVnuuZk1xOr5AiIN1A4sualp7OVjfyTUXzMEyqGV+ab6Tz2wq4VB9F7/YEXvcQyik8tU/7uftk+3ctb6Yz2wqGfPeL420Yb92bPoCvkd2naa918fnLl/AD25eRqfHz9f+uJ+QbPMVQgghhDhvGWb6BoSYLNvq1RT9/nec/vSnqf/yl+l8+nL0Lhf6lBR0qSnoU534A356FixAn5aOIT0NfXopRQsgAAAgAElEQVQ6OsvYLXVCCDGW2y4q5On9DSOqyGbSkrlOLshL5en3Gqg404XHH+Tfb1mOw3z2/ev9xpVz+fZTh7j70X38+s4LMegH/h/kmydaURRYVzKyTVabw7e7pp0LI7/XWlavX5474vgvXlnK84cb+c8Xj9PZ52dZvotl+U7y06woisL3/lbBtgNnuG7pHL79/sXjVmsWZtgozrDx+rEWVFUdcXwgGOLzj+5FVeGr1yyKtiPHq98f5H9eryYn1cyHVudjMer56NpCHtt9ml+/eZJPXzJ2IDmY1totYwWEEEIIIc5+Z9/fAIQALIsWUfzoo9R98Yv0vPoqhEa2WtUO+2fFZsOQFg779OlpGNLS0adHAsC0yOfStc+lo7Pbp+W1CCHODhcWp3Pgn6/BPsvCs4+sKeDbfznMvtMdfGJDccxZcWeD2y8q5HB9J3/YU8t3nznCd29cAoQr6t6samVJnpM0+8iZgisLXRj1CntOtsNl4c/9df8Z0mzGmGGsxajnhx9azid/u4f/eX2gii/DbqI40867p9ysLU7ngVtXoNdNLPjatDCL3+08RVVLLwuyHUMe+8WOap4/3ATA9oombl6Vz5evXshcl3VC5x7usd2nae3x8s/XL45WJ377/eXsqm7j/ueOsrE0k7I5Q6tMOz1+nj14hurWXpq6+mns7Ke520tTVz9Oq5HnvrQJp1W2fwshhBBCnM1m199ShJgEU0EBJU88gRoKEerrI9TVRbC7m2BnJ81VVbj0eoLtboLudgLtboLt7QTc7QRaWvAePYrq8419/uJi7Bs2YN+wAdvategdEvgJcb6bbeEewA0r5vL9ZyuZ47Twzc1lM307cVMUhe/euIRTbX38bucp5mc5uHN9MYcbuujo8/PRtbErJy1GPcvyXbxT4yYYUqlu6+doUzcfXVuIUR97EsnKwjTe+cerqWrpYX9tBwfqOjlQ18HBuk4W5aTwiztWD2ntHc+m0nDA9/qxliEB34nmbv5z+3HmZ9nZevMyfrT9GH96t46n9zfwifXFfPay+ZNahOINBPmf16rJdJj56NrC6OdtJgM/+vAKbn7wLb70h/d46vMbMBt0vFfbwaNvn+avBxro9w/8jzCn1UhOqpkF2Q4O1HXy+J7TfGbT/AnfhxBCCCGEmH1m399UhJgkRadD73CgdzjQ6g8MubmkFRSM+hxVVQn19hF0t4eDv/b2cBjY4SbQ3k6guYW+d97B/cgjuB95BAwGrCuW49iwAfv69ViWLEHRT/wvf0IIMVWcViN/+fwGnDbjpEKp2chk0PHz21fzwZ+9yXf+epjCDBuVZ8KbdWPN39OsKU7n3VNuKhu7ePlEBxC7PXcwvS48929hTgofujD87wtfIIROYUh78ESsm5+BUa/w+vEWPrlxHgDBkMrX/3QAfyjE/bcsZ3VRGo98+iJ2HG9l67OV/M/r1fxhTy3/+ZEVXL5oYgtR/vhOHY1d/dx3XdmIr/WKAhdfvLKUB7Yf4/OP7KW+w0NlY/i9W1no4qNrC7loXjo5qZboc72BIBu2vsJv36zhkxvmTfp1CyGEEEKI2UMCPnFeUhQFvcMersobJQhUVRXfyRp633yT3rfeou/tt/G88y4t//VjdE4n9osvxr5+PfYN61GDwZjnEEKI6VCak9hct9nEaTPy0F1r+MBP3+SeR/eR67RgNoS35Y7monnp/Py1KvacbOel4x1kpZi5aN7kW5VNhvgCLrvZwOqiNHZVt9HvD2Ix6vn1GyfZd7qDT2+cF713RVHYtDCLjQsyeXp/A//y18N86rd7+Na15Xz6knljzsLzB0M8+GoV6XYTt11UFPOYz102n1ePNvNSZTMpZgMfv7iIj64tZHFe7MUwZoOeO9YV8cD2Yzx7qJHrl+fF9fqFEEIIIcTMk4BPiFEoioK5ZB7mknmkf/x2VJ8Pz/799Lz5Jr1v7aT7hRfofn5gi2+l2YzOakVns6HYrOhs9ug/66xWdHYbOrsD+8aN2NevQ9FJpYQQQsQyL9POz29fzR2/fpvjzT1sXJA5ZnXiqqI0FAV+t+sUdZ0+7lpfPOH5ecmyaWEWu6rbeafGTZ7Lwn+8cJTiDBtfvWbRiGN1OoUPrJzLykIXn3r4Hb73twqONnXzvQ8uwWyI/TqfP9pBfYeHr79v0ait4ga9jl/duYa3q9u4dFEWNtP4/5l320WF/OSVEzz0xkkJ+IQQQgghzmIS8AkxQYrJhG3NGmxr1sCXvkTA7abv7bfp272b7voGLBCeBejxEOrrI9DSgtrXR6ivD9Xvj56n/be/xZiXh/Pmm3DddBPG3LHbyIQQ4ny0bn4G3/vAUr7x5wNcWT52C6vTaqRsTioVZ7qA8dtzp8Km0izuf+4orx5tZn9dB75guDXXaho9mCzKsPPk59bzhcf28ad36zjZ2svPb19NVop5yHGBYIjfv9uM02rkjnWxq/c06XYT1y6d+OvPcJi5aeVc/rCnlndPuceslBRCCCGEELOXBHxCxMmQlkbq5s2kbt6Mv7aWgrFm/vn9hDweAi0tdP71r3Q+8SSt//0TWn/yU+yXbMSx6VIUoxFFrwOdPvyrwYAhPR1DVhaG7Gx0KSljtm8JIcS55tY1Baybn0Gu0zLusWuL06g400WOw8jKgukPqRbnppLpMPPwzhr8QZW71hezdl76uM9LsRj51Z1r+MFzlfzi9Wpu/MkbfGRtIe4+H+294Y+mrn4aunx86apSUizJ33b7yY3z+MOeWn79xkkJ+IQQQgghzlIS8AkxDRSjEb3RiD41lewvfYmsu++mZ8cOOv70Z3pefZXe13eMfw6zGUNWFkGnk7r8fAzZ2ZHwLwtDZhY6swkMBhSDEcVoQDGEPxj2z4rBAEZj+PfSJiyEmOUK0m0TOm7tvAwe3nmKyxc40U1zey6E2243lWbyxL56CtKtfP19I1tzR6PXKdx3XTkLc1K474mDPLD9WPQxm0lPut3EhfkOPrFh3lTcOgtzUrikNJNnD52htr1vwu/5RNW5+3j9WCv7azu4sDiN65fnnfULYYQQQgghZhsJ+ISYAYrBQMrll5Ny+eUEWlrwVlWFF3WEQgO/+vwE3e34m5sJNDcTaGkh0NxCoL6e7sOHk3MjOl009NOnp2MqLg5/zAv/GjIY8MfaFqzXo5hM4apD7VepLhRCzKBrLsjhH64rZ33uzP1ZdMOKPJ473Mj9Ny8fdU7eWG5Znc+GBRm09fhIt5tIt5uiQVhtbS1Oa/Kr9zSfvqSEHcdbefitGv7x/Ysn/Lweb4Auj5+QqhIKQVBVCYZUTrf38vqxVl4/1kJ1a2/0+MffqeXftlVw64X53HZREcWZ9ql4OUIIIYQQ5x0J+ISYYYasLAxZWRM+vra2lvycHAJtbZHQr5lAaxuqz4caCEQ+/BAIoPoDwz4XjH2M30+gtZW+PXvofeONIdc7MdEbMxpRjEZ0g0M/kwkMehRFB4oCOh3olPA/x/i9T4W6jAx0Dgc6ux2d3YY++nt7+PO28O8VY4w/vhQdismIzmRCMZvD96F9SLWiEOc0o17H320qoba2dsbu4bJF2Rz6l/clVEGY67SS67Qm8a4mZlNpJqXZDh7fU8uXrl44oec8vuc03/7LYXyB0KjH5DotfPjCAi5ZmMnyfBcvVjTx+12n+OWOk/xyx0kuKc1kQ4GFVQE7BelWslMs074gRQghhBDiXCABnxBnIcVkwpibm/QFHWooRKCxEV9NDd6TJ2mvrCTF7hh5XDCI6veh+vyofn84XPT5Bn4/+HOhEGowEK5KVFVQ1cjvQxAa9PtgiKDHQ7fHk9TXFGUwhIO/yEdQp3DCbEbR6VEM+sjsQ324OnHIr7qBgBKG/KqYTOjMJhSTORwomk3hFmmdAsNCTF9PNy1OZzhojDw2+Ljw7xXQ6SNhph29Fmo6HOjM5nC7tSFyXwZD+Pom09S8X0KIuMxEe3AyKIrCJzfO41tPHOT/9tRyddHo/4kYCIb43t8q+M2bNcx1WXnfBXPQ68KvXa8o6HUK6XYTl5RmMj/LMaTC+xMb5nHX+mJ2Vrfxv7tO8fzhJnYcV+HlOgCMeoU8l5XiDDt3X7GANcXjzzEUQgghhBAS8AkhBlF0Oox5eRjz8rCvX09vbS05YywPSbba2lry584NbyPu7Q1/9PQM/L63l2BPD6HePggFRzxfDQbDoaPPh+r1RkJIHyGvbyBw9HrDn+vrRac3QDCAGgyh+nwQjLRIB4NDfw1FqlNUdeBaqhrejhwITPj1tSb8Do1kyMnBNG8e5pJ5mIrnYZo3j2AggNfrHaikHPaBwSAt1UKIET64ci7//vxRfvPWSa4oWBDzmE6Pn7sf3cuO462sLU7nwdtXkeEwxzx2NIqisH5+JuvnZ9LU1c+L+07g0dmoc3uoc/dR2+5hZ1Ubb5xo5d7NZXz6knmj/plV3+HhpYomNpVmSbuvEEIIIc5rEvAJIWYVRadD73Cgd4ysHEym2nE2H0+UGgj8/+3dd5xcZdn/8c81szXJpjd6qCaCiCBKEYiKosbeHlREsIAI+nvUR40FOz4RsaOAoqKiPPIDxJ8E2w9EmqCg0kzoC6mk960z1/PHfc/u2dmZnZktk8zk+3695jW7c+5zrnOfueds5spdYhKxq6/3Yl8vxWy27+dVK1cye9asxDYHzw4q572ZRIJzG9lt28hs3RYSk5lMSEj2ZvBML97RQfdTT9Nx//3suOuuAef1RInzHpDwa8pLAjY0hp6GqVR/D8ZUquBrnZkMK/fak4Zp02mYNo2G6dNIT51GqrUllLXYOzGVwpqaaZg5Y8zfWxEZnpbGNO944b589+bH+OatK3jVkU08Z69J7DGpBTPjibXbeO9P7+GJdds59eh9+OLrDqOpYWTTH8ya2MKJB0wadD9+5JmtvP/Ke7ngxiXc+9RGLnzL4UxMrCC8uaOH79/yGD+5o53u3izplPGG5+3Fh15yMPtOG91FQkRERERqgRJ8IiIjkFukJDVu6C+U6eZmWsaoN6S707tmDd1PPknXE0+w8ellTBw3LgyVrvjRTbZjRxg+ncmEYdWZTP+Q6txr2SxkMmS7uticGdybciip8eNpmDWLhlkzaZw5C2ttwVJxWHTK4nDpFKTiEOlUOgx1Tqfp3rqV9VOnhjK5ss1NpCdOJD1pEqn4nG5rC8nLVBhebX1zQCZ+F5FB3nnsflxz73J+89AGfvPQBgCmjm/i0D0nct+yTWzr6uVzr3k2Zxw3Z0w/R4fMauP/nfciFl57Pzfcv4qlq7dwyWlHceCMCfzi7qf4zk2PsnFHD3Nnt3HGcXP4zb9Wcs29y/n1P1fw5iP35ryXHDTqqwGLiIiI7Mp26wTfkrnzDgZ+CkwHNgNnzFu6ZJSWJxURqQ4zo3HWLBpnzWL8McewfdkyZlRpaPXTTz/NXpMmhUVf1q0js35936IveK6nYuitmN3RERaFWfMMPaufofO++9mxY0fFMdeM1smn+hd/yfVOTD5nDR7J9WZMp0MyI50e2JMxl5hMbkvHhOSABGWq/zjpOA9jYltnZyerpk8j1TqOVGsrqXGtWEtLSFLmsXScp7GtjXRbG6kJbaTbJmDNzSFOPJe+n3N1UlJTyjCzrYVbPjaf2+5/jHW9rTy4cjMPrdzC39s30NqY5oozX8CJh5S/MNRITGhu4Ltvex7P328KF9y4hNd/7w5mTmxm2YYOZk9s4Wtvnscbj9ybdMo49QX7ctcT6/nGnx7hV/cs49p/LOeUw2Yz/5AZnHjIDGZNbKnKOYuIiMiuY87CxYNyPu2LFtRtzme3TvABlwE/mLd0yRVL5s57M3AFcPTOPSURkdphZqHH3KRJNB9wQMX7Z7Ztx7u7Qs/AbByynMlCNjH/YW4YcybD6pWrmDVjeijjYc5E7+oms2Uz2S1byGzeTGbzFjJbt0BvZmCSMbm4S0w6elzoJRkjt+hLZ0cHTY2NA3syxrLh/LJ4T9egbZ7NQCb/mIkyyXkdEzaNxhsylEQy081YmkhMDkwM2oBh2dbUhLW2kmpuxlpbSLW0hkVlcovQpBv6ni2dgnRDSGY2pLFUmq4d21k7ecrgMunUwEVtkgveDHhOYQ0N4XnQ/gOPY+k02TVr6Cm0YE48Xji3Bq2sPYTmhjTPmjGOkxP/UdCbCW22IV3d62ZmnHH8/hy+z2TO+8U/2Li9h4+d8izeffz+tDalB5Q95oBp/OqsY/jr4+v51k2Psvj+VSy+fxUAc2e3hUU/2pw9O9bSk8nGh9OTybK9q5dNO3rY3NHDpo4eNu3ooas3w/7Tx3PIrDaeNbuNQ2a2MWnc4KR7OTp7Mjy4YjP3PLWR1Zs7OXrOVI4/aBqTx2mhJBERkTF0GfCD9kULrpizcHHd53x22wTfkrnzZgLPB14eX7oWuHjJ3HkHzVu65LGdd2YiIruP9ITxQPkT46fb2mitUu/E0ZqnsZhk8m95ezt7Tp9OdkcH3rGDbEdH+DkTF3HxxI6Z3rDYzNZtZLdtJbN1G9mtW8MQ62xm0OrUfYnMxFDrju3baWluimUzfYnOAfvnzq+7O8wFuW4d2c5Osp2d0NNTUV3HYoGZoZT9RzyX6IvPhVfSThdOZqZSdGUyPNXa2pfMzD0XWpnbGhtDsrS5GWtqDAnTxsbQm9PCKtp9q2kTe14a8fUUPRs3snHqtJiAjeX69iWu0J3bt0SZxMPSDaRamrGW1vAck7m+aRO94xOfzdgDtNCyQtbYRKqpERobx6yn6JH7TuGmj84n486E5uL/fDUzjjtoOscdNJ21W7u4/bG13PbIOm59dB0/vO3JWKq9ZLyGlNGQNm57dGDrnT2xhanjByfl0ilj8rhGpo5vYur4JqaNb2LSuCYeal/NIxue5sEVW+jO9Cf2r7iznZTB4XtP5sSDp3PiITM4ZHYbbc1aBElERGQ0zFm4uGDOZ87CxQe1L1pQlzmf3TbBB+wDrJq3dEkvwLylS3zJ3HlPA/tSwXcDERGR4egbDgxYaysNU6fC1OrEHmnysi/5l1htuv/nbFgMJpuF3l5WrVjBrBkz+haRIZsZ/Jy/cnXyOJlsSHQOeB58HM9moDfDls2baGsdF89xiP1zPSp7e4uUHbyitvd0hucYy3t66HIfcJxc+UK9NEdq9agfcWiPDmMfa2oKj9jrMpeozPUKJWUYA4eO92QyPN7U1N97NNfbtKEhLvzTgDU2hARiQyObBrzeGLYRk2K55GX8+ViD48z4WAoem9DKvdtTtLa00GhOgxGfnXHmTEplmJjK0mZZxpmDGWu8kcd7m3g808Tjvc08saOTLdvTg+rdi/FYNkWHD+7h2JbK8vzmbp7b0sVzW3qY0ZDh3s5m7t7RzN0rsvxr2Sa+c3P4p2ezOVPTWaY1ZJmWzjIpnSVtkAJSBimctIWcf9aNDHF6VKC7u5vxzU00mtNo0GBOA+Bm9Dj0eP9zLlZTKjy3pJzmkBsu246ODsa1Vmeewx0dO+oyVrXj1WusasdT3WovVrXj7cp1e8XLj+KAZ1c+6qZG7QOsal+0oBegfdECn7NwcV3nfHbnBF9ZzOwjwEcSv7Ns2bKdeEaja8OGDYpVY/HqNVa146lutRer2vHqNVZV46XTbJowgVRra3XiAds3bKB5amWZUst7LteGDRuYWiRWcjEaMpmQAOzuDr0fcytu51bd7nsQVteOP3vi561bNtM2YUKiDECMUfBnx8kNT/eC28O2DN7VBV3dYbh8/Lmzo4OW5uZwjL5K9VUu8Vo2DIePC/XQ0wM93SH5mqtXNht2TawYnjyHTDaLZTN4b2518cS16+3Fe3uhtzf83tMz7OTpdOCUMsp1xgeEfyg/Kz7K0ZVqYEvzeDY3TWBz03imdW5h363PkBrQDRdOiI+MpXhk8j78c+bBrB43lY3NbWxqaWNVcxtLmieQSQ1OJhbXCh0VFB+x8WE2o6oYV6exqh2vXmNVO57qVnuxqh1v163blDvvo7FteNNN7IJSZrY88fs33P0bO+1sdgG7c4JvGbDHkrnzGuYtXdK7ZO48I2Ryn04Wig2kr5Gk02kfyyFbO0M161Ovsaodr15jVTue6lZ7saodr15jVTue6jZyYz1kfGfGqzSWZ7Mh6dfTg/f2hsQigHtIrPbl0rw/GRmTjStXrWLP2bMTOcrBZQYcKxbpO2iFZVavXs2smTP7y/QF7i9zoDuv9IEJQICsO9t7nIxDJpslS+yt5yEZnY497tIYKYO1a9cwZdoMerLQk3V6stDrWVIGjSmLj/AzQFdvlq6M05lxujLQmck7hwLnlNy2cdMmpkyeXLzMKKrXWNWOV6+xqh1Pdau9WNWOtyvX7dDnHcK0PaqzWFYVZN197yG2LwP2mLNwcUP7ogW9cxYuLpjzqSe7bYJv3tIla5bMnfcP4DTCRItvApZr/j0RERGRXVdu8ReaKl+gIpXJ0LjXXmNwVoWlJ0wY0byh5c9QCj3LlrG3ksA1Fava8eo1VrXjqW61F6va8eq5brWkfdGCNXMWLh6U86nX+fdgN07wRWcDVyyZO+9TwBbgzJ18PiIiIiIiIiIiMnJnA1fMWbh4t8j57NYJvnlLlzwMHLuzz0NEREREREREREZP+6IFu1XOZ/BSXyIiIiIiIiIiIlIzlOATERERERERERGpYUrwiYiIiIiIiIiI1DAl+ERERERERERERGqYEnwiIiIiIiIiIiI1TAk+ERERERERERGRGqYEn4iIiIiIiIiISA1Tgk9ERERERERERKSGKcEnIiIiIiIiIiJSw5TgExERERERERERqWFK8ImIiIiIiIiIiNQwJfhERERERERERERqmBJ8IiIiIiIiIiIiNUwJPhERERERERERkRqmBJ+IiIiIiIiIiEgNU4JPRERERERERESkhinBJyIiIiIiIiIiUsOU4BMREREREREREalhSvCJiIiIiIiIiIjUMCX4REREREREREREapgSfCIiIiIiIiIiIjVMCT4REREREREREZEapgSfiIiIiIiIiIhIDVOCT0REREREREREpIY17OwTqDXZbBYzy+zs8xhFKSCrWDUVr15jVTue6lZ7saodr15jVTue6lZ7saodr15jVTue6lZ7saodr15jVTue6lZ7saodr57rtitJ7+wT2NWYu+/sc5CdyMyWu/veilU78eo1VrXjqW61F6va8eo1VrXjqW61F6va8eo1VrXjqW61F6va8eo1VrXjqW61F6va8eq5brJr0xBdERERERERERGRGqYEn4iIiIiIiIiISA1Tgk++oVg1F69eY1U7nupWe7GqHa9eY1U7nupWe7GqHa9eY1U7nupWe7GqHa9eY1U7nupWe7GqHa+e6ya7MM3BJyIiIiIiIiIiUsPUg09ERERERERERKSGKcEnIiIiIiIiIiJSw5TgExERERERERERqWFK8ImIiIiIiIiIiNQwJfjqkJndYmbdZrbNzLaY2YNm9p4S+8w0s5+a2ZNxv3Yz+28zay4j3v5mdpWZrYz7rjSzG81sjxL7XRrLJx9uZt/Oq8dWM9tsZsvM7HozW1DmdXgo79g74vHfkCjjZtZhZpn4s8d4FcWKxzrWzG6O+28yszvNLJWoR08izsMV1ONUM7stvpduZg0FyhxuZrea2fZ4/T9vZpa4jsn6ZeP5XF1G7EvN7KkYe42ZXWtmcxLbP1XkPcwmfl9hZhebWWuJWM0x3iPxGi6Pv08pUddvDbP9nW5md5jZBjNbH6/T8UXKNiSu/7bhtMe84/06Huvk+PstsX30xmuXNbONZvaFMo83Gm0km9dGevI/L0Vif8jM7o6fr+UFts+Jx9me104mJcpUfM/KizHRwj1rUN0LHPshMzu7zOMOWbdY5gzrv9fsiO9hRbHKbfuJ8kfF9+f2UazrwWb2WzNbFz8TfzKzw4scu+zPddy31H3k/kS7dzPrMrO7yv1slWr/ZnaAhc/6uljmcTM738xSRa5b7jgnlxG7ZBtJlH1dPG7Ghv93bZaZ/dLMnrHwd+avZnZSXplkm3zUzN5dzrFFREREpLYpwVe/LnT3CcAUYBFwuZnNH6L8BOBh4GRgYnxeAHy1jFg3AluBw2LM5wG/AoZcotnd3+/uE3IP4Li46ed59Whz90nAUcAfgf8xswtKnZS7H5p3/IXAeuB3eUVfA9wGXODu5u5tlcYys2Pjca8AZgHTgQ/Tfw2+DnyccF3vBZ4o99jARuD7wH8Wid0G/AG4I8Y9BXhvXvk7gDvc3YADgMfjo5TvEt7XicD+wFPAtbmN7v6VvGu8f6zzdYnXjgdeCny2RKyGWNfXA5OBo4GDgZ+UqOu5wBwqbH9AG/BFYD9gNnA98Hsz27tA2U8BvfHnI4bTHhN1OB0YV2DTYuA/gGnAnoTr/Fkz+1EZhx2NNvKV2P5zbWQ90MHgz0u+lcCFQKlr8NxkW3H3zXnbK71nJX2LcP8qJnfsycAXgEvykyJFDFk3C8nPbwPvI9w3HyG0u7dXGKtk20/EbCHcZ/5S5FjDrev/AJ2Ez/AewIPAjbkkWPLYFX6uocR9hFD/6whtvwE4j/D5uno07pHAWuDdwKx4Di8jvEfn5tcN+CDh/gxwOKWV1f7NbDqhnW4B/j3cv2uEeu4DHEa4XtcAN5jZ1Bgnv02eBVxsZq8t49giIiIiUsOU4Ktz7p5x9ysJX9aPGqLcEzFZ87i7Z939MeDHwIuHOr6ZTQPmApe6+4Z4rGfc/afuvrrC0/0A8Dd3v6fIOa5x99yXuIVmdlCFxz8H+JG7d5YqOIxYF8Zj/8zdd7h7r7vf7e65JFPG3b/p7n8GthGSfGUd293/4O5X0f+lM98bgTRwvrt3uPsDwNcIX5ILHa8d+D1lfHl194fcfWvipSzwrCF2eQ/QQyLZUm48d9/u7p9093/HdruKkBhItsEBdSV8uW4A9q60/bn79+K13eruPe7+LSBDSK70MW0iDOUAABKcSURBVLMjgdPJS4gOpz3G5OGXCV++8z3o7te6+0Z3X+3u7wWWAWfupDbSCKwq9Xlx92vc/VpgxVDlylXuPSvHzF4DPIdQn1LHzrr71cAG8t7nIuVL1e1U4Cp3v9Pds8AmYCnwwUpildn2cy4AbgJuL7AtecyK6gocBFwZPw9dwI+AvYAZRY7fzujdR9YAS2Pbz7j7D4GHgN8yCvfIWKeH3T2Te6nAOeQ+n18Ccsmwoe51uWOX2/4vIyTeOvL2r/Q+chBwjbuvjfW5jPAfdAfH7QPaZPybcx0hcSkiIiIidUwJvjpnYWjhO4GpwN8r3P3lwD+HKuDu64EHgMvM7EwLwwArbldmNhF4B6F3Qim/jM8vreD4LwEOAS4tsPlKQm+U95hZfuKlZCwzG0fofZgxs79ZGO55r5m9qcRpVVyPIo4A/unuvYnX/g4cEK9rzvPMbK2ZrSD0ZnmgnIOb2TlmtpmQmPw/wGeKlEsBZxOSbp54/UDglcCt5VepT34bHFDX2P4eB/aO5zms9hfP84WEL8r3JV5rBn5KSD5niuxa1vtoZkZImn/Z3Z8u43z2JSRXvNSxy1BuG8nFfgfhnvF/Rxg36S9xiOSdNsSw30ruWfE/GC4GzqS/h+VQ5RvM7O2Enk9LKjr7IoeMj/zXjhyFWIPuv2Z2IvBqQo/SoU+s8vgXAO80s8nxnnY2odfvM0WOX9Hnutz7SCy7LyG59uP40kjbf+64t5lZByEROBH4Xl6RHwNfAV4Ufy/5OS0z7mnATOA7QxQr9+/BV4HXm9keZtZI6IX4OHB/LhyD22QKOLKikxYRERGRmqMEX/36LzPbBKwm9Aw4093LTrCY2fmEoY5Fv4QlvJgwjO8c4G/AOjO7yMqYvy/hdKCLMLRySLHn1jrCF9dyfQD4vbs/mff6yYQhY3cCtwAXmtk5FcaaSvgsvYvwZWsW4cvyVXHo7mjWo5CJhJ5DSRsT2wBeSEiAtBKGf3YCbzWzCaUO7u6XxKFkexGG/N1XpOirgL2BVcT2Z2bbgMcIPXTKSd72iUNZ30lIBuQUqutp8fkshtn+zGwfQttb5O7JXkBfAu529z8W27eC9/EcwNz9B2WczyTg14RhjNVqI8n37EpCz6+yhx4PYR0hAb4/YWjhJYThiK/KKzece9YlwA/d/cES5XLH7gR+BnzC3RdXWI9CrgfeZmYnWpj3bQpwKOGeMOxYhdp+/Kz+GHifu+8YYvfh1vUPhM/4BsKUC68iDOMedOzhfK7LvY8k23783I1G+8+dwwmEJP7xhKkg1iQ2f4Lwt+xiwnUDuHukMc1sL0JS7t2xl2excyv3PnIH4b1dSegN+FHgXXF/yGuTZvYywtDvQYl8EREREakvSvDVr4vcfbK7T3f3o9z9p+XuaGZfIiRL5rv7kJOGQ+hF5e6fdfcXAJMIvcPeB3yygvM9B/hJOcNnLUzqPoMwhK8kM9sTeB0Fvoi6+03xi5ETekF8m/DFupJYuaFnV7j73+Pw3OuAPxO+WI1KPYawhTDfVtKUxDaAr7n7JA9zTM0kDO+bQ/+8hyW5+0rgB8BiM5tVoMgHCF8uu+lvf7l4zxASCGUxs7OAbwKvcPdkIqBQXXP3sZMYRvuLQ+JuBa52988kXj8OeCvwkRL7l3wfY2+n8xmcMClUdgZwM2GY8/tLHbtM5bSRi9x9MqGnay/wbyp4z4px923u/ld3747Dg38OXEV/YjanonuWmZ0KHEiYr6+UXN2mEOave7kVWIikUu7+S0JvuksI87ztQ0gyrx5urCHa/kXAjWUkPSuuq5lNJtyvbibMTTmOMO3AHfH+OeDYw/1cw9D3kby2f8Yo3iOT8TPufich4Z1LtrcQkmYH0X/dYHT+jfQj4Ovu/uhQhcq8j6QI12c1IRHYQrjX3WhmR0DBNvlxQj3XjbgmIiIiIrJLU4JP+ljwPeBtwAnuPtSk9QW5e5e7Xw/8f8ocEmRhIv15hC8k5XgbISF3c5nlzyLMZVZqsQAI8zIlhzeVjOVhsYDHKb2oQ75K61HMvwjDb5Nf4p8PPOHuW/ILu/taQu8Vo/JeHY2EXoD7JF80swMICzcUSqKuJQxzPTYOqRySmX2CME/dye5+R97mIetaafuzsErobcCP3f3jeZtfTuiN+YSZraN/Pri/xR6uOeW8jycQvpDfG4ep5r5sX2tmfT36Yk/C2whzNJ5GSDBWu43kPi8XUuZ7Ngz5n7PheAVh/s/V8Xr+Jr6+2szeVWiHOA/cuYRFRM4tVKZS7n6xhwV9phCGSU4CbhpOrBJt/xXA6Yn283HghfH3QfO2VRj/QEJi66I4H2CXu19GeI9OKFLvij7XeQrdRyaSaPtxOPlo3SOLnUNujr3JhKTmvcCT9P/HzG+Sn89hOgX4dOJ9mwnMi78nexmXU9cphPfzO+6+If5n0m8If39OyRVKtkl3fxlhIaGbRlgPEREREdnFKcEnQJiviTAsbz4hudde5n5TzGxRnPus2czSZvZSwlCncocEfwD4Q97QyEKxZpjZ2YSVCL9WqkdE3KeB0MPhsvzhUWZ2pJkdZWZNhC+y+xOGBl41jFjfJfQ4OcLMUhZWLDyJMLl5Ll6zhRUwmwnJom9RXs+OdNyvKb7UbGYt1j/X3HWE+eG+YGatZnYY8F8MnF9qnoVVHDGzQ2LsDEP0vjGz6WZ2hvWvzrgPIYG3jLDCZtL7gYfjhO75x5lC6BW5LM6ZN1Rdvwp8CDjJ3QvN/5hf1+MIw2ivq7T9xX1vAb7q7l8qUOQbhInrj4iP3JyFrwW+XWEbuZrwxfyIxAPCPGcL489TCcPvbgQ+TWi3ZbW/UWojyc/LzwgJxnLes4YYuzH+3hIfFn8/wczmxXNsMrO3EVYwvWqo45bhw4QETe565npHHkVYWbQgDwtIfBE4Pw4HHUnd2szsOfEzP5EwRH0/whDUSmOVavvHEFZOzdX3UsIcfUcA7SOs61JCD68Px/o1mNl7CL35ig2lLetzXeZ9pJUwxcGN7n4WMK2S+2+p9m9mLzOz4+I9osHMXkwY/nxjLL+GMDQ3//PZQ+nVcYdsI4Qk5nMTx11HGN58hLt3VXIfidd5CXCumU2M7e7VhGHh98b4A9qkmX2U8Hf9C0PVQ0RERETqgLvrUWcPQtLiyxXucxKh90AnYRL0vkeJ/cYDlxOGVG0lDHt6kDCfkZURdzZhSOdritSjO57HFmA5oZfOayuo15tinaYX2PYawpelbYQhidlYdrixPkn40roV+Afwurx6ZOM1Tj5uKeO4ZxTYzwlDqHNlcj3RdhCGb30+d/1j/GTsDGHFx1eUiDuN0BNuPbA9XpNfAgfnlWsmDAX7YIH3bVvc9lvg0BLx9ovnl9w399i3SF2fide64vZHGJKYLRDrU0XK3xXPb/tw20je8ZzQUyt3zTKJ9ygb22QHYYXqarSR7hjPCUmIku9Z3PfzRWLPidvfS+hhtJ0wv9tdwFsKfNYrumcVOI/5MW5DqWMTVhR+GPjKCOu2FyEBtjW2ifWE/0yoKBZltv0C53b7KNb1aPo/75uAe4A35h17OJ/rkvcRwrydyeuba/+/K/O9P6PI+zQ/bn8joXflNmAzYfj5Z3Jtpch1c8L9fERtpED51YTP+rD+rhH+0+F6QlJyC2G14bMS2/Pb5GLgsJF8tvTQQw899NBDDz30qI1H7sudiIiIiIiIiIiI1CAN0RUREREREREREalhI15FUGqDme1LGJZUyP3uXvZqqhXEvJTBK2XmnOruN4zw+A8RhrYVspeHxS9GxVjGqmY9CsTeVmTTJnffu5bjjXX7KxBPbWR04475PavK7XGnXMdqxB/ruu1O7X9n1lVEREREapuG6IqIiIiIiIiIiNQwDdEVERERERERERGpYUrwiYiIiIiIiIiI1DAl+ERERKRumNlrzOw2M9tiZh4f83f2eYmIiIiIjCUtsiEiIiJ1wcyOAK4l/AfmzcAqwIHVVT6PW4CTgBe7+y3VjC0iIiIiuycl+ERERKRevB5oBL7i7p/e2ScjIiIiIlItGqIrIiIi9WLf+PzoTj0LEREREZEqU4JPREREapqZfd7MHDgzvvSTxPx7tyTKTTGzL5jZv8xsq5ntMLMHzOwzZjauwHHbzOx9ZnadmT1qZtvj4wEzu8DMJueVnx/P46T40p8T5+FmdkayXPLcCsT2eKyir5vZmWb2VzPbHF+fkyi3p5l9w8yWxHpuNbO/m9l5ZjaiERxmdkWuPma2v5n93MxWm1mXmT1uZl82s+YC+1V0PRP7tefqZ2avNLNbYp03mtkNZvacRNm3x2uy1cw2xVgHDlGXMbtOIiIiItVk7oP+7SgiIiJSM8zs9YThuS8CDgTuAB6Lm5e6+yIzezbwe2Afwtx89wE9wAuAWcC/gPnuvjlx3BcBtwFrgYeBFcAU4ChgWoxxjLuvj+XnAguBV8Rj/oGB8/9d7u63x0U//gz8xd3nF6mTA7i7FXoduBj4AHAnsAw4APgPd3/KzE4Ero/n2g7cDzTHuk4B/gi82t17il/V4szsCuBdwLcJSdWNwN3AVOB4oBW43t3fkLdfRdczsV87sB+wCPhErPMK4AjgEGAT8HzgbODDwK3ABuCFhPd7JXCYu2/MO+6YXicRERGRalKCT0REROpCIvF0prtfkXi9FXiAkPz7MvAld++O28YBlwNvA37i7u9O7Lc38Czgz+6eTbw+DrgEOB34vrufm3cetzDEIhujlODbApzi7nflbZ8NPEhItp0LXJY7dzObBlwNvAT4nLt/sVDsUhLXGeCCeKxM3HYYcBcwHjjO3f+a2G+417OdkODrAha4+03x9TRwFfCWWOc9gJe6+32J4/4JOA74jLtfUM3rJCIiIlJNGqIrIiIi9e5dhOTeDe5+fi65B+DuO4CzgDXAO81sSmLbcne/KZmMSuxzDtBLSC7tDBflJ/ei/yT0hvueu1+SPPfYM+50Qs/F88zMCuxfiXuB83PJvRjjQeDn8deTk4VH4Xp+J5fci/tlgP+Ovx4GfDaX3Esc9+vx15fmHaua10lERERkzGluEREREal3C+LzrwptdPdtZnYP8CrgaMLQzD5mdhxwAmERj3FALuHTDcwwsyn5wz+r4Joir5eq6wozexR4NnAw8MgIzuEGLzwUZEl83qvQTiO4njcWeO3RMrfvmfd6Na+TiIiIyJhTgk9ERETq3QHx+edm9vMhS8KM3A9mNhO4ljC331AmEuahq6b2Iq/n6npbGR3PZjCyxNXTRV7fEp9bki+OwvUcFC8mZ4c6n62FzoXqXicRERGRMacEn4iIiNS73JQkvweeKVH2qcTPlxOSUX8FPkdYmGNjbtEFM1tJmPdtVIdwmlnJKVTcvaPIpty+1wDbSxxmfYntpWRLFxlgpNdzyHj5Q39LqOZ1EhERERlzSvCJiIhIvVsGzAV+5O7FhrYOYGbjCUN2s8Cr3H1Tge2zh3k+uTkA24ps32+Yx4VQ14OBr7r7PSM4zqga4+s5HLvkdRIREREZLi2yISIiIvXud/H5rRXsMwlIA1vyk1HRaRTvaZZL4BX7j9QV8fkAM2sqsH1BgdfKNZy6VsNIrudY2FWvk4iIiMiwKMEnIiIi9e4HhKG3bzGzr5rZoJ5zZjbbzN6XeOkZwjxwk83snXllj6F/9dZClsfnQwttdPenCIs/TAY+kXfs+cAXh6zN0L4GbAI+YmYfLZRANLP9zey0EcQYjpFcz7Gwq14nERERkWFRgk9ERETqmrtvJ/SKawc+DjxtZn8xs1+Y2a/N7CFgJfClxD4Z+hNtPzOzu8zsl2Z2O3AncAMD5+tLujY+X2hmvzWzH5nZ5XH12JyFgANfNLN/mtnVcSXfm4HvjqCuy4HXEZJpFwHLzOwmM7synstjwBPAecONMczzGsn1HIvz2SWvk4iIiMhwaQ4+ERERqXvu/pCZHQ68H3gDcDhwLLCO0OPuIuDXeft8y8yeJCQFn03okbcUOBe4FHiySKzFsTfgOcBLgHFxUy6ZhbtfZ2avBj4FPI8wH9wDwKnufrWZfXYEdb3VzA4lJKcWAEcDzcAawkqzV9KfhKya4V7PMTyfXfI6iYiIiAyHufvOPgcREREREREREREZJg3RFRERERERERERqWFK8ImIiIiIiIiIiNQwzcEnIiIispsys4uA6WUWv93dLx/L8xERERGR4VGCT0RERGT39WZgvwrKK8EnIiIisgvSIhsiIiIiIiIiIiI1THPwiYiIiIiIiIiI1DAl+ERERERERERERGqYEnwiIiIiIiIiIiI1TAk+ERERERERERGRGqYEn4iIiIiIiIiISA1Tgk9ERERERERERKSGKcEnIiIiIiIiIiJSw/4XIhzlDxka7zcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python S4_feature_combined.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhWhXG1R3CsN",
        "outputId": "7f4bc9c9-bb7b-4d5a-b038-1639719094d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "available gpus: []\n",
            "----tmp1.shape------ (411,)\n",
            "----tmp2.shape------ (648,)\n",
            "----tmp.shape------ (1059,)\n",
            "----len(df)--before df.append(tmp)------ 9\n",
            "----len(df)--after df.append(tmp)------ 10\n",
            "----df.shape--all_feature.feather------ (10683, 6380)\n",
            "100% 224/224 [00:00<00:00, 456.05it/s]\n",
            "----df.shape--nn_series.feather------ (130000, 224)\n",
            "100% 208/208 [00:00<00:00, 293.27it/s]\n",
            "100% 1062/1062 [00:18<00:00, 57.60it/s] \n",
            "100% 1062/1062 [00:16<00:00, 64.85it/s] \n",
            "100% 177/177 [00:01<00:00, 174.25it/s]\n",
            "100% 141/141 [00:00<00:00, 302.88it/s]\n",
            "100% 885/885 [00:12<00:00, 70.36it/s] \n",
            "100% 885/885 [00:11<00:00, 75.24it/s] \n",
            "100% 885/885 [00:12<00:00, 72.34it/s] \n",
            "100% 1062/1062 [00:15<00:00, 68.45it/s] \n",
            "----tmp.shape------ (1059, 13)\n",
            "----df.shape--nn_all_feature.feather------ (10683, 6380)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python S5_LGB_main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmN35wMS1qIo",
        "outputId": "9e4d949f-5ab2-4c5b-ab66-bc30e26055eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "available gpus: []\n",
            "====S5====df.shape (10683, 6380)\n",
            "====S5====train_y.shape (5000, 2)\n",
            "====S5====train_y.shape[0] 5000\n",
            "====S5====test.shape (5683, 6380)\n",
            "====S5====train_y.shape (5000, 2)\n",
            "====S5====train.shape (5000, 6381)\n",
            "(5000, 6381) (5683, 6380)\n",
            "====S5====test.shape (5683, 6380)\n",
            "====utils.py====test.shape (5683, 6380)\n",
            "----features.len: 6366\n",
            "[50]\ttraining's binary_logloss: 0.491851\tvalid_1's binary_logloss: 0.486147\n",
            "[100]\ttraining's binary_logloss: 0.444213\tvalid_1's binary_logloss: 0.438194\n",
            "[150]\ttraining's binary_logloss: 0.42327\tvalid_1's binary_logloss: 0.416669\n",
            "[200]\ttraining's binary_logloss: 0.412982\tvalid_1's binary_logloss: 0.407476\n",
            "[250]\ttraining's binary_logloss: 0.387769\tvalid_1's binary_logloss: 0.381818\n",
            "[300]\ttraining's binary_logloss: 0.372751\tvalid_1's binary_logloss: 0.367349\n",
            "[350]\ttraining's binary_logloss: 0.360635\tvalid_1's binary_logloss: 0.356989\n",
            "[400]\ttraining's binary_logloss: 0.356959\tvalid_1's binary_logloss: 0.353764\n",
            "[450]\ttraining's binary_logloss: 0.35397\tvalid_1's binary_logloss: 0.351281\n",
            "[500]\ttraining's binary_logloss: 0.339023\tvalid_1's binary_logloss: 0.339207\n",
            "[550]\ttraining's binary_logloss: 0.333883\tvalid_1's binary_logloss: 0.33566\n",
            "[600]\ttraining's binary_logloss: 0.329441\tvalid_1's binary_logloss: 0.331951\n",
            "[650]\ttraining's binary_logloss: 0.319253\tvalid_1's binary_logloss: 0.325884\n",
            "[700]\ttraining's binary_logloss: 0.313254\tvalid_1's binary_logloss: 0.323409\n",
            "[750]\ttraining's binary_logloss: 0.305775\tvalid_1's binary_logloss: 0.318742\n",
            "[800]\ttraining's binary_logloss: 0.300247\tvalid_1's binary_logloss: 0.31716\n",
            "[850]\ttraining's binary_logloss: 0.292725\tvalid_1's binary_logloss: 0.314695\n",
            "[900]\ttraining's binary_logloss: 0.288939\tvalid_1's binary_logloss: 0.31383\n",
            "[950]\ttraining's binary_logloss: 0.288355\tvalid_1's binary_logloss: 0.314217\n",
            "[1000]\ttraining's binary_logloss: 0.283965\tvalid_1's binary_logloss: 0.313337\n",
            "[1050]\ttraining's binary_logloss: 0.280589\tvalid_1's binary_logloss: 0.311645\n",
            "[1100]\ttraining's binary_logloss: 0.274296\tvalid_1's binary_logloss: 0.308735\n",
            "[1150]\ttraining's binary_logloss: 0.273373\tvalid_1's binary_logloss: 0.308755\n",
            "[1200]\ttraining's binary_logloss: 0.269798\tvalid_1's binary_logloss: 0.308764\n",
            "[1250]\ttraining's binary_logloss: 0.266715\tvalid_1's binary_logloss: 0.308532\n",
            "[1300]\ttraining's binary_logloss: 0.264643\tvalid_1's binary_logloss: 0.307619\n",
            "[1350]\ttraining's binary_logloss: 0.263216\tvalid_1's binary_logloss: 0.308102\n",
            "[1400]\ttraining's binary_logloss: 0.258606\tvalid_1's binary_logloss: 0.307621\n",
            "[1450]\ttraining's binary_logloss: 0.256642\tvalid_1's binary_logloss: 0.306735\n",
            "[1500]\ttraining's binary_logloss: 0.254745\tvalid_1's binary_logloss: 0.306504\n",
            "[1550]\ttraining's binary_logloss: 0.249432\tvalid_1's binary_logloss: 0.305162\n",
            "[1600]\ttraining's binary_logloss: 0.245479\tvalid_1's binary_logloss: 0.304398\n",
            "[1650]\ttraining's binary_logloss: 0.242107\tvalid_1's binary_logloss: 0.303725\n",
            "[1700]\ttraining's binary_logloss: 0.240293\tvalid_1's binary_logloss: 0.303873\n",
            "[1750]\ttraining's binary_logloss: 0.238529\tvalid_1's binary_logloss: 0.303549\n",
            "[1800]\ttraining's binary_logloss: 0.237413\tvalid_1's binary_logloss: 0.304094\n",
            "[1850]\ttraining's binary_logloss: 0.234781\tvalid_1's binary_logloss: 0.303841\n",
            "[1900]\ttraining's binary_logloss: 0.232394\tvalid_1's binary_logloss: 0.303889\n",
            "[1950]\ttraining's binary_logloss: 0.229164\tvalid_1's binary_logloss: 0.303565\n",
            "[2000]\ttraining's binary_logloss: 0.226651\tvalid_1's binary_logloss: 0.303223\n",
            "[2050]\ttraining's binary_logloss: 0.224892\tvalid_1's binary_logloss: 0.303478\n",
            "[2100]\ttraining's binary_logloss: 0.223011\tvalid_1's binary_logloss: 0.303778\n",
            "[2150]\ttraining's binary_logloss: 0.222631\tvalid_1's binary_logloss: 0.304179\n",
            "[2200]\ttraining's binary_logloss: 0.220104\tvalid_1's binary_logloss: 0.303723\n",
            "[2250]\ttraining's binary_logloss: 0.217917\tvalid_1's binary_logloss: 0.303226\n",
            "[2300]\ttraining's binary_logloss: 0.215117\tvalid_1's binary_logloss: 0.303035\n",
            "[2350]\ttraining's binary_logloss: 0.213591\tvalid_1's binary_logloss: 0.301863\n",
            "[2400]\ttraining's binary_logloss: 0.21227\tvalid_1's binary_logloss: 0.302181\n",
            "[2450]\ttraining's binary_logloss: 0.210156\tvalid_1's binary_logloss: 0.301622\n",
            "[2500]\ttraining's binary_logloss: 0.209106\tvalid_1's binary_logloss: 0.301402\n",
            "[2550]\ttraining's binary_logloss: 0.207089\tvalid_1's binary_logloss: 0.300905\n",
            "[2600]\ttraining's binary_logloss: 0.205216\tvalid_1's binary_logloss: 0.300709\n",
            "[2650]\ttraining's binary_logloss: 0.203089\tvalid_1's binary_logloss: 0.300678\n",
            "[2700]\ttraining's binary_logloss: 0.200875\tvalid_1's binary_logloss: 0.30036\n",
            "[2750]\ttraining's binary_logloss: 0.199974\tvalid_1's binary_logloss: 0.300737\n",
            "[2800]\ttraining's binary_logloss: 0.19853\tvalid_1's binary_logloss: 0.300266\n",
            "[2850]\ttraining's binary_logloss: 0.195537\tvalid_1's binary_logloss: 0.299814\n",
            "[2900]\ttraining's binary_logloss: 0.194252\tvalid_1's binary_logloss: 0.299999\n",
            "[2950]\ttraining's binary_logloss: 0.192029\tvalid_1's binary_logloss: 0.300162\n",
            "[3000]\ttraining's binary_logloss: 0.19016\tvalid_1's binary_logloss: 0.30021\n",
            "[3050]\ttraining's binary_logloss: 0.188325\tvalid_1's binary_logloss: 0.300075\n",
            "[3100]\ttraining's binary_logloss: 0.186692\tvalid_1's binary_logloss: 0.300333\n",
            "[3150]\ttraining's binary_logloss: 0.185322\tvalid_1's binary_logloss: 0.300168\n",
            "[3200]\ttraining's binary_logloss: 0.183317\tvalid_1's binary_logloss: 0.299282\n",
            "[3250]\ttraining's binary_logloss: 0.181672\tvalid_1's binary_logloss: 0.300115\n",
            "[3300]\ttraining's binary_logloss: 0.180118\tvalid_1's binary_logloss: 0.300499\n",
            "[3350]\ttraining's binary_logloss: 0.178047\tvalid_1's binary_logloss: 0.300359\n",
            "[3400]\ttraining's binary_logloss: 0.175846\tvalid_1's binary_logloss: 0.300274\n",
            "[3450]\ttraining's binary_logloss: 0.173896\tvalid_1's binary_logloss: 0.300069\n",
            "[3500]\ttraining's binary_logloss: 0.172745\tvalid_1's binary_logloss: 0.300115\n",
            "[3550]\ttraining's binary_logloss: 0.17122\tvalid_1's binary_logloss: 0.300371\n",
            "[3600]\ttraining's binary_logloss: 0.169821\tvalid_1's binary_logloss: 0.300506\n",
            "[3650]\ttraining's binary_logloss: 0.168369\tvalid_1's binary_logloss: 0.299991\n",
            "[3700]\ttraining's binary_logloss: 0.165652\tvalid_1's binary_logloss: 0.299986\n",
            "[3750]\ttraining's binary_logloss: 0.16419\tvalid_1's binary_logloss: 0.299847\n",
            "[3800]\ttraining's binary_logloss: 0.162892\tvalid_1's binary_logloss: 0.300048\n",
            "[3850]\ttraining's binary_logloss: 0.161492\tvalid_1's binary_logloss: 0.300363\n",
            "[3900]\ttraining's binary_logloss: 0.160485\tvalid_1's binary_logloss: 0.3006\n",
            "[3950]\ttraining's binary_logloss: 0.160222\tvalid_1's binary_logloss: 0.300498\n",
            "[4000]\ttraining's binary_logloss: 0.158485\tvalid_1's binary_logloss: 0.300263\n",
            "[4050]\ttraining's binary_logloss: 0.157429\tvalid_1's binary_logloss: 0.300102\n",
            "[4100]\ttraining's binary_logloss: 0.155991\tvalid_1's binary_logloss: 0.299801\n",
            "[4150]\ttraining's binary_logloss: 0.153902\tvalid_1's binary_logloss: 0.299484\n",
            "[4200]\ttraining's binary_logloss: 0.152612\tvalid_1's binary_logloss: 0.299999\n",
            "[4250]\ttraining's binary_logloss: 0.151232\tvalid_1's binary_logloss: 0.300105\n",
            "[4300]\ttraining's binary_logloss: 0.149246\tvalid_1's binary_logloss: 0.300307\n",
            "[4350]\ttraining's binary_logloss: 0.148557\tvalid_1's binary_logloss: 0.300719\n",
            "[4400]\ttraining's binary_logloss: 0.147695\tvalid_1's binary_logloss: 0.300606\n",
            "[4450]\ttraining's binary_logloss: 0.145933\tvalid_1's binary_logloss: 0.30125\n",
            "[4500]\ttraining's binary_logloss: 0.144995\tvalid_1's binary_logloss: 0.30175\n",
            " - 0 round - train_metric: 0.678466 - valid_metric: 0.677759\n",
            "\n",
            " - 50 round - train_metric: 0.493609 - valid_metric: 0.487935\n",
            "\n",
            " - 100 round - train_metric: 0.441063 - valid_metric: 0.434782\n",
            "\n",
            " - 150 round - train_metric: 0.424830 - valid_metric: 0.418237\n",
            "\n",
            " - 200 round - train_metric: 0.414055 - valid_metric: 0.408573\n",
            "\n",
            " - 250 round - train_metric: 0.386195 - valid_metric: 0.380474\n",
            "\n",
            " - 300 round - train_metric: 0.371261 - valid_metric: 0.366053\n",
            "\n",
            " - 350 round - train_metric: 0.361226 - valid_metric: 0.357565\n",
            "\n",
            " - 400 round - train_metric: 0.357454 - valid_metric: 0.354240\n",
            "\n",
            " - 450 round - train_metric: 0.354422 - valid_metric: 0.351702\n",
            "\n",
            " - 500 round - train_metric: 0.338335 - valid_metric: 0.338635\n",
            "\n",
            " - 550 round - train_metric: 0.333376 - valid_metric: 0.335129\n",
            "\n",
            " - 600 round - train_metric: 0.329002 - valid_metric: 0.331639\n",
            "\n",
            " - 650 round - train_metric: 0.319477 - valid_metric: 0.326072\n",
            "\n",
            " - 700 round - train_metric: 0.313480 - valid_metric: 0.323600\n",
            "\n",
            " - 750 round - train_metric: 0.306000 - valid_metric: 0.318897\n",
            "\n",
            " - 800 round - train_metric: 0.300419 - valid_metric: 0.317303\n",
            "\n",
            " - 850 round - train_metric: 0.292471 - valid_metric: 0.314668\n",
            "\n",
            " - 900 round - train_metric: 0.288638 - valid_metric: 0.313693\n",
            "\n",
            " - 950 round - train_metric: 0.288087 - valid_metric: 0.313909\n",
            "\n",
            " - 1000 round - train_metric: 0.284112 - valid_metric: 0.313440\n",
            "\n",
            " - 1050 round - train_metric: 0.280312 - valid_metric: 0.311428\n",
            "\n",
            " - 1100 round - train_metric: 0.274031 - valid_metric: 0.308549\n",
            "\n",
            " - 1150 round - train_metric: 0.273483 - valid_metric: 0.308813\n",
            "\n",
            " - 1200 round - train_metric: 0.269906 - valid_metric: 0.308827\n",
            "\n",
            " - 1250 round - train_metric: 0.266810 - valid_metric: 0.308587\n",
            "\n",
            " - 1300 round - train_metric: 0.264743 - valid_metric: 0.307670\n",
            "\n",
            " - 1350 round - train_metric: 0.263324 - valid_metric: 0.308149\n",
            "\n",
            " - 1400 round - train_metric: 0.258433 - valid_metric: 0.307553\n",
            "\n",
            " - 1450 round - train_metric: 0.256741 - valid_metric: 0.306784\n",
            "\n",
            " - 1500 round - train_metric: 0.254567 - valid_metric: 0.306469\n",
            "\n",
            " - 1550 round - train_metric: 0.249225 - valid_metric: 0.305088\n",
            "\n",
            " - 1600 round - train_metric: 0.245589 - valid_metric: 0.304444\n",
            "\n",
            " - 1650 round - train_metric: 0.241872 - valid_metric: 0.303548\n",
            "\n",
            " - 1700 round - train_metric: 0.240145 - valid_metric: 0.303747\n",
            "\n",
            " - 1750 round - train_metric: 0.238615 - valid_metric: 0.303583\n",
            "\n",
            " - 1800 round - train_metric: 0.237293 - valid_metric: 0.304100\n",
            "\n",
            " - 1850 round - train_metric: 0.234887 - valid_metric: 0.303881\n",
            "\n",
            " - 1900 round - train_metric: 0.232229 - valid_metric: 0.303874\n",
            "\n",
            " - 1950 round - train_metric: 0.229230 - valid_metric: 0.303596\n",
            "\n",
            " - 2000 round - train_metric: 0.226489 - valid_metric: 0.303242\n",
            "\n",
            " - 2050 round - train_metric: 0.224952 - valid_metric: 0.303500\n",
            "\n",
            " - 2100 round - train_metric: 0.223062 - valid_metric: 0.303795\n",
            "\n",
            " - 2150 round - train_metric: 0.222710 - valid_metric: 0.304198\n",
            "\n",
            " - 2200 round - train_metric: 0.220176 - valid_metric: 0.303745\n",
            "\n",
            " - 2250 round - train_metric: 0.217790 - valid_metric: 0.303273\n",
            "\n",
            " - 2300 round - train_metric: 0.215193 - valid_metric: 0.303056\n",
            "\n",
            " - 2350 round - train_metric: 0.213675 - valid_metric: 0.301869\n",
            "\n",
            " - 2400 round - train_metric: 0.212119 - valid_metric: 0.302190\n",
            "\n",
            " - 2450 round - train_metric: 0.210022 - valid_metric: 0.301598\n",
            "\n",
            " - 2500 round - train_metric: 0.209147 - valid_metric: 0.301418\n",
            "\n",
            " - 2550 round - train_metric: 0.206982 - valid_metric: 0.300846\n",
            "\n",
            " - 2600 round - train_metric: 0.205252 - valid_metric: 0.300723\n",
            "\n",
            " - 2650 round - train_metric: 0.203129 - valid_metric: 0.300684\n",
            "\n",
            " - 2700 round - train_metric: 0.200930 - valid_metric: 0.300365\n",
            "\n",
            " - 2750 round - train_metric: 0.200019 - valid_metric: 0.300750\n",
            "\n",
            " - 2800 round - train_metric: 0.198396 - valid_metric: 0.300323\n",
            "\n",
            " - 2850 round - train_metric: 0.195579 - valid_metric: 0.299821\n",
            "\n",
            " - 2900 round - train_metric: 0.194312 - valid_metric: 0.300008\n",
            "\n",
            " - 2950 round - train_metric: 0.192070 - valid_metric: 0.300179\n",
            "\n",
            " - 3000 round - train_metric: 0.190199 - valid_metric: 0.300219\n",
            "\n",
            " - 3050 round - train_metric: 0.188250 - valid_metric: 0.300128\n",
            "\n",
            " - 3100 round - train_metric: 0.186723 - valid_metric: 0.300338\n",
            "\n",
            " - 3150 round - train_metric: 0.185367 - valid_metric: 0.300179\n",
            "\n",
            " - 3200 round - train_metric: 0.183199 - valid_metric: 0.299392\n",
            "\n",
            " - 3250 round - train_metric: 0.181700 - valid_metric: 0.300118\n",
            "\n",
            " - 3300 round - train_metric: 0.180161 - valid_metric: 0.300504\n",
            "\n",
            " - 3350 round - train_metric: 0.178087 - valid_metric: 0.300358\n",
            "\n",
            " - 3400 round - train_metric: 0.175883 - valid_metric: 0.300282\n",
            "\n",
            " - 3450 round - train_metric: 0.173812 - valid_metric: 0.300162\n",
            "\n",
            " - 3500 round - train_metric: 0.172681 - valid_metric: 0.300057\n",
            "\n",
            " - 3550 round - train_metric: 0.171249 - valid_metric: 0.300371\n",
            "\n",
            " - 3600 round - train_metric: 0.169857 - valid_metric: 0.300509\n",
            "\n",
            " - 3650 round - train_metric: 0.168419 - valid_metric: 0.299993\n",
            "\n",
            " - 3700 round - train_metric: 0.165520 - valid_metric: 0.299958\n",
            "\n",
            " - 3750 round - train_metric: 0.164071 - valid_metric: 0.299817\n",
            "\n",
            " - 3800 round - train_metric: 0.162792 - valid_metric: 0.300058\n",
            "\n",
            " - 3850 round - train_metric: 0.161401 - valid_metric: 0.300424\n",
            "\n",
            " - 3900 round - train_metric: 0.160508 - valid_metric: 0.300600\n",
            "\n",
            " - 3950 round - train_metric: 0.160123 - valid_metric: 0.300499\n",
            "\n",
            " - 4000 round - train_metric: 0.158381 - valid_metric: 0.300260\n",
            "\n",
            " - 4050 round - train_metric: 0.157460 - valid_metric: 0.300100\n",
            "\n",
            " - 4100 round - train_metric: 0.156030 - valid_metric: 0.299807\n",
            "\n",
            " - 4150 round - train_metric: 0.153939 - valid_metric: 0.299480\n",
            "\n",
            " - 4200 round - train_metric: 0.152644 - valid_metric: 0.300004\n",
            "\n",
            " - 4250 round - train_metric: 0.151263 - valid_metric: 0.300102\n",
            "\n",
            " - 4300 round - train_metric: 0.149290 - valid_metric: 0.300309\n",
            "\n",
            " - 4350 round - train_metric: 0.148470 - valid_metric: 0.300718\n",
            "\n",
            " - 4400 round - train_metric: 0.147598 - valid_metric: 0.300710\n",
            "\n",
            " - 4450 round - train_metric: 0.145963 - valid_metric: 0.301252\n",
            "\n",
            "- fold0 valid metric: 0.696640\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.489065\tvalid_1's binary_logloss: 0.493564\n",
            "[100]\ttraining's binary_logloss: 0.441879\tvalid_1's binary_logloss: 0.447186\n",
            "[150]\ttraining's binary_logloss: 0.421149\tvalid_1's binary_logloss: 0.427539\n",
            "[200]\ttraining's binary_logloss: 0.410254\tvalid_1's binary_logloss: 0.417469\n",
            "[250]\ttraining's binary_logloss: 0.385239\tvalid_1's binary_logloss: 0.394044\n",
            "[300]\ttraining's binary_logloss: 0.36986\tvalid_1's binary_logloss: 0.380987\n",
            "[350]\ttraining's binary_logloss: 0.358962\tvalid_1's binary_logloss: 0.371558\n",
            "[400]\ttraining's binary_logloss: 0.354645\tvalid_1's binary_logloss: 0.367063\n",
            "[450]\ttraining's binary_logloss: 0.351368\tvalid_1's binary_logloss: 0.364107\n",
            "[500]\ttraining's binary_logloss: 0.336074\tvalid_1's binary_logloss: 0.351755\n",
            "[550]\ttraining's binary_logloss: 0.331025\tvalid_1's binary_logloss: 0.347824\n",
            "[600]\ttraining's binary_logloss: 0.327732\tvalid_1's binary_logloss: 0.346166\n",
            "[650]\ttraining's binary_logloss: 0.317845\tvalid_1's binary_logloss: 0.33984\n",
            "[700]\ttraining's binary_logloss: 0.311385\tvalid_1's binary_logloss: 0.335501\n",
            "[750]\ttraining's binary_logloss: 0.303714\tvalid_1's binary_logloss: 0.331602\n",
            "[800]\ttraining's binary_logloss: 0.298734\tvalid_1's binary_logloss: 0.329452\n",
            "[850]\ttraining's binary_logloss: 0.292071\tvalid_1's binary_logloss: 0.327199\n",
            "[900]\ttraining's binary_logloss: 0.288431\tvalid_1's binary_logloss: 0.326554\n",
            "[950]\ttraining's binary_logloss: 0.287676\tvalid_1's binary_logloss: 0.327044\n",
            "[1000]\ttraining's binary_logloss: 0.282817\tvalid_1's binary_logloss: 0.324372\n",
            "[1050]\ttraining's binary_logloss: 0.280168\tvalid_1's binary_logloss: 0.324861\n",
            "[1100]\ttraining's binary_logloss: 0.273095\tvalid_1's binary_logloss: 0.323388\n",
            "[1150]\ttraining's binary_logloss: 0.272268\tvalid_1's binary_logloss: 0.323335\n",
            "[1200]\ttraining's binary_logloss: 0.268596\tvalid_1's binary_logloss: 0.321933\n",
            "[1250]\ttraining's binary_logloss: 0.265386\tvalid_1's binary_logloss: 0.321108\n",
            "[1300]\ttraining's binary_logloss: 0.263553\tvalid_1's binary_logloss: 0.321332\n",
            "[1350]\ttraining's binary_logloss: 0.261431\tvalid_1's binary_logloss: 0.320016\n",
            "[1400]\ttraining's binary_logloss: 0.256286\tvalid_1's binary_logloss: 0.318825\n",
            "[1450]\ttraining's binary_logloss: 0.254398\tvalid_1's binary_logloss: 0.318899\n",
            "[1500]\ttraining's binary_logloss: 0.252569\tvalid_1's binary_logloss: 0.319047\n",
            "[1550]\ttraining's binary_logloss: 0.247425\tvalid_1's binary_logloss: 0.318173\n",
            "[1600]\ttraining's binary_logloss: 0.243916\tvalid_1's binary_logloss: 0.318284\n",
            "[1650]\ttraining's binary_logloss: 0.240568\tvalid_1's binary_logloss: 0.318248\n",
            "[1700]\ttraining's binary_logloss: 0.238336\tvalid_1's binary_logloss: 0.317038\n",
            "[1750]\ttraining's binary_logloss: 0.236118\tvalid_1's binary_logloss: 0.316842\n",
            "[1800]\ttraining's binary_logloss: 0.234948\tvalid_1's binary_logloss: 0.317188\n",
            "[1850]\ttraining's binary_logloss: 0.232627\tvalid_1's binary_logloss: 0.316979\n",
            "[1900]\ttraining's binary_logloss: 0.230011\tvalid_1's binary_logloss: 0.31636\n",
            "[1950]\ttraining's binary_logloss: 0.226745\tvalid_1's binary_logloss: 0.316461\n",
            "[2000]\ttraining's binary_logloss: 0.224201\tvalid_1's binary_logloss: 0.316736\n",
            "[2050]\ttraining's binary_logloss: 0.222443\tvalid_1's binary_logloss: 0.31732\n",
            "[2100]\ttraining's binary_logloss: 0.220441\tvalid_1's binary_logloss: 0.317018\n",
            "[2150]\ttraining's binary_logloss: 0.220097\tvalid_1's binary_logloss: 0.317482\n",
            "[2200]\ttraining's binary_logloss: 0.217386\tvalid_1's binary_logloss: 0.31743\n",
            "[2250]\ttraining's binary_logloss: 0.215112\tvalid_1's binary_logloss: 0.316581\n",
            "[2300]\ttraining's binary_logloss: 0.212441\tvalid_1's binary_logloss: 0.316425\n",
            "[2350]\ttraining's binary_logloss: 0.210781\tvalid_1's binary_logloss: 0.316506\n",
            "[2400]\ttraining's binary_logloss: 0.209282\tvalid_1's binary_logloss: 0.317155\n",
            "[2450]\ttraining's binary_logloss: 0.207337\tvalid_1's binary_logloss: 0.317223\n",
            "[2500]\ttraining's binary_logloss: 0.206069\tvalid_1's binary_logloss: 0.317225\n",
            "[2550]\ttraining's binary_logloss: 0.204152\tvalid_1's binary_logloss: 0.317209\n",
            "[2600]\ttraining's binary_logloss: 0.202506\tvalid_1's binary_logloss: 0.317288\n",
            "[2650]\ttraining's binary_logloss: 0.200589\tvalid_1's binary_logloss: 0.317447\n",
            "[2700]\ttraining's binary_logloss: 0.198221\tvalid_1's binary_logloss: 0.317611\n",
            "[2750]\ttraining's binary_logloss: 0.19744\tvalid_1's binary_logloss: 0.317898\n",
            "[2800]\ttraining's binary_logloss: 0.196197\tvalid_1's binary_logloss: 0.318293\n",
            "[2850]\ttraining's binary_logloss: 0.193175\tvalid_1's binary_logloss: 0.318109\n",
            "[2900]\ttraining's binary_logloss: 0.191797\tvalid_1's binary_logloss: 0.318132\n",
            "[2950]\ttraining's binary_logloss: 0.189442\tvalid_1's binary_logloss: 0.318476\n",
            "[3000]\ttraining's binary_logloss: 0.187435\tvalid_1's binary_logloss: 0.317958\n",
            "[3050]\ttraining's binary_logloss: 0.185734\tvalid_1's binary_logloss: 0.31754\n",
            "[3100]\ttraining's binary_logloss: 0.184107\tvalid_1's binary_logloss: 0.31733\n",
            "[3150]\ttraining's binary_logloss: 0.182756\tvalid_1's binary_logloss: 0.31717\n",
            "[3200]\ttraining's binary_logloss: 0.180628\tvalid_1's binary_logloss: 0.317501\n",
            "[3250]\ttraining's binary_logloss: 0.178804\tvalid_1's binary_logloss: 0.317274\n",
            "[3300]\ttraining's binary_logloss: 0.177292\tvalid_1's binary_logloss: 0.31664\n",
            "[3350]\ttraining's binary_logloss: 0.175338\tvalid_1's binary_logloss: 0.317178\n",
            "[3400]\ttraining's binary_logloss: 0.173047\tvalid_1's binary_logloss: 0.317064\n",
            "[3450]\ttraining's binary_logloss: 0.171122\tvalid_1's binary_logloss: 0.316722\n",
            "[3500]\ttraining's binary_logloss: 0.169949\tvalid_1's binary_logloss: 0.316746\n",
            "[3550]\ttraining's binary_logloss: 0.168486\tvalid_1's binary_logloss: 0.317311\n",
            "[3600]\ttraining's binary_logloss: 0.166995\tvalid_1's binary_logloss: 0.316954\n",
            "[3650]\ttraining's binary_logloss: 0.16559\tvalid_1's binary_logloss: 0.317385\n",
            "[3700]\ttraining's binary_logloss: 0.163001\tvalid_1's binary_logloss: 0.317696\n",
            "[3750]\ttraining's binary_logloss: 0.161544\tvalid_1's binary_logloss: 0.317641\n",
            "[3800]\ttraining's binary_logloss: 0.160366\tvalid_1's binary_logloss: 0.317672\n",
            "[3850]\ttraining's binary_logloss: 0.158829\tvalid_1's binary_logloss: 0.317587\n",
            "[3900]\ttraining's binary_logloss: 0.157977\tvalid_1's binary_logloss: 0.317906\n",
            "[3950]\ttraining's binary_logloss: 0.157633\tvalid_1's binary_logloss: 0.318082\n",
            "[4000]\ttraining's binary_logloss: 0.155766\tvalid_1's binary_logloss: 0.318196\n",
            "[4050]\ttraining's binary_logloss: 0.154638\tvalid_1's binary_logloss: 0.31834\n",
            "[4100]\ttraining's binary_logloss: 0.15293\tvalid_1's binary_logloss: 0.318356\n",
            "[4150]\ttraining's binary_logloss: 0.150922\tvalid_1's binary_logloss: 0.318903\n",
            "[4200]\ttraining's binary_logloss: 0.14971\tvalid_1's binary_logloss: 0.318769\n",
            "[4250]\ttraining's binary_logloss: 0.148437\tvalid_1's binary_logloss: 0.318681\n",
            "[4300]\ttraining's binary_logloss: 0.146659\tvalid_1's binary_logloss: 0.318937\n",
            "[4350]\ttraining's binary_logloss: 0.146073\tvalid_1's binary_logloss: 0.319057\n",
            "[4400]\ttraining's binary_logloss: 0.145167\tvalid_1's binary_logloss: 0.318635\n",
            "[4450]\ttraining's binary_logloss: 0.143489\tvalid_1's binary_logloss: 0.318527\n",
            "[4500]\ttraining's binary_logloss: 0.142609\tvalid_1's binary_logloss: 0.318852\n",
            " - 0 round - train_metric: 0.678585 - valid_metric: 0.678625\n",
            "\n",
            " - 50 round - train_metric: 0.490947 - valid_metric: 0.495336\n",
            "\n",
            " - 100 round - train_metric: 0.438554 - valid_metric: 0.443828\n",
            "\n",
            " - 150 round - train_metric: 0.422723 - valid_metric: 0.429047\n",
            "\n",
            " - 200 round - train_metric: 0.411326 - valid_metric: 0.418479\n",
            "\n",
            " - 250 round - train_metric: 0.383561 - valid_metric: 0.392620\n",
            "\n",
            " - 300 round - train_metric: 0.368683 - valid_metric: 0.380013\n",
            "\n",
            " - 350 round - train_metric: 0.359599 - valid_metric: 0.372118\n",
            "\n",
            " - 400 round - train_metric: 0.355149 - valid_metric: 0.367505\n",
            "\n",
            " - 450 round - train_metric: 0.351819 - valid_metric: 0.364500\n",
            "\n",
            " - 500 round - train_metric: 0.335485 - valid_metric: 0.351266\n",
            "\n",
            " - 550 round - train_metric: 0.330309 - valid_metric: 0.347233\n",
            "\n",
            " - 600 round - train_metric: 0.326828 - valid_metric: 0.345437\n",
            "\n",
            " - 650 round - train_metric: 0.318063 - valid_metric: 0.340015\n",
            "\n",
            " - 700 round - train_metric: 0.311620 - valid_metric: 0.335670\n",
            "\n",
            " - 750 round - train_metric: 0.303927 - valid_metric: 0.331729\n",
            "\n",
            " - 800 round - train_metric: 0.298896 - valid_metric: 0.329571\n",
            "\n",
            " - 850 round - train_metric: 0.291649 - valid_metric: 0.326900\n",
            "\n",
            " - 900 round - train_metric: 0.288183 - valid_metric: 0.326522\n",
            "\n",
            " - 950 round - train_metric: 0.287391 - valid_metric: 0.326799\n",
            "\n",
            " - 1000 round - train_metric: 0.282957 - valid_metric: 0.324448\n",
            "\n",
            " - 1050 round - train_metric: 0.279827 - valid_metric: 0.324567\n",
            "\n",
            " - 1100 round - train_metric: 0.272855 - valid_metric: 0.323143\n",
            "\n",
            " - 1150 round - train_metric: 0.272373 - valid_metric: 0.323386\n",
            "\n",
            " - 1200 round - train_metric: 0.268705 - valid_metric: 0.321992\n",
            "\n",
            " - 1250 round - train_metric: 0.265477 - valid_metric: 0.321163\n",
            "\n",
            " - 1300 round - train_metric: 0.263645 - valid_metric: 0.321381\n",
            "\n",
            " - 1350 round - train_metric: 0.261548 - valid_metric: 0.320074\n",
            "\n",
            " - 1400 round - train_metric: 0.256096 - valid_metric: 0.318844\n",
            "\n",
            " - 1450 round - train_metric: 0.254497 - valid_metric: 0.318947\n",
            "\n",
            " - 1500 round - train_metric: 0.252344 - valid_metric: 0.318928\n",
            "\n",
            " - 1550 round - train_metric: 0.247263 - valid_metric: 0.318088\n",
            "\n",
            " - 1600 round - train_metric: 0.244015 - valid_metric: 0.318311\n",
            "\n",
            " - 1650 round - train_metric: 0.240387 - valid_metric: 0.318159\n",
            "\n",
            " - 1700 round - train_metric: 0.238131 - valid_metric: 0.316945\n",
            "\n",
            " - 1750 round - train_metric: 0.236199 - valid_metric: 0.316877\n",
            "\n",
            " - 1800 round - train_metric: 0.234807 - valid_metric: 0.316994\n",
            "\n",
            " - 1850 round - train_metric: 0.232736 - valid_metric: 0.317021\n",
            "\n",
            " - 1900 round - train_metric: 0.229774 - valid_metric: 0.316163\n",
            "\n",
            " - 1950 round - train_metric: 0.226817 - valid_metric: 0.316477\n",
            "\n",
            " - 2000 round - train_metric: 0.224021 - valid_metric: 0.316664\n",
            "\n",
            " - 2050 round - train_metric: 0.222506 - valid_metric: 0.317336\n",
            "\n",
            " - 2100 round - train_metric: 0.220492 - valid_metric: 0.317034\n",
            "\n",
            " - 2150 round - train_metric: 0.220175 - valid_metric: 0.317505\n",
            "\n",
            " - 2200 round - train_metric: 0.217459 - valid_metric: 0.317451\n",
            "\n",
            " - 2250 round - train_metric: 0.214927 - valid_metric: 0.316516\n",
            "\n",
            " - 2300 round - train_metric: 0.212517 - valid_metric: 0.316450\n",
            "\n",
            " - 2350 round - train_metric: 0.210862 - valid_metric: 0.316519\n",
            "\n",
            " - 2400 round - train_metric: 0.209131 - valid_metric: 0.317298\n",
            "\n",
            " - 2450 round - train_metric: 0.207225 - valid_metric: 0.317201\n",
            "\n",
            " - 2500 round - train_metric: 0.206113 - valid_metric: 0.317236\n",
            "\n",
            " - 2550 round - train_metric: 0.204008 - valid_metric: 0.317153\n",
            "\n",
            " - 2600 round - train_metric: 0.202543 - valid_metric: 0.317296\n",
            "\n",
            " - 2650 round - train_metric: 0.200626 - valid_metric: 0.317456\n",
            "\n",
            " - 2700 round - train_metric: 0.198276 - valid_metric: 0.317632\n",
            "\n",
            " - 2750 round - train_metric: 0.197485 - valid_metric: 0.317904\n",
            "\n",
            " - 2800 round - train_metric: 0.196069 - valid_metric: 0.318232\n",
            "\n",
            " - 2850 round - train_metric: 0.193217 - valid_metric: 0.318113\n",
            "\n",
            " - 2900 round - train_metric: 0.191857 - valid_metric: 0.318132\n",
            "\n",
            " - 2950 round - train_metric: 0.189483 - valid_metric: 0.318482\n",
            "\n",
            " - 3000 round - train_metric: 0.187477 - valid_metric: 0.317963\n",
            "\n",
            " - 3050 round - train_metric: 0.185601 - valid_metric: 0.317430\n",
            "\n",
            " - 3100 round - train_metric: 0.184141 - valid_metric: 0.317331\n",
            "\n",
            " - 3150 round - train_metric: 0.182802 - valid_metric: 0.317187\n",
            "\n",
            " - 3200 round - train_metric: 0.180500 - valid_metric: 0.317548\n",
            "\n",
            " - 3250 round - train_metric: 0.178833 - valid_metric: 0.317280\n",
            "\n",
            " - 3300 round - train_metric: 0.177329 - valid_metric: 0.316637\n",
            "\n",
            " - 3350 round - train_metric: 0.175379 - valid_metric: 0.317183\n",
            "\n",
            " - 3400 round - train_metric: 0.173085 - valid_metric: 0.317063\n",
            "\n",
            " - 3450 round - train_metric: 0.171009 - valid_metric: 0.316756\n",
            "\n",
            " - 3500 round - train_metric: 0.169839 - valid_metric: 0.316738\n",
            "\n",
            " - 3550 round - train_metric: 0.168516 - valid_metric: 0.317314\n",
            "\n",
            " - 3600 round - train_metric: 0.167030 - valid_metric: 0.316949\n",
            "\n",
            " - 3650 round - train_metric: 0.165641 - valid_metric: 0.317385\n",
            "\n",
            " - 3700 round - train_metric: 0.162930 - valid_metric: 0.317657\n",
            "\n",
            " - 3750 round - train_metric: 0.161460 - valid_metric: 0.317683\n",
            "\n",
            " - 3800 round - train_metric: 0.160262 - valid_metric: 0.317658\n",
            "\n",
            " - 3850 round - train_metric: 0.158741 - valid_metric: 0.317535\n",
            "\n",
            " - 3900 round - train_metric: 0.157998 - valid_metric: 0.317911\n",
            "\n",
            " - 3950 round - train_metric: 0.157556 - valid_metric: 0.318062\n",
            "\n",
            " - 4000 round - train_metric: 0.155681 - valid_metric: 0.318245\n",
            "\n",
            " - 4050 round - train_metric: 0.154670 - valid_metric: 0.318343\n",
            "\n",
            " - 4100 round - train_metric: 0.152969 - valid_metric: 0.318359\n",
            "\n",
            " - 4150 round - train_metric: 0.150959 - valid_metric: 0.318896\n",
            "\n",
            " - 4200 round - train_metric: 0.149742 - valid_metric: 0.318761\n",
            "\n",
            " - 4250 round - train_metric: 0.148468 - valid_metric: 0.318677\n",
            "\n",
            " - 4300 round - train_metric: 0.146702 - valid_metric: 0.318938\n",
            "\n",
            " - 4350 round - train_metric: 0.145977 - valid_metric: 0.319006\n",
            "\n",
            " - 4400 round - train_metric: 0.145087 - valid_metric: 0.318761\n",
            "\n",
            " - 4450 round - train_metric: 0.143518 - valid_metric: 0.318528\n",
            "\n",
            "- fold1 valid metric: 0.664868\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.486998\tvalid_1's binary_logloss: 0.500261\n",
            "[100]\ttraining's binary_logloss: 0.438034\tvalid_1's binary_logloss: 0.456062\n",
            "[150]\ttraining's binary_logloss: 0.416466\tvalid_1's binary_logloss: 0.436136\n",
            "[200]\ttraining's binary_logloss: 0.405288\tvalid_1's binary_logloss: 0.427318\n",
            "[250]\ttraining's binary_logloss: 0.379444\tvalid_1's binary_logloss: 0.406396\n",
            "[300]\ttraining's binary_logloss: 0.36398\tvalid_1's binary_logloss: 0.393646\n",
            "[350]\ttraining's binary_logloss: 0.353231\tvalid_1's binary_logloss: 0.383922\n",
            "[400]\ttraining's binary_logloss: 0.349336\tvalid_1's binary_logloss: 0.381456\n",
            "[450]\ttraining's binary_logloss: 0.347367\tvalid_1's binary_logloss: 0.381167\n",
            "[500]\ttraining's binary_logloss: 0.332192\tvalid_1's binary_logloss: 0.369946\n",
            "[550]\ttraining's binary_logloss: 0.327078\tvalid_1's binary_logloss: 0.366224\n",
            "[600]\ttraining's binary_logloss: 0.322762\tvalid_1's binary_logloss: 0.364139\n",
            "[650]\ttraining's binary_logloss: 0.313177\tvalid_1's binary_logloss: 0.358451\n",
            "[700]\ttraining's binary_logloss: 0.307057\tvalid_1's binary_logloss: 0.355163\n",
            "[750]\ttraining's binary_logloss: 0.299385\tvalid_1's binary_logloss: 0.351713\n",
            "[800]\ttraining's binary_logloss: 0.294588\tvalid_1's binary_logloss: 0.34953\n",
            "[850]\ttraining's binary_logloss: 0.287871\tvalid_1's binary_logloss: 0.345751\n",
            "[900]\ttraining's binary_logloss: 0.284386\tvalid_1's binary_logloss: 0.344245\n",
            "[950]\ttraining's binary_logloss: 0.28365\tvalid_1's binary_logloss: 0.343698\n",
            "[1000]\ttraining's binary_logloss: 0.279416\tvalid_1's binary_logloss: 0.342882\n",
            "[1050]\ttraining's binary_logloss: 0.276201\tvalid_1's binary_logloss: 0.341636\n",
            "[1100]\ttraining's binary_logloss: 0.26939\tvalid_1's binary_logloss: 0.338842\n",
            "[1150]\ttraining's binary_logloss: 0.268457\tvalid_1's binary_logloss: 0.33946\n",
            "[1200]\ttraining's binary_logloss: 0.265501\tvalid_1's binary_logloss: 0.339074\n",
            "[1250]\ttraining's binary_logloss: 0.262439\tvalid_1's binary_logloss: 0.337589\n",
            "[1300]\ttraining's binary_logloss: 0.260497\tvalid_1's binary_logloss: 0.337619\n",
            "Traceback (most recent call last):\n",
            "  File \"S5_LGB_main.py\", line 95, in <module>\n",
            "    Lgb_train_and_predict(train,test,lgb_config,aug=None,run_id='LGB_with_manual_feature')\n",
            "  File \"/content/drive/MyDrive/Credit_risk/Kaggle-American-Express/utils.py\", line 158, in Lgb_train_and_predict\n",
            "    model = lgb.train(params,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py\", line 218, in train\n",
            "    booster.update(fobj=fobj)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py\", line 1800, in update\n",
            "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python  S6_NN_main.py --do_train --batch_size 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_uJ6QzGN7v_",
        "outputId": "d87aef72-0d87-4614-ab8d-d9c33b49cfc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available gpus: [0]\n",
            "------NN------len(train) 4\n",
            "loss: 0.5854: 100% 27/27 [01:01<00:00,  2.29s/it]\n",
            "100% 14/14 [00:31<00:00,  2.25s/it]\n",
            "[epoch 0] lr: 0.001000, train_loss: 0.565504, valid_metric: 0.247273, valid_mean:0.257521\n",
            "loss: 0.5330: 100% 27/27 [00:58<00:00,  2.17s/it]\n",
            "100% 14/14 [00:33<00:00,  2.43s/it]\n",
            "[epoch 1] lr: 0.001000, train_loss: 0.539461, valid_metric: 0.239928, valid_mean:0.280032, NIE +1 ---> 1\n",
            "loss: 0.5619: 100% 27/27 [00:58<00:00,  2.16s/it]\n",
            "100% 14/14 [00:31<00:00,  2.24s/it]\n",
            "[epoch 2] lr: 0.001000, train_loss: 0.533713, valid_metric: 0.243475, valid_mean:0.269496, NIE +1 ---> 2\n",
            "loss: 0.5625: 100% 27/27 [01:00<00:00,  2.25s/it]\n",
            "100% 14/14 [00:31<00:00,  2.26s/it]\n",
            "[epoch 3] lr: 0.001000, train_loss: 0.527885, valid_metric: 0.237306, valid_mean:0.292118, NIE +1 ---> 3\n",
            "loss: 0.5824: 100% 27/27 [01:00<00:00,  2.26s/it]\n",
            "100% 14/14 [00:31<00:00,  2.26s/it]\n",
            "[epoch 4] lr: 0.001000, train_loss: 0.527735, valid_metric: 0.234063, valid_mean:0.250922, NIE +1 ---> 4\n",
            "loss: 0.5375: 100% 27/27 [01:00<00:00,  2.24s/it]\n",
            "100% 14/14 [00:31<00:00,  2.25s/it]\n",
            "[epoch 5] lr: 0.000100, train_loss: 0.519500, valid_metric: 0.248631, valid_mean:0.267558\n",
            "loss: 0.4979: 100% 27/27 [00:58<00:00,  2.16s/it]\n",
            "100% 14/14 [00:34<00:00,  2.44s/it]\n",
            "[epoch 6] lr: 0.000100, train_loss: 0.515029, valid_metric: 0.239016, valid_mean:0.264016, NIE +1 ---> 1\n",
            "loss: 0.5455: 100% 27/27 [00:58<00:00,  2.17s/it]\n",
            "100% 14/14 [00:34<00:00,  2.43s/it]\n",
            "[epoch 7] lr: 0.000100, train_loss: 0.510850, valid_metric: 0.239740, valid_mean:0.260364, NIE +1 ---> 2\n",
            "loss: 0.5060: 100% 27/27 [00:58<00:00,  2.17s/it]\n",
            "100% 14/14 [00:31<00:00,  2.25s/it]\n",
            "[epoch 8] lr: 0.000100, train_loss: 0.508729, valid_metric: 0.239631, valid_mean:0.260251, NIE +1 ---> 3\n",
            "loss: 0.4965: 100% 27/27 [00:59<00:00,  2.22s/it]\n",
            "100% 14/14 [00:30<00:00,  2.21s/it]\n",
            "[epoch 9] lr: 0.000010, train_loss: 0.506755, valid_metric: 0.240648, valid_mean:0.260907, NIE +1 ---> 4\n",
            "100% 14/14 [00:31<00:00,  2.22s/it]\n",
            "[fold 0] best_valid_metric: 0.248631, best_valid_mean: 0.267558\n",
            "loss: 0.5652: 100% 27/27 [00:59<00:00,  2.21s/it]\n",
            "100% 14/14 [00:31<00:00,  2.22s/it]\n",
            "[epoch 0] lr: 0.001000, train_loss: 0.564119, valid_metric: 0.238127, valid_mean:0.258069\n",
            "loss: 0.5951: 100% 27/27 [00:59<00:00,  2.21s/it]\n",
            "100% 14/14 [00:31<00:00,  2.22s/it]\n",
            "[epoch 1] lr: 0.001000, train_loss: 0.541613, valid_metric: 0.244273, valid_mean:0.234970\n",
            "loss: 0.5400: 100% 27/27 [00:59<00:00,  2.20s/it]\n",
            "100% 14/14 [00:29<00:00,  2.08s/it]\n",
            "[epoch 2] lr: 0.001000, train_loss: 0.537623, valid_metric: 0.246421, valid_mean:0.223914\n",
            "loss: 0.5444: 100% 27/27 [00:59<00:00,  2.21s/it]\n",
            "100% 14/14 [00:31<00:00,  2.23s/it]\n",
            "[epoch 3] lr: 0.001000, train_loss: 0.532221, valid_metric: 0.249441, valid_mean:0.268675\n",
            "loss: 0.5341: 100% 27/27 [01:00<00:00,  2.22s/it]\n",
            "100% 14/14 [00:29<00:00,  2.08s/it]\n",
            "[epoch 4] lr: 0.001000, train_loss: 0.529229, valid_metric: 0.240376, valid_mean:0.269148, NIE +1 ---> 1\n",
            "loss: 0.5113: 100% 27/27 [01:02<00:00,  2.30s/it]\n",
            "100% 14/14 [00:29<00:00,  2.08s/it]\n",
            "[epoch 5] lr: 0.000100, train_loss: 0.527347, valid_metric: 0.245036, valid_mean:0.250030, NIE +1 ---> 2\n",
            "loss: 0.4962: 100% 27/27 [01:02<00:00,  2.30s/it]\n",
            "100% 14/14 [00:29<00:00,  2.08s/it]\n",
            "[epoch 6] lr: 0.000100, train_loss: 0.524947, valid_metric: 0.245532, valid_mean:0.254439, NIE +1 ---> 3\n",
            "loss: 0.5519: 100% 27/27 [01:01<00:00,  2.27s/it]\n",
            "100% 14/14 [00:28<00:00,  2.05s/it]\n",
            "[epoch 7] lr: 0.000100, train_loss: 0.523236, valid_metric: 0.246624, valid_mean:0.258115, NIE +1 ---> 4\n",
            "loss: 0.5595: 100% 27/27 [00:56<00:00,  2.11s/it]\n",
            "100% 14/14 [00:32<00:00,  2.31s/it]\n",
            "[epoch 8] lr: 0.000100, train_loss: 0.518858, valid_metric: 0.248353, valid_mean:0.256296, NIE +1 ---> 5\n",
            "loss: 0.5565: 100% 27/27 [00:56<00:00,  2.10s/it]\n",
            "100% 14/14 [00:30<00:00,  2.18s/it]\n",
            "[epoch 9] lr: 0.000010, train_loss: 0.514813, valid_metric: 0.249320, valid_mean:0.259366, NIE +1 ---> 6\n",
            "100% 14/14 [00:32<00:00,  2.33s/it]\n",
            "[fold 1] best_valid_metric: 0.249441, best_valid_mean: 0.268675\n",
            "loss: 0.5362: 100% 27/27 [00:56<00:00,  2.11s/it]\n",
            "100% 14/14 [00:30<00:00,  2.18s/it]\n",
            "[epoch 0] lr: 0.001000, train_loss: 0.559550, valid_metric: 0.207005, valid_mean:0.236461\n",
            "loss: 0.5526: 100% 27/27 [00:58<00:00,  2.17s/it]\n",
            "100% 14/14 [00:30<00:00,  2.18s/it]\n",
            "[epoch 1] lr: 0.001000, train_loss: 0.535764, valid_metric: 0.211119, valid_mean:0.255526\n",
            "loss: 0.5485: 100% 27/27 [00:58<00:00,  2.18s/it]\n",
            "100% 14/14 [00:30<00:00,  2.18s/it]\n",
            "[epoch 2] lr: 0.001000, train_loss: 0.530653, valid_metric: 0.222333, valid_mean:0.261689\n",
            "loss: 0.5143: 100% 27/27 [00:59<00:00,  2.19s/it]\n",
            "100% 14/14 [00:30<00:00,  2.16s/it]\n",
            "[epoch 3] lr: 0.001000, train_loss: 0.527393, valid_metric: 0.216728, valid_mean:0.267289, NIE +1 ---> 1\n",
            "loss: 0.5344: 100% 27/27 [00:56<00:00,  2.10s/it]\n",
            "100% 14/14 [00:30<00:00,  2.18s/it]\n",
            "[epoch 4] lr: 0.001000, train_loss: 0.523031, valid_metric: 0.226255, valid_mean:0.260205\n",
            "loss: 0.5061: 100% 27/27 [00:58<00:00,  2.18s/it]\n",
            "100% 14/14 [00:28<00:00,  2.05s/it]\n",
            "[epoch 5] lr: 0.000100, train_loss: 0.516045, valid_metric: 0.220807, valid_mean:0.261912, NIE +1 ---> 1\n",
            "loss: 0.5194: 100% 27/27 [00:58<00:00,  2.17s/it]\n",
            "100% 14/14 [00:30<00:00,  2.16s/it]\n",
            "[epoch 6] lr: 0.000100, train_loss: 0.509610, valid_metric: 0.227628, valid_mean:0.269487\n",
            "loss: 0.4970: 100% 27/27 [00:58<00:00,  2.17s/it]\n",
            "100% 14/14 [00:30<00:00,  2.19s/it]\n",
            "[epoch 7] lr: 0.000100, train_loss: 0.508005, valid_metric: 0.225913, valid_mean:0.257863, NIE +1 ---> 1\n",
            "loss: 0.5038: 100% 27/27 [00:56<00:00,  2.09s/it]\n",
            "100% 14/14 [00:32<00:00,  2.33s/it]\n",
            "[epoch 8] lr: 0.000100, train_loss: 0.504950, valid_metric: 0.227788, valid_mean:0.260979\n",
            "loss: 0.4959: 100% 27/27 [00:56<00:00,  2.09s/it]\n",
            "100% 14/14 [00:32<00:00,  2.31s/it]\n",
            "[epoch 9] lr: 0.000010, train_loss: 0.500664, valid_metric: 0.227825, valid_mean:0.262276\n",
            "100% 14/14 [00:28<00:00,  2.04s/it]\n",
            "[fold 2] best_valid_metric: 0.227825, best_valid_mean: 0.262276\n",
            "all valid mean metric:0.241966\n",
            "0it [00:00, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"S6_NN_main.py\", line 78, in <module>\n",
            "    NN_train_and_predict([df,f,y,series_idx.values[:y.shape[0]]],[df,f,series_idx.values[y.shape[0]:]],Amodel,nn_config,use_series_oof=False,run_id='NN_with_series_feature')\n",
            "  File \"/content/drive/MyDrive/Credit_risk/Kaggle-American-Express/utils.py\", line 551, in NN_train_and_predict\n",
            "    test_preds = np.concatenate(test_preds).reshape(-1)\n",
            "  File \"<__array_function__ internals>\", line 5, in concatenate\n",
            "ValueError: need at least one array to concatenate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run.sh\n",
        "python S1_denoise.py\n",
        "python S2_manual_feature.py\n",
        "python S3_series_feature.py\n",
        "python S4_feature_combined.py\n",
        "python S5_LGB_main.py\n",
        "CUDA_VISIBLE_DEVICES=0 python  S6_NN_main.py --do_train --batch_size 512\n",
        "python S7_ensemble.py"
      ],
      "metadata": {
        "id": "QFo_nn78W9v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python S5_LGB_main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yza6eYEwRlIh",
        "outputId": "7f333533-5ede-42fd-90a5-12575799361f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'S5_LGB_main.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh run.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6sD-c_FXI4G",
        "outputId": "a6a9cddb-fb0d-440a-eb33-157635fadccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start ------\n",
            "train.shape (50000, 190)\n",
            "100% 190/190 [00:00<00:00, 1246.45it/s]\n",
            "test.shape (80000, 190)\n",
            "100% 190/190 [00:00<00:00, 936.69it/s]\n",
            "-----------li-----------: 0\n",
            "cat_feature: 100% 16/16 [00:04<00:00,  3.32it/s]\n",
            "prefix----: \n",
            "cat_feature_df.shape-----------: (10683, 208)\n",
            "num_feature: 100% 16/16 [00:09<00:00,  1.61it/s]\n",
            "prefix----: \n",
            "num_feature_df.shape-----------: (10683, 1063)\n",
            "diff_feature: 100% 16/16 [00:05<00:00,  2.82it/s]\n",
            "prefix----: \n",
            "diff_feature_df.shape-----------: (10683, 1063)\n",
            "num_feature: 100% 16/16 [00:03<00:00,  4.69it/s]\n",
            "prefix----: rank_\n",
            "num_feature_df.shape-----------: (10683, 178)\n",
            "num_feature: 100% 16/16 [00:08<00:00,  1.97it/s]\n",
            "prefix----: ym_rank_\n",
            "num_feature_df.shape-----------: (10683, 1063)\n",
            "-----------li-----------: 1\n",
            "all df shape (130000, 190)\n",
            "last 3 shape (31725, 190)\n",
            "cat_feature: 100% 16/16 [00:01<00:00, 10.92it/s]\n",
            "prefix----: last3_\n",
            "cat_feature_df.shape-----------: (10683, 142)\n",
            "num_feature: 100% 16/16 [00:01<00:00, 10.44it/s]\n",
            "prefix----: last3_\n",
            "num_feature_df.shape-----------: (10683, 886)\n",
            "diff_feature: 100% 16/16 [00:01<00:00, 15.46it/s]\n",
            "prefix----: last3_\n",
            "diff_feature_df.shape-----------: (10683, 886)\n",
            "-----------li-----------: 2\n",
            "all df shape (130000, 190)\n",
            "last 6 shape (62466, 190)\n",
            "num_feature: 100% 16/16 [00:03<00:00,  4.87it/s]\n",
            "prefix----: last6_\n",
            "num_feature_df.shape-----------: (10683, 886)\n",
            "available gpus: []\n",
            "-----------train.shape----------- (50000, 190)\n",
            "-----------test.shape----------- (80000, 190)\n",
            "(50000, 191) (80000, 190)\n",
            "====utils.py====test.shape (80000, 190)\n",
            "----features.len: 188\n",
            "[50]\ttraining's binary_logloss: 0.424813\tvalid_1's binary_logloss: 0.436547\n",
            "[100]\ttraining's binary_logloss: 0.365921\tvalid_1's binary_logloss: 0.383039\n",
            "[150]\ttraining's binary_logloss: 0.33871\tvalid_1's binary_logloss: 0.360434\n",
            "[200]\ttraining's binary_logloss: 0.324721\tvalid_1's binary_logloss: 0.349337\n",
            "[250]\ttraining's binary_logloss: 0.293284\tvalid_1's binary_logloss: 0.324222\n",
            "[300]\ttraining's binary_logloss: 0.274515\tvalid_1's binary_logloss: 0.311848\n",
            "[350]\ttraining's binary_logloss: 0.260243\tvalid_1's binary_logloss: 0.30383\n",
            "[400]\ttraining's binary_logloss: 0.254051\tvalid_1's binary_logloss: 0.301359\n",
            "[450]\ttraining's binary_logloss: 0.249695\tvalid_1's binary_logloss: 0.300323\n",
            "[500]\ttraining's binary_logloss: 0.229595\tvalid_1's binary_logloss: 0.291726\n",
            "[550]\ttraining's binary_logloss: 0.221355\tvalid_1's binary_logloss: 0.289539\n",
            "[600]\ttraining's binary_logloss: 0.214989\tvalid_1's binary_logloss: 0.287755\n",
            "[650]\ttraining's binary_logloss: 0.200511\tvalid_1's binary_logloss: 0.285019\n",
            "[700]\ttraining's binary_logloss: 0.190383\tvalid_1's binary_logloss: 0.283822\n",
            "[750]\ttraining's binary_logloss: 0.179052\tvalid_1's binary_logloss: 0.283206\n",
            "[800]\ttraining's binary_logloss: 0.171183\tvalid_1's binary_logloss: 0.282542\n",
            "[850]\ttraining's binary_logloss: 0.160789\tvalid_1's binary_logloss: 0.281969\n",
            "[900]\ttraining's binary_logloss: 0.154504\tvalid_1's binary_logloss: 0.2816\n",
            "[950]\ttraining's binary_logloss: 0.152708\tvalid_1's binary_logloss: 0.281751\n",
            "[1000]\ttraining's binary_logloss: 0.146061\tvalid_1's binary_logloss: 0.281799\n",
            "[1050]\ttraining's binary_logloss: 0.141075\tvalid_1's binary_logloss: 0.282009\n",
            "[1100]\ttraining's binary_logloss: 0.132459\tvalid_1's binary_logloss: 0.282669\n",
            "[1150]\ttraining's binary_logloss: 0.130832\tvalid_1's binary_logloss: 0.282091\n",
            "[1200]\ttraining's binary_logloss: 0.126607\tvalid_1's binary_logloss: 0.281806\n",
            "[1250]\ttraining's binary_logloss: 0.122228\tvalid_1's binary_logloss: 0.281838\n",
            "[1300]\ttraining's binary_logloss: 0.119531\tvalid_1's binary_logloss: 0.281649\n",
            "[1350]\ttraining's binary_logloss: 0.117614\tvalid_1's binary_logloss: 0.281545\n",
            "[1400]\ttraining's binary_logloss: 0.112162\tvalid_1's binary_logloss: 0.28233\n",
            "[1450]\ttraining's binary_logloss: 0.109655\tvalid_1's binary_logloss: 0.28199\n",
            "[1500]\ttraining's binary_logloss: 0.107397\tvalid_1's binary_logloss: 0.282249\n",
            "[1550]\ttraining's binary_logloss: 0.102007\tvalid_1's binary_logloss: 0.283898\n",
            "[1600]\ttraining's binary_logloss: 0.0978824\tvalid_1's binary_logloss: 0.284894\n",
            "[1650]\ttraining's binary_logloss: 0.0945762\tvalid_1's binary_logloss: 0.285784\n",
            "[1700]\ttraining's binary_logloss: 0.0926041\tvalid_1's binary_logloss: 0.285326\n",
            "[1750]\ttraining's binary_logloss: 0.0908891\tvalid_1's binary_logloss: 0.285381\n",
            "[1800]\ttraining's binary_logloss: 0.0898616\tvalid_1's binary_logloss: 0.285526\n",
            "[1850]\ttraining's binary_logloss: 0.0877121\tvalid_1's binary_logloss: 0.285641\n",
            "[1900]\ttraining's binary_logloss: 0.0853217\tvalid_1's binary_logloss: 0.285668\n",
            "[1950]\ttraining's binary_logloss: 0.0822634\tvalid_1's binary_logloss: 0.286736\n",
            "[2000]\ttraining's binary_logloss: 0.080272\tvalid_1's binary_logloss: 0.287105\n",
            "[2050]\ttraining's binary_logloss: 0.0786996\tvalid_1's binary_logloss: 0.287379\n",
            "[2100]\ttraining's binary_logloss: 0.07717\tvalid_1's binary_logloss: 0.287723\n",
            "[2150]\ttraining's binary_logloss: 0.0770135\tvalid_1's binary_logloss: 0.287196\n",
            "[2200]\ttraining's binary_logloss: 0.0747612\tvalid_1's binary_logloss: 0.28769\n",
            "[2250]\ttraining's binary_logloss: 0.0731065\tvalid_1's binary_logloss: 0.288588\n",
            "[2300]\ttraining's binary_logloss: 0.0709893\tvalid_1's binary_logloss: 0.28897\n",
            "[2350]\ttraining's binary_logloss: 0.0697684\tvalid_1's binary_logloss: 0.289117\n",
            "[2400]\ttraining's binary_logloss: 0.0687924\tvalid_1's binary_logloss: 0.289459\n",
            "[2450]\ttraining's binary_logloss: 0.0672878\tvalid_1's binary_logloss: 0.290172\n",
            "[2500]\ttraining's binary_logloss: 0.0666748\tvalid_1's binary_logloss: 0.290359\n",
            "[2550]\ttraining's binary_logloss: 0.0653418\tvalid_1's binary_logloss: 0.291446\n",
            "[2600]\ttraining's binary_logloss: 0.06404\tvalid_1's binary_logloss: 0.29206\n",
            "[2650]\ttraining's binary_logloss: 0.0627918\tvalid_1's binary_logloss: 0.29276\n",
            "[2700]\ttraining's binary_logloss: 0.061341\tvalid_1's binary_logloss: 0.29328\n",
            "[2750]\ttraining's binary_logloss: 0.0608595\tvalid_1's binary_logloss: 0.293051\n",
            "[2800]\ttraining's binary_logloss: 0.0599756\tvalid_1's binary_logloss: 0.293487\n",
            "[2850]\ttraining's binary_logloss: 0.0580471\tvalid_1's binary_logloss: 0.294361\n",
            "[2900]\ttraining's binary_logloss: 0.0572455\tvalid_1's binary_logloss: 0.295189\n",
            "[2950]\ttraining's binary_logloss: 0.0556788\tvalid_1's binary_logloss: 0.295846\n",
            "[3000]\ttraining's binary_logloss: 0.0545375\tvalid_1's binary_logloss: 0.29651\n",
            "[3050]\ttraining's binary_logloss: 0.0535847\tvalid_1's binary_logloss: 0.296761\n",
            "[3100]\ttraining's binary_logloss: 0.0526341\tvalid_1's binary_logloss: 0.297809\n",
            "[3150]\ttraining's binary_logloss: 0.051961\tvalid_1's binary_logloss: 0.298141\n",
            "[3200]\ttraining's binary_logloss: 0.0508089\tvalid_1's binary_logloss: 0.298858\n",
            "[3250]\ttraining's binary_logloss: 0.0498492\tvalid_1's binary_logloss: 0.299364\n",
            "[3300]\ttraining's binary_logloss: 0.0490601\tvalid_1's binary_logloss: 0.299711\n",
            "[3350]\ttraining's binary_logloss: 0.0479016\tvalid_1's binary_logloss: 0.300622\n",
            "[3400]\ttraining's binary_logloss: 0.0467434\tvalid_1's binary_logloss: 0.301234\n",
            "[3450]\ttraining's binary_logloss: 0.0457715\tvalid_1's binary_logloss: 0.301884\n",
            "[3500]\ttraining's binary_logloss: 0.0452466\tvalid_1's binary_logloss: 0.301883\n",
            "[3550]\ttraining's binary_logloss: 0.0444486\tvalid_1's binary_logloss: 0.302652\n",
            "[3600]\ttraining's binary_logloss: 0.043823\tvalid_1's binary_logloss: 0.30278\n",
            "[3650]\ttraining's binary_logloss: 0.0430638\tvalid_1's binary_logloss: 0.302975\n",
            "[3700]\ttraining's binary_logloss: 0.0416922\tvalid_1's binary_logloss: 0.303952\n",
            "[3750]\ttraining's binary_logloss: 0.0410312\tvalid_1's binary_logloss: 0.304379\n",
            "[3800]\ttraining's binary_logloss: 0.0405324\tvalid_1's binary_logloss: 0.304149\n",
            "[3850]\ttraining's binary_logloss: 0.0398735\tvalid_1's binary_logloss: 0.304731\n",
            "[3900]\ttraining's binary_logloss: 0.039499\tvalid_1's binary_logloss: 0.304977\n",
            "[3950]\ttraining's binary_logloss: 0.0394699\tvalid_1's binary_logloss: 0.305086\n",
            "[4000]\ttraining's binary_logloss: 0.0385845\tvalid_1's binary_logloss: 0.306119\n",
            "[4050]\ttraining's binary_logloss: 0.0381509\tvalid_1's binary_logloss: 0.306588\n",
            "[4100]\ttraining's binary_logloss: 0.0375237\tvalid_1's binary_logloss: 0.307289\n",
            "[4150]\ttraining's binary_logloss: 0.0365449\tvalid_1's binary_logloss: 0.308353\n",
            "[4200]\ttraining's binary_logloss: 0.0360078\tvalid_1's binary_logloss: 0.30928\n",
            "[4250]\ttraining's binary_logloss: 0.0355008\tvalid_1's binary_logloss: 0.310178\n",
            "[4300]\ttraining's binary_logloss: 0.0346231\tvalid_1's binary_logloss: 0.310956\n",
            "[4350]\ttraining's binary_logloss: 0.0344966\tvalid_1's binary_logloss: 0.310822\n",
            "[4400]\ttraining's binary_logloss: 0.0342415\tvalid_1's binary_logloss: 0.310971\n",
            "[4450]\ttraining's binary_logloss: 0.0335714\tvalid_1's binary_logloss: 0.312171\n",
            "[4500]\ttraining's binary_logloss: 0.0332649\tvalid_1's binary_logloss: 0.312658\n",
            " - 0 round - train_metric: 0.674007 - valid_metric: 0.674773\n",
            "\n",
            " - 50 round - train_metric: 0.427145 - valid_metric: 0.438728\n",
            "\n",
            " - 100 round - train_metric: 0.361890 - valid_metric: 0.379283\n",
            "\n",
            " - 150 round - train_metric: 0.340629 - valid_metric: 0.362093\n",
            "\n",
            " - 200 round - train_metric: 0.325996 - valid_metric: 0.350420\n",
            "\n",
            " - 250 round - train_metric: 0.291367 - valid_metric: 0.322751\n",
            "\n",
            " - 300 round - train_metric: 0.273009 - valid_metric: 0.310747\n",
            "\n",
            " - 350 round - train_metric: 0.260959 - valid_metric: 0.304273\n",
            "\n",
            " - 400 round - train_metric: 0.254598 - valid_metric: 0.301705\n",
            "\n",
            " - 450 round - train_metric: 0.250205 - valid_metric: 0.300626\n",
            "\n",
            " - 500 round - train_metric: 0.228768 - valid_metric: 0.291439\n",
            "\n",
            " - 550 round - train_metric: 0.220547 - valid_metric: 0.289135\n",
            "\n",
            " - 600 round - train_metric: 0.214251 - valid_metric: 0.287465\n",
            "\n",
            " - 650 round - train_metric: 0.200762 - valid_metric: 0.285097\n",
            "\n",
            " - 700 round - train_metric: 0.190650 - valid_metric: 0.283874\n",
            "\n",
            " - 750 round - train_metric: 0.179324 - valid_metric: 0.283239\n",
            "\n",
            " - 800 round - train_metric: 0.171361 - valid_metric: 0.282559\n",
            "\n",
            " - 850 round - train_metric: 0.160227 - valid_metric: 0.282176\n",
            "\n",
            " - 900 round - train_metric: 0.154097 - valid_metric: 0.281469\n",
            "\n",
            " - 950 round - train_metric: 0.152367 - valid_metric: 0.281753\n",
            "\n",
            " - 1000 round - train_metric: 0.146221 - valid_metric: 0.281800\n",
            "\n",
            " - 1050 round - train_metric: 0.140781 - valid_metric: 0.282100\n",
            "\n",
            " - 1100 round - train_metric: 0.132074 - valid_metric: 0.282597\n",
            "\n",
            " - 1150 round - train_metric: 0.130953 - valid_metric: 0.282079\n",
            "\n",
            " - 1200 round - train_metric: 0.126731 - valid_metric: 0.281786\n",
            "\n",
            " - 1250 round - train_metric: 0.122334 - valid_metric: 0.281819\n",
            "\n",
            " - 1300 round - train_metric: 0.119637 - valid_metric: 0.281626\n",
            "\n",
            " - 1350 round - train_metric: 0.117748 - valid_metric: 0.281517\n",
            "\n",
            " - 1400 round - train_metric: 0.111935 - valid_metric: 0.282388\n",
            "\n",
            " - 1450 round - train_metric: 0.109769 - valid_metric: 0.281962\n",
            "\n",
            " - 1500 round - train_metric: 0.107211 - valid_metric: 0.282345\n",
            "\n",
            " - 1550 round - train_metric: 0.101819 - valid_metric: 0.283977\n",
            "\n",
            " - 1600 round - train_metric: 0.097995 - valid_metric: 0.284845\n",
            "\n",
            " - 1650 round - train_metric: 0.094452 - valid_metric: 0.285752\n",
            "\n",
            " - 1700 round - train_metric: 0.092392 - valid_metric: 0.285502\n",
            "\n",
            " - 1750 round - train_metric: 0.090974 - valid_metric: 0.285339\n",
            "\n",
            " - 1800 round - train_metric: 0.089679 - valid_metric: 0.285489\n",
            "\n",
            " - 1850 round - train_metric: 0.087819 - valid_metric: 0.285589\n",
            "\n",
            " - 1900 round - train_metric: 0.085177 - valid_metric: 0.285686\n",
            "\n",
            " - 1950 round - train_metric: 0.082330 - valid_metric: 0.286698\n",
            "\n",
            " - 2000 round - train_metric: 0.080118 - valid_metric: 0.287146\n",
            "\n",
            " - 2050 round - train_metric: 0.078763 - valid_metric: 0.287349\n",
            "\n",
            " - 2100 round - train_metric: 0.077221 - valid_metric: 0.287698\n",
            "\n",
            " - 2150 round - train_metric: 0.077088 - valid_metric: 0.287147\n",
            "\n",
            " - 2200 round - train_metric: 0.074830 - valid_metric: 0.287651\n",
            "\n",
            " - 2250 round - train_metric: 0.072970 - valid_metric: 0.288668\n",
            "\n",
            " - 2300 round - train_metric: 0.071056 - valid_metric: 0.288938\n",
            "\n",
            " - 2350 round - train_metric: 0.069843 - valid_metric: 0.289076\n",
            "\n",
            " - 2400 round - train_metric: 0.068695 - valid_metric: 0.289596\n",
            "\n",
            " - 2450 round - train_metric: 0.067174 - valid_metric: 0.290224\n",
            "\n",
            " - 2500 round - train_metric: 0.066712 - valid_metric: 0.290335\n",
            "\n",
            " - 2550 round - train_metric: 0.065223 - valid_metric: 0.291526\n",
            "\n",
            " - 2600 round - train_metric: 0.064069 - valid_metric: 0.292035\n",
            "\n",
            " - 2650 round - train_metric: 0.062824 - valid_metric: 0.292733\n",
            "\n",
            " - 2700 round - train_metric: 0.061387 - valid_metric: 0.293244\n",
            "\n",
            " - 2750 round - train_metric: 0.060896 - valid_metric: 0.293019\n",
            "\n",
            " - 2800 round - train_metric: 0.059884 - valid_metric: 0.293463\n",
            "\n",
            " - 2850 round - train_metric: 0.058082 - valid_metric: 0.294331\n",
            "\n",
            " - 2900 round - train_metric: 0.057294 - valid_metric: 0.295147\n",
            "\n",
            " - 2950 round - train_metric: 0.055714 - valid_metric: 0.295817\n",
            "\n",
            " - 3000 round - train_metric: 0.054571 - valid_metric: 0.296483\n",
            "\n",
            " - 3050 round - train_metric: 0.053509 - valid_metric: 0.296933\n",
            "\n",
            " - 3100 round - train_metric: 0.052659 - valid_metric: 0.297778\n",
            "\n",
            " - 3150 round - train_metric: 0.051998 - valid_metric: 0.298103\n",
            "\n",
            " - 3200 round - train_metric: 0.050746 - valid_metric: 0.298814\n",
            "\n",
            " - 3250 round - train_metric: 0.049871 - valid_metric: 0.299338\n",
            "\n",
            " - 3300 round - train_metric: 0.049090 - valid_metric: 0.299684\n",
            "\n",
            " - 3350 round - train_metric: 0.047930 - valid_metric: 0.300588\n",
            "\n",
            " - 3400 round - train_metric: 0.046770 - valid_metric: 0.301201\n",
            "\n",
            " - 3450 round - train_metric: 0.045714 - valid_metric: 0.301790\n",
            "\n",
            " - 3500 round - train_metric: 0.045199 - valid_metric: 0.301931\n",
            "\n",
            " - 3550 round - train_metric: 0.044469 - valid_metric: 0.302626\n",
            "\n",
            " - 3600 round - train_metric: 0.043848 - valid_metric: 0.302750\n",
            "\n",
            " - 3650 round - train_metric: 0.043099 - valid_metric: 0.302934\n",
            "\n",
            " - 3700 round - train_metric: 0.041638 - valid_metric: 0.304159\n",
            "\n",
            " - 3750 round - train_metric: 0.040975 - valid_metric: 0.304452\n",
            "\n",
            " - 3800 round - train_metric: 0.040482 - valid_metric: 0.304219\n",
            "\n",
            " - 3850 round - train_metric: 0.039818 - valid_metric: 0.304796\n",
            "\n",
            " - 3900 round - train_metric: 0.039514 - valid_metric: 0.304952\n",
            "\n",
            " - 3950 round - train_metric: 0.039423 - valid_metric: 0.305187\n",
            "\n",
            " - 4000 round - train_metric: 0.038532 - valid_metric: 0.306249\n",
            "\n",
            " - 4050 round - train_metric: 0.038170 - valid_metric: 0.306560\n",
            "\n",
            " - 4100 round - train_metric: 0.037550 - valid_metric: 0.307253\n",
            "\n",
            " - 4150 round - train_metric: 0.036568 - valid_metric: 0.308314\n",
            "\n",
            " - 4200 round - train_metric: 0.036029 - valid_metric: 0.309247\n",
            "\n",
            " - 4250 round - train_metric: 0.035520 - valid_metric: 0.310139\n",
            "\n",
            " - 4300 round - train_metric: 0.034649 - valid_metric: 0.310915\n",
            "\n",
            " - 4350 round - train_metric: 0.034461 - valid_metric: 0.310827\n",
            "\n",
            " - 4400 round - train_metric: 0.034211 - valid_metric: 0.311106\n",
            "\n",
            " - 4450 round - train_metric: 0.033589 - valid_metric: 0.312145\n",
            "\n",
            "- fold0 valid metric: 0.675637\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.421358\tvalid_1's binary_logloss: 0.447767\n",
            "[100]\ttraining's binary_logloss: 0.360902\tvalid_1's binary_logloss: 0.398282\n",
            "[150]\ttraining's binary_logloss: 0.334014\tvalid_1's binary_logloss: 0.377676\n",
            "[200]\ttraining's binary_logloss: 0.319761\tvalid_1's binary_logloss: 0.367321\n",
            "[250]\ttraining's binary_logloss: 0.288101\tvalid_1's binary_logloss: 0.346314\n",
            "[300]\ttraining's binary_logloss: 0.269246\tvalid_1's binary_logloss: 0.334771\n",
            "[350]\ttraining's binary_logloss: 0.255243\tvalid_1's binary_logloss: 0.327097\n",
            "[400]\ttraining's binary_logloss: 0.24869\tvalid_1's binary_logloss: 0.324534\n",
            "[450]\ttraining's binary_logloss: 0.244836\tvalid_1's binary_logloss: 0.323379\n",
            "[500]\ttraining's binary_logloss: 0.22629\tvalid_1's binary_logloss: 0.315736\n",
            "[550]\ttraining's binary_logloss: 0.218358\tvalid_1's binary_logloss: 0.312362\n",
            "[600]\ttraining's binary_logloss: 0.211666\tvalid_1's binary_logloss: 0.311343\n",
            "[650]\ttraining's binary_logloss: 0.19801\tvalid_1's binary_logloss: 0.30769\n",
            "[700]\ttraining's binary_logloss: 0.188026\tvalid_1's binary_logloss: 0.305535\n",
            "[750]\ttraining's binary_logloss: 0.176463\tvalid_1's binary_logloss: 0.304515\n",
            "[800]\ttraining's binary_logloss: 0.168402\tvalid_1's binary_logloss: 0.303978\n",
            "[850]\ttraining's binary_logloss: 0.157796\tvalid_1's binary_logloss: 0.302773\n",
            "[900]\ttraining's binary_logloss: 0.151907\tvalid_1's binary_logloss: 0.302252\n",
            "[950]\ttraining's binary_logloss: 0.149795\tvalid_1's binary_logloss: 0.302205\n",
            "[1000]\ttraining's binary_logloss: 0.143352\tvalid_1's binary_logloss: 0.301642\n",
            "[1050]\ttraining's binary_logloss: 0.138568\tvalid_1's binary_logloss: 0.302208\n",
            "[1100]\ttraining's binary_logloss: 0.129952\tvalid_1's binary_logloss: 0.302793\n",
            "[1150]\ttraining's binary_logloss: 0.128366\tvalid_1's binary_logloss: 0.302202\n",
            "[1200]\ttraining's binary_logloss: 0.124108\tvalid_1's binary_logloss: 0.302761\n",
            "[1250]\ttraining's binary_logloss: 0.120296\tvalid_1's binary_logloss: 0.303717\n",
            "[1300]\ttraining's binary_logloss: 0.118084\tvalid_1's binary_logloss: 0.304326\n",
            "[1350]\ttraining's binary_logloss: 0.116028\tvalid_1's binary_logloss: 0.303923\n",
            "[1400]\ttraining's binary_logloss: 0.11022\tvalid_1's binary_logloss: 0.305404\n",
            "[1450]\ttraining's binary_logloss: 0.107995\tvalid_1's binary_logloss: 0.305912\n",
            "[1500]\ttraining's binary_logloss: 0.105627\tvalid_1's binary_logloss: 0.306494\n",
            "[1550]\ttraining's binary_logloss: 0.10026\tvalid_1's binary_logloss: 0.307844\n",
            "[1600]\ttraining's binary_logloss: 0.0957904\tvalid_1's binary_logloss: 0.308752\n",
            "[1650]\ttraining's binary_logloss: 0.0924951\tvalid_1's binary_logloss: 0.309943\n",
            "[1700]\ttraining's binary_logloss: 0.0907221\tvalid_1's binary_logloss: 0.309898\n",
            "[1750]\ttraining's binary_logloss: 0.088906\tvalid_1's binary_logloss: 0.310344\n",
            "[1800]\ttraining's binary_logloss: 0.0878328\tvalid_1's binary_logloss: 0.311057\n",
            "[1850]\ttraining's binary_logloss: 0.0856042\tvalid_1's binary_logloss: 0.311723\n",
            "[1900]\ttraining's binary_logloss: 0.0832276\tvalid_1's binary_logloss: 0.31233\n",
            "[1950]\ttraining's binary_logloss: 0.0803547\tvalid_1's binary_logloss: 0.313561\n",
            "[2000]\ttraining's binary_logloss: 0.078284\tvalid_1's binary_logloss: 0.314331\n",
            "[2050]\ttraining's binary_logloss: 0.0767126\tvalid_1's binary_logloss: 0.314711\n",
            "[2100]\ttraining's binary_logloss: 0.0750961\tvalid_1's binary_logloss: 0.315417\n",
            "[2150]\ttraining's binary_logloss: 0.0749457\tvalid_1's binary_logloss: 0.314814\n",
            "[2200]\ttraining's binary_logloss: 0.0727058\tvalid_1's binary_logloss: 0.316061\n",
            "[2250]\ttraining's binary_logloss: 0.0712734\tvalid_1's binary_logloss: 0.316763\n",
            "[2300]\ttraining's binary_logloss: 0.0691213\tvalid_1's binary_logloss: 0.318279\n",
            "[2350]\ttraining's binary_logloss: 0.0679672\tvalid_1's binary_logloss: 0.318248\n",
            "[2400]\ttraining's binary_logloss: 0.0670531\tvalid_1's binary_logloss: 0.318765\n",
            "[2450]\ttraining's binary_logloss: 0.0655384\tvalid_1's binary_logloss: 0.319065\n",
            "[2500]\ttraining's binary_logloss: 0.064808\tvalid_1's binary_logloss: 0.319925\n",
            "[2550]\ttraining's binary_logloss: 0.0636609\tvalid_1's binary_logloss: 0.320895\n",
            "[2600]\ttraining's binary_logloss: 0.0623556\tvalid_1's binary_logloss: 0.321555\n",
            "[2650]\ttraining's binary_logloss: 0.06095\tvalid_1's binary_logloss: 0.321895\n",
            "[2700]\ttraining's binary_logloss: 0.0594425\tvalid_1's binary_logloss: 0.322519\n",
            "[2750]\ttraining's binary_logloss: 0.0590526\tvalid_1's binary_logloss: 0.322287\n",
            "[2800]\ttraining's binary_logloss: 0.0581032\tvalid_1's binary_logloss: 0.322265\n",
            "[2850]\ttraining's binary_logloss: 0.056279\tvalid_1's binary_logloss: 0.323605\n",
            "[2900]\ttraining's binary_logloss: 0.0554826\tvalid_1's binary_logloss: 0.324081\n",
            "[2950]\ttraining's binary_logloss: 0.0540389\tvalid_1's binary_logloss: 0.325273\n",
            "[3000]\ttraining's binary_logloss: 0.0529662\tvalid_1's binary_logloss: 0.32597\n",
            "[3050]\ttraining's binary_logloss: 0.0519942\tvalid_1's binary_logloss: 0.326583\n",
            "[3100]\ttraining's binary_logloss: 0.0511558\tvalid_1's binary_logloss: 0.327301\n",
            "[3150]\ttraining's binary_logloss: 0.0504419\tvalid_1's binary_logloss: 0.327599\n",
            "[3200]\ttraining's binary_logloss: 0.0493128\tvalid_1's binary_logloss: 0.328759\n",
            "[3250]\ttraining's binary_logloss: 0.0483431\tvalid_1's binary_logloss: 0.329032\n",
            "[3300]\ttraining's binary_logloss: 0.0476226\tvalid_1's binary_logloss: 0.329246\n",
            "[3350]\ttraining's binary_logloss: 0.046551\tvalid_1's binary_logloss: 0.330916\n",
            "[3400]\ttraining's binary_logloss: 0.0454377\tvalid_1's binary_logloss: 0.332132\n",
            "[3450]\ttraining's binary_logloss: 0.0444206\tvalid_1's binary_logloss: 0.333067\n",
            "[3500]\ttraining's binary_logloss: 0.0438826\tvalid_1's binary_logloss: 0.33373\n",
            "[3550]\ttraining's binary_logloss: 0.043212\tvalid_1's binary_logloss: 0.334578\n",
            "[3600]\ttraining's binary_logloss: 0.0425395\tvalid_1's binary_logloss: 0.33514\n",
            "[3650]\ttraining's binary_logloss: 0.0418257\tvalid_1's binary_logloss: 0.335513\n",
            "[3700]\ttraining's binary_logloss: 0.0404914\tvalid_1's binary_logloss: 0.337369\n",
            "[3750]\ttraining's binary_logloss: 0.0398142\tvalid_1's binary_logloss: 0.338031\n",
            "[3800]\ttraining's binary_logloss: 0.0393215\tvalid_1's binary_logloss: 0.338418\n",
            "[3850]\ttraining's binary_logloss: 0.0387881\tvalid_1's binary_logloss: 0.339429\n",
            "[3900]\ttraining's binary_logloss: 0.0384484\tvalid_1's binary_logloss: 0.339958\n",
            "[3950]\ttraining's binary_logloss: 0.0384836\tvalid_1's binary_logloss: 0.339745\n",
            "[4000]\ttraining's binary_logloss: 0.0376233\tvalid_1's binary_logloss: 0.340674\n",
            "[4050]\ttraining's binary_logloss: 0.0371809\tvalid_1's binary_logloss: 0.34097\n",
            "[4100]\ttraining's binary_logloss: 0.0365166\tvalid_1's binary_logloss: 0.341794\n",
            "[4150]\ttraining's binary_logloss: 0.0355917\tvalid_1's binary_logloss: 0.342754\n",
            "[4200]\ttraining's binary_logloss: 0.0351197\tvalid_1's binary_logloss: 0.343359\n",
            "[4250]\ttraining's binary_logloss: 0.034563\tvalid_1's binary_logloss: 0.343823\n",
            "[4300]\ttraining's binary_logloss: 0.0337842\tvalid_1's binary_logloss: 0.34501\n",
            "[4350]\ttraining's binary_logloss: 0.0336371\tvalid_1's binary_logloss: 0.344598\n",
            "[4400]\ttraining's binary_logloss: 0.033393\tvalid_1's binary_logloss: 0.344823\n",
            "[4450]\ttraining's binary_logloss: 0.0327281\tvalid_1's binary_logloss: 0.345652\n",
            "[4500]\ttraining's binary_logloss: 0.0324405\tvalid_1's binary_logloss: 0.345926\n",
            " - 0 round - train_metric: 0.673766 - valid_metric: 0.675145\n",
            "\n",
            " - 50 round - train_metric: 0.423704 - valid_metric: 0.449773\n",
            "\n",
            " - 100 round - train_metric: 0.356812 - valid_metric: 0.395117\n",
            "\n",
            " - 150 round - train_metric: 0.335933 - valid_metric: 0.379183\n",
            "\n",
            " - 200 round - train_metric: 0.321048 - valid_metric: 0.368296\n",
            "\n",
            " - 250 round - train_metric: 0.286066 - valid_metric: 0.345152\n",
            "\n",
            " - 300 round - train_metric: 0.267697 - valid_metric: 0.333860\n",
            "\n",
            " - 350 round - train_metric: 0.255949 - valid_metric: 0.327474\n",
            "\n",
            " - 400 round - train_metric: 0.249245 - valid_metric: 0.324812\n",
            "\n",
            " - 450 round - train_metric: 0.245344 - valid_metric: 0.323618\n",
            "\n",
            " - 500 round - train_metric: 0.225430 - valid_metric: 0.315400\n",
            "\n",
            " - 550 round - train_metric: 0.217495 - valid_metric: 0.312308\n",
            "\n",
            " - 600 round - train_metric: 0.211032 - valid_metric: 0.311145\n",
            "\n",
            " - 650 round - train_metric: 0.198254 - valid_metric: 0.307732\n",
            "\n",
            " - 700 round - train_metric: 0.188286 - valid_metric: 0.305566\n",
            "\n",
            " - 750 round - train_metric: 0.176728 - valid_metric: 0.304513\n",
            "\n",
            " - 800 round - train_metric: 0.168580 - valid_metric: 0.303973\n",
            "\n",
            " - 850 round - train_metric: 0.157423 - valid_metric: 0.302703\n",
            "\n",
            " - 900 round - train_metric: 0.151522 - valid_metric: 0.302270\n",
            "\n",
            " - 950 round - train_metric: 0.149451 - valid_metric: 0.302183\n",
            "\n",
            " - 1000 round - train_metric: 0.143516 - valid_metric: 0.301618\n",
            "\n",
            " - 1050 round - train_metric: 0.138226 - valid_metric: 0.302279\n",
            "\n",
            " - 1100 round - train_metric: 0.129616 - valid_metric: 0.302830\n",
            "\n",
            " - 1150 round - train_metric: 0.128480 - valid_metric: 0.302170\n",
            "\n",
            " - 1200 round - train_metric: 0.124231 - valid_metric: 0.302727\n",
            "\n",
            " - 1250 round - train_metric: 0.120398 - valid_metric: 0.303683\n",
            "\n",
            " - 1300 round - train_metric: 0.118191 - valid_metric: 0.304294\n",
            "\n",
            " - 1350 round - train_metric: 0.116156 - valid_metric: 0.303893\n",
            "\n",
            " - 1400 round - train_metric: 0.109987 - valid_metric: 0.305335\n",
            "\n",
            " - 1450 round - train_metric: 0.108106 - valid_metric: 0.305876\n",
            "\n",
            " - 1500 round - train_metric: 0.105416 - valid_metric: 0.306634\n",
            "\n",
            " - 1550 round - train_metric: 0.099978 - valid_metric: 0.307811\n",
            "\n",
            " - 1600 round - train_metric: 0.095903 - valid_metric: 0.308693\n",
            "\n",
            " - 1650 round - train_metric: 0.092324 - valid_metric: 0.309958\n",
            "\n",
            " - 1700 round - train_metric: 0.090531 - valid_metric: 0.310028\n",
            "\n",
            " - 1750 round - train_metric: 0.088987 - valid_metric: 0.310294\n",
            "\n",
            " - 1800 round - train_metric: 0.087677 - valid_metric: 0.311063\n",
            "\n",
            " - 1850 round - train_metric: 0.085712 - valid_metric: 0.311681\n",
            "\n",
            " - 1900 round - train_metric: 0.083069 - valid_metric: 0.312391\n",
            "\n",
            " - 1950 round - train_metric: 0.080421 - valid_metric: 0.313519\n",
            "\n",
            " - 2000 round - train_metric: 0.078145 - valid_metric: 0.314465\n",
            "\n",
            " - 2050 round - train_metric: 0.076774 - valid_metric: 0.314669\n",
            "\n",
            " - 2100 round - train_metric: 0.075146 - valid_metric: 0.315388\n",
            "\n",
            " - 2150 round - train_metric: 0.075015 - valid_metric: 0.314755\n",
            "\n",
            " - 2200 round - train_metric: 0.072772 - valid_metric: 0.316018\n",
            "\n",
            " - 2250 round - train_metric: 0.071156 - valid_metric: 0.316825\n",
            "\n",
            " - 2300 round - train_metric: 0.069184 - valid_metric: 0.318226\n",
            "\n",
            " - 2350 round - train_metric: 0.068041 - valid_metric: 0.318180\n",
            "\n",
            " - 2400 round - train_metric: 0.066944 - valid_metric: 0.318879\n",
            "\n",
            " - 2450 round - train_metric: 0.065426 - valid_metric: 0.319092\n",
            "\n",
            " - 2500 round - train_metric: 0.064844 - valid_metric: 0.319890\n",
            "\n",
            " - 2550 round - train_metric: 0.063543 - valid_metric: 0.321012\n",
            "\n",
            " - 2600 round - train_metric: 0.062385 - valid_metric: 0.321518\n",
            "\n",
            " - 2650 round - train_metric: 0.060981 - valid_metric: 0.321862\n",
            "\n",
            " - 2700 round - train_metric: 0.059487 - valid_metric: 0.322466\n",
            "\n",
            " - 2750 round - train_metric: 0.059088 - valid_metric: 0.322255\n",
            "\n",
            " - 2800 round - train_metric: 0.058023 - valid_metric: 0.322295\n",
            "\n",
            " - 2850 round - train_metric: 0.056313 - valid_metric: 0.323564\n",
            "\n",
            " - 2900 round - train_metric: 0.055532 - valid_metric: 0.324029\n",
            "\n",
            " - 2950 round - train_metric: 0.054073 - valid_metric: 0.325225\n",
            "\n",
            " - 3000 round - train_metric: 0.053000 - valid_metric: 0.325932\n",
            "\n",
            " - 3050 round - train_metric: 0.051922 - valid_metric: 0.326680\n",
            "\n",
            " - 3100 round - train_metric: 0.051181 - valid_metric: 0.327271\n",
            "\n",
            " - 3150 round - train_metric: 0.050477 - valid_metric: 0.327560\n",
            "\n",
            " - 3200 round - train_metric: 0.049238 - valid_metric: 0.328888\n",
            "\n",
            " - 3250 round - train_metric: 0.048365 - valid_metric: 0.328999\n",
            "\n",
            " - 3300 round - train_metric: 0.047651 - valid_metric: 0.329209\n",
            "\n",
            " - 3350 round - train_metric: 0.046578 - valid_metric: 0.330879\n",
            "\n",
            " - 3400 round - train_metric: 0.045465 - valid_metric: 0.332088\n",
            "\n",
            " - 3450 round - train_metric: 0.044363 - valid_metric: 0.333100\n",
            "\n",
            " - 3500 round - train_metric: 0.043828 - valid_metric: 0.333791\n",
            "\n",
            " - 3550 round - train_metric: 0.043233 - valid_metric: 0.334546\n",
            "\n",
            " - 3600 round - train_metric: 0.042565 - valid_metric: 0.335098\n",
            "\n",
            " - 3650 round - train_metric: 0.041861 - valid_metric: 0.335470\n",
            "\n",
            " - 3700 round - train_metric: 0.040442 - valid_metric: 0.337428\n",
            "\n",
            " - 3750 round - train_metric: 0.039765 - valid_metric: 0.338083\n",
            "\n",
            " - 3800 round - train_metric: 0.039269 - valid_metric: 0.338605\n",
            "\n",
            " - 3850 round - train_metric: 0.038745 - valid_metric: 0.339467\n",
            "\n",
            " - 3900 round - train_metric: 0.038464 - valid_metric: 0.339924\n",
            "\n",
            " - 3950 round - train_metric: 0.038441 - valid_metric: 0.339806\n",
            "\n",
            " - 4000 round - train_metric: 0.037566 - valid_metric: 0.340784\n",
            "\n",
            " - 4050 round - train_metric: 0.037200 - valid_metric: 0.340937\n",
            "\n",
            " - 4100 round - train_metric: 0.036542 - valid_metric: 0.341751\n",
            "\n",
            " - 4150 round - train_metric: 0.035615 - valid_metric: 0.342713\n",
            "\n",
            " - 4200 round - train_metric: 0.035141 - valid_metric: 0.343317\n",
            "\n",
            " - 4250 round - train_metric: 0.034582 - valid_metric: 0.343782\n",
            "\n",
            " - 4300 round - train_metric: 0.033810 - valid_metric: 0.344959\n",
            "\n",
            " - 4350 round - train_metric: 0.033602 - valid_metric: 0.344642\n",
            "\n",
            " - 4400 round - train_metric: 0.033359 - valid_metric: 0.344877\n",
            "\n",
            " - 4450 round - train_metric: 0.032745 - valid_metric: 0.345612\n",
            "\n",
            "- fold1 valid metric: 0.623979\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.422712\tvalid_1's binary_logloss: 0.441707\n",
            "[100]\ttraining's binary_logloss: 0.362768\tvalid_1's binary_logloss: 0.390828\n",
            "[150]\ttraining's binary_logloss: 0.335955\tvalid_1's binary_logloss: 0.36932\n",
            "[200]\ttraining's binary_logloss: 0.321528\tvalid_1's binary_logloss: 0.358627\n",
            "[250]\ttraining's binary_logloss: 0.289991\tvalid_1's binary_logloss: 0.335339\n",
            "[300]\ttraining's binary_logloss: 0.271643\tvalid_1's binary_logloss: 0.324292\n",
            "[350]\ttraining's binary_logloss: 0.2564\tvalid_1's binary_logloss: 0.316556\n",
            "[400]\ttraining's binary_logloss: 0.250245\tvalid_1's binary_logloss: 0.313612\n",
            "[450]\ttraining's binary_logloss: 0.246061\tvalid_1's binary_logloss: 0.311415\n",
            "[500]\ttraining's binary_logloss: 0.226413\tvalid_1's binary_logloss: 0.304614\n",
            "[550]\ttraining's binary_logloss: 0.218474\tvalid_1's binary_logloss: 0.302631\n",
            "[600]\ttraining's binary_logloss: 0.212013\tvalid_1's binary_logloss: 0.30147\n",
            "[650]\ttraining's binary_logloss: 0.198089\tvalid_1's binary_logloss: 0.299338\n",
            "[700]\ttraining's binary_logloss: 0.188437\tvalid_1's binary_logloss: 0.297216\n",
            "[750]\ttraining's binary_logloss: 0.177337\tvalid_1's binary_logloss: 0.296187\n",
            "[800]\ttraining's binary_logloss: 0.169466\tvalid_1's binary_logloss: 0.295856\n",
            "[850]\ttraining's binary_logloss: 0.158718\tvalid_1's binary_logloss: 0.296529\n",
            "[900]\ttraining's binary_logloss: 0.152401\tvalid_1's binary_logloss: 0.296577\n",
            "[950]\ttraining's binary_logloss: 0.150336\tvalid_1's binary_logloss: 0.296727\n",
            "[1000]\ttraining's binary_logloss: 0.14366\tvalid_1's binary_logloss: 0.298209\n",
            "[1050]\ttraining's binary_logloss: 0.139327\tvalid_1's binary_logloss: 0.299153\n",
            "[1100]\ttraining's binary_logloss: 0.130361\tvalid_1's binary_logloss: 0.299365\n",
            "[1150]\ttraining's binary_logloss: 0.128879\tvalid_1's binary_logloss: 0.298999\n",
            "[1200]\ttraining's binary_logloss: 0.125006\tvalid_1's binary_logloss: 0.299928\n",
            "[1250]\ttraining's binary_logloss: 0.121161\tvalid_1's binary_logloss: 0.300475\n",
            "[1300]\ttraining's binary_logloss: 0.118527\tvalid_1's binary_logloss: 0.300484\n",
            "[1350]\ttraining's binary_logloss: 0.11649\tvalid_1's binary_logloss: 0.300422\n",
            "[1400]\ttraining's binary_logloss: 0.110995\tvalid_1's binary_logloss: 0.302522\n",
            "[1450]\ttraining's binary_logloss: 0.108696\tvalid_1's binary_logloss: 0.303099\n",
            "[1500]\ttraining's binary_logloss: 0.106713\tvalid_1's binary_logloss: 0.303723\n",
            "[1550]\ttraining's binary_logloss: 0.101234\tvalid_1's binary_logloss: 0.304456\n",
            "[1600]\ttraining's binary_logloss: 0.0972817\tvalid_1's binary_logloss: 0.30487\n",
            "[1650]\ttraining's binary_logloss: 0.0940017\tvalid_1's binary_logloss: 0.305885\n",
            "[1700]\ttraining's binary_logloss: 0.0919118\tvalid_1's binary_logloss: 0.306947\n",
            "[1750]\ttraining's binary_logloss: 0.0901497\tvalid_1's binary_logloss: 0.307262\n",
            "[1800]\ttraining's binary_logloss: 0.0891714\tvalid_1's binary_logloss: 0.307244\n",
            "[1850]\ttraining's binary_logloss: 0.0868985\tvalid_1's binary_logloss: 0.30764\n",
            "[1900]\ttraining's binary_logloss: 0.0846547\tvalid_1's binary_logloss: 0.308395\n",
            "[1950]\ttraining's binary_logloss: 0.0814874\tvalid_1's binary_logloss: 0.309757\n",
            "[2000]\ttraining's binary_logloss: 0.0795998\tvalid_1's binary_logloss: 0.310022\n",
            "[2050]\ttraining's binary_logloss: 0.0779752\tvalid_1's binary_logloss: 0.310576\n",
            "[2100]\ttraining's binary_logloss: 0.076441\tvalid_1's binary_logloss: 0.311179\n",
            "[2150]\ttraining's binary_logloss: 0.076245\tvalid_1's binary_logloss: 0.31108\n",
            "[2200]\ttraining's binary_logloss: 0.0741095\tvalid_1's binary_logloss: 0.311858\n",
            "[2250]\ttraining's binary_logloss: 0.0723987\tvalid_1's binary_logloss: 0.312569\n",
            "[2300]\ttraining's binary_logloss: 0.0702844\tvalid_1's binary_logloss: 0.312906\n",
            "[2350]\ttraining's binary_logloss: 0.0690998\tvalid_1's binary_logloss: 0.313152\n",
            "[2400]\ttraining's binary_logloss: 0.0681005\tvalid_1's binary_logloss: 0.31361\n",
            "[2450]\ttraining's binary_logloss: 0.0665626\tvalid_1's binary_logloss: 0.314717\n",
            "[2500]\ttraining's binary_logloss: 0.0657059\tvalid_1's binary_logloss: 0.31435\n",
            "[2550]\ttraining's binary_logloss: 0.0643563\tvalid_1's binary_logloss: 0.314535\n",
            "[2600]\ttraining's binary_logloss: 0.063105\tvalid_1's binary_logloss: 0.31504\n",
            "[2650]\ttraining's binary_logloss: 0.0618091\tvalid_1's binary_logloss: 0.31571\n",
            "[2700]\ttraining's binary_logloss: 0.0603833\tvalid_1's binary_logloss: 0.316637\n",
            "[2750]\ttraining's binary_logloss: 0.0598565\tvalid_1's binary_logloss: 0.317506\n",
            "[2800]\ttraining's binary_logloss: 0.0590961\tvalid_1's binary_logloss: 0.317404\n",
            "[2850]\ttraining's binary_logloss: 0.0571402\tvalid_1's binary_logloss: 0.318483\n",
            "[2900]\ttraining's binary_logloss: 0.0563226\tvalid_1's binary_logloss: 0.318451\n",
            "[2950]\ttraining's binary_logloss: 0.0547777\tvalid_1's binary_logloss: 0.319201\n",
            "[3000]\ttraining's binary_logloss: 0.0536179\tvalid_1's binary_logloss: 0.31996\n",
            "[3050]\ttraining's binary_logloss: 0.0526758\tvalid_1's binary_logloss: 0.320748\n",
            "[3100]\ttraining's binary_logloss: 0.0518027\tvalid_1's binary_logloss: 0.320752\n",
            "[3150]\ttraining's binary_logloss: 0.051088\tvalid_1's binary_logloss: 0.321273\n",
            "[3200]\ttraining's binary_logloss: 0.0498428\tvalid_1's binary_logloss: 0.321938\n",
            "[3250]\ttraining's binary_logloss: 0.0489097\tvalid_1's binary_logloss: 0.322537\n",
            "[3300]\ttraining's binary_logloss: 0.0481654\tvalid_1's binary_logloss: 0.323022\n",
            "[3350]\ttraining's binary_logloss: 0.0470081\tvalid_1's binary_logloss: 0.323666\n",
            "[3400]\ttraining's binary_logloss: 0.0458236\tvalid_1's binary_logloss: 0.324228\n",
            "[3450]\ttraining's binary_logloss: 0.044892\tvalid_1's binary_logloss: 0.325008\n",
            "[3500]\ttraining's binary_logloss: 0.0443547\tvalid_1's binary_logloss: 0.325164\n",
            "[3550]\ttraining's binary_logloss: 0.0435714\tvalid_1's binary_logloss: 0.325703\n",
            "[3600]\ttraining's binary_logloss: 0.0429441\tvalid_1's binary_logloss: 0.326122\n",
            "[3650]\ttraining's binary_logloss: 0.0422478\tvalid_1's binary_logloss: 0.326778\n",
            "[3700]\ttraining's binary_logloss: 0.040804\tvalid_1's binary_logloss: 0.328292\n",
            "[3750]\ttraining's binary_logloss: 0.0401974\tvalid_1's binary_logloss: 0.328938\n",
            "[3800]\ttraining's binary_logloss: 0.0397211\tvalid_1's binary_logloss: 0.329023\n",
            "[3850]\ttraining's binary_logloss: 0.0391333\tvalid_1's binary_logloss: 0.330033\n",
            "[3900]\ttraining's binary_logloss: 0.0387458\tvalid_1's binary_logloss: 0.329854\n",
            "[3950]\ttraining's binary_logloss: 0.0387391\tvalid_1's binary_logloss: 0.329565\n",
            "[4000]\ttraining's binary_logloss: 0.0378389\tvalid_1's binary_logloss: 0.33041\n",
            "[4050]\ttraining's binary_logloss: 0.0374073\tvalid_1's binary_logloss: 0.330651\n",
            "[4100]\ttraining's binary_logloss: 0.0368569\tvalid_1's binary_logloss: 0.331149\n",
            "[4150]\ttraining's binary_logloss: 0.035904\tvalid_1's binary_logloss: 0.332407\n",
            "[4200]\ttraining's binary_logloss: 0.0354026\tvalid_1's binary_logloss: 0.332438\n",
            "[4250]\ttraining's binary_logloss: 0.0348676\tvalid_1's binary_logloss: 0.332676\n",
            "[4300]\ttraining's binary_logloss: 0.0340527\tvalid_1's binary_logloss: 0.333776\n",
            "[4350]\ttraining's binary_logloss: 0.0338858\tvalid_1's binary_logloss: 0.333717\n",
            "[4400]\ttraining's binary_logloss: 0.0336056\tvalid_1's binary_logloss: 0.334042\n",
            "[4450]\ttraining's binary_logloss: 0.0329412\tvalid_1's binary_logloss: 0.335007\n",
            "[4500]\ttraining's binary_logloss: 0.032644\tvalid_1's binary_logloss: 0.3355\n",
            " - 0 round - train_metric: 0.673783 - valid_metric: 0.674472\n",
            "\n",
            " - 50 round - train_metric: 0.425053 - valid_metric: 0.443784\n",
            "\n",
            " - 100 round - train_metric: 0.358690 - valid_metric: 0.387515\n",
            "\n",
            " - 150 round - train_metric: 0.337860 - valid_metric: 0.370859\n",
            "\n",
            " - 200 round - train_metric: 0.322806 - valid_metric: 0.359661\n",
            "\n",
            " - 250 round - train_metric: 0.288040 - valid_metric: 0.333948\n",
            "\n",
            " - 300 round - train_metric: 0.270053 - valid_metric: 0.323397\n",
            "\n",
            " - 350 round - train_metric: 0.257119 - valid_metric: 0.316950\n",
            "\n",
            " - 400 round - train_metric: 0.250801 - valid_metric: 0.313903\n",
            "\n",
            " - 450 round - train_metric: 0.246568 - valid_metric: 0.311670\n",
            "\n",
            " - 500 round - train_metric: 0.225501 - valid_metric: 0.304212\n",
            "\n",
            " - 550 round - train_metric: 0.217788 - valid_metric: 0.302465\n",
            "\n",
            " - 600 round - train_metric: 0.211337 - valid_metric: 0.301260\n",
            "\n",
            " - 650 round - train_metric: 0.198332 - valid_metric: 0.299389\n",
            "\n",
            " - 700 round - train_metric: 0.188702 - valid_metric: 0.297248\n",
            "\n",
            " - 750 round - train_metric: 0.177606 - valid_metric: 0.296203\n",
            "\n",
            " - 800 round - train_metric: 0.169643 - valid_metric: 0.295848\n",
            "\n",
            " - 850 round - train_metric: 0.158274 - valid_metric: 0.296453\n",
            "\n",
            " - 900 round - train_metric: 0.152039 - valid_metric: 0.296562\n",
            "\n",
            " - 950 round - train_metric: 0.149967 - valid_metric: 0.296769\n",
            "\n",
            " - 1000 round - train_metric: 0.143823 - valid_metric: 0.298195\n",
            "\n",
            " - 1050 round - train_metric: 0.139071 - valid_metric: 0.299082\n",
            "\n",
            " - 1100 round - train_metric: 0.130066 - valid_metric: 0.299353\n",
            "\n",
            " - 1150 round - train_metric: 0.128995 - valid_metric: 0.298973\n",
            "\n",
            " - 1200 round - train_metric: 0.125129 - valid_metric: 0.299900\n",
            "\n",
            " - 1250 round - train_metric: 0.121262 - valid_metric: 0.300443\n",
            "\n",
            " - 1300 round - train_metric: 0.118630 - valid_metric: 0.300457\n",
            "\n",
            " - 1350 round - train_metric: 0.116623 - valid_metric: 0.300373\n",
            "\n",
            " - 1400 round - train_metric: 0.110756 - valid_metric: 0.302626\n",
            "\n",
            " - 1450 round - train_metric: 0.108809 - valid_metric: 0.303064\n",
            "\n",
            " - 1500 round - train_metric: 0.106518 - valid_metric: 0.303787\n",
            "\n",
            " - 1550 round - train_metric: 0.101037 - valid_metric: 0.304477\n",
            "\n",
            " - 1600 round - train_metric: 0.097390 - valid_metric: 0.304812\n",
            "\n",
            " - 1650 round - train_metric: 0.093855 - valid_metric: 0.305969\n",
            "\n",
            " - 1700 round - train_metric: 0.091719 - valid_metric: 0.307107\n",
            "\n",
            " - 1750 round - train_metric: 0.090231 - valid_metric: 0.307213\n",
            "\n",
            " - 1800 round - train_metric: 0.088987 - valid_metric: 0.307248\n",
            "\n",
            " - 1850 round - train_metric: 0.087004 - valid_metric: 0.307593\n",
            "\n",
            " - 1900 round - train_metric: 0.084520 - valid_metric: 0.308526\n",
            "\n",
            " - 1950 round - train_metric: 0.081558 - valid_metric: 0.309703\n",
            "\n",
            " - 2000 round - train_metric: 0.079458 - valid_metric: 0.309948\n",
            "\n",
            " - 2050 round - train_metric: 0.078036 - valid_metric: 0.310529\n",
            "\n",
            " - 2100 round - train_metric: 0.076491 - valid_metric: 0.311144\n",
            "\n",
            " - 2150 round - train_metric: 0.076316 - valid_metric: 0.311030\n",
            "\n",
            " - 2200 round - train_metric: 0.074177 - valid_metric: 0.311809\n",
            "\n",
            " - 2250 round - train_metric: 0.072310 - valid_metric: 0.312591\n",
            "\n",
            " - 2300 round - train_metric: 0.070348 - valid_metric: 0.312854\n",
            "\n",
            " - 2350 round - train_metric: 0.069172 - valid_metric: 0.313096\n",
            "\n",
            " - 2400 round - train_metric: 0.068001 - valid_metric: 0.313697\n",
            "\n",
            " - 2450 round - train_metric: 0.066443 - valid_metric: 0.314781\n",
            "\n",
            " - 2500 round - train_metric: 0.065741 - valid_metric: 0.314314\n",
            "\n",
            " - 2550 round - train_metric: 0.064257 - valid_metric: 0.314572\n",
            "\n",
            " - 2600 round - train_metric: 0.063134 - valid_metric: 0.315012\n",
            "\n",
            " - 2650 round - train_metric: 0.061840 - valid_metric: 0.315679\n",
            "\n",
            " - 2700 round - train_metric: 0.060430 - valid_metric: 0.316592\n",
            "\n",
            " - 2750 round - train_metric: 0.059893 - valid_metric: 0.317473\n",
            "\n",
            " - 2800 round - train_metric: 0.058981 - valid_metric: 0.317381\n",
            "\n",
            " - 2850 round - train_metric: 0.057174 - valid_metric: 0.318449\n",
            "\n",
            " - 2900 round - train_metric: 0.056371 - valid_metric: 0.318397\n",
            "\n",
            " - 2950 round - train_metric: 0.054811 - valid_metric: 0.319158\n",
            "\n",
            " - 3000 round - train_metric: 0.053652 - valid_metric: 0.319920\n",
            "\n",
            " - 3050 round - train_metric: 0.052602 - valid_metric: 0.320740\n",
            "\n",
            " - 3100 round - train_metric: 0.051829 - valid_metric: 0.320712\n",
            "\n",
            " - 3150 round - train_metric: 0.051122 - valid_metric: 0.321227\n",
            "\n",
            " - 3200 round - train_metric: 0.049778 - valid_metric: 0.321917\n",
            "\n",
            " - 3250 round - train_metric: 0.048930 - valid_metric: 0.322500\n",
            "\n",
            " - 3300 round - train_metric: 0.048193 - valid_metric: 0.322982\n",
            "\n",
            " - 3350 round - train_metric: 0.047035 - valid_metric: 0.323630\n",
            "\n",
            " - 3400 round - train_metric: 0.045850 - valid_metric: 0.324181\n",
            "\n",
            " - 3450 round - train_metric: 0.044840 - valid_metric: 0.325089\n",
            "\n",
            " - 3500 round - train_metric: 0.044301 - valid_metric: 0.325281\n",
            "\n",
            " - 3550 round - train_metric: 0.043592 - valid_metric: 0.325667\n",
            "\n",
            " - 3600 round - train_metric: 0.042969 - valid_metric: 0.326083\n",
            "\n",
            " - 3650 round - train_metric: 0.042282 - valid_metric: 0.326722\n",
            "\n",
            " - 3700 round - train_metric: 0.040761 - valid_metric: 0.328341\n",
            "\n",
            " - 3750 round - train_metric: 0.040148 - valid_metric: 0.328924\n",
            "\n",
            " - 3800 round - train_metric: 0.039675 - valid_metric: 0.329112\n",
            "\n",
            " - 3850 round - train_metric: 0.039090 - valid_metric: 0.329994\n",
            "\n",
            " - 3900 round - train_metric: 0.038761 - valid_metric: 0.329820\n",
            "\n",
            " - 3950 round - train_metric: 0.038701 - valid_metric: 0.329628\n",
            "\n",
            " - 4000 round - train_metric: 0.037798 - valid_metric: 0.330451\n",
            "\n",
            " - 4050 round - train_metric: 0.037427 - valid_metric: 0.330612\n",
            "\n",
            " - 4100 round - train_metric: 0.036882 - valid_metric: 0.331099\n",
            "\n",
            " - 4150 round - train_metric: 0.035927 - valid_metric: 0.332365\n",
            "\n",
            " - 4200 round - train_metric: 0.035423 - valid_metric: 0.332401\n",
            "\n",
            " - 4250 round - train_metric: 0.034887 - valid_metric: 0.332637\n",
            "\n",
            " - 4300 round - train_metric: 0.034079 - valid_metric: 0.333734\n",
            "\n",
            " - 4350 round - train_metric: 0.033850 - valid_metric: 0.333735\n",
            "\n",
            " - 4400 round - train_metric: 0.033579 - valid_metric: 0.334024\n",
            "\n",
            " - 4450 round - train_metric: 0.032959 - valid_metric: 0.334966\n",
            "\n",
            "- fold2 valid metric: 0.632886\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.425213\tvalid_1's binary_logloss: 0.436537\n",
            "[100]\ttraining's binary_logloss: 0.366152\tvalid_1's binary_logloss: 0.383732\n",
            "[150]\ttraining's binary_logloss: 0.339538\tvalid_1's binary_logloss: 0.360331\n",
            "[200]\ttraining's binary_logloss: 0.325472\tvalid_1's binary_logloss: 0.349211\n",
            "[250]\ttraining's binary_logloss: 0.294266\tvalid_1's binary_logloss: 0.324933\n",
            "[300]\ttraining's binary_logloss: 0.275926\tvalid_1's binary_logloss: 0.312038\n",
            "[350]\ttraining's binary_logloss: 0.261992\tvalid_1's binary_logloss: 0.304257\n",
            "[400]\ttraining's binary_logloss: 0.255408\tvalid_1's binary_logloss: 0.301159\n",
            "[450]\ttraining's binary_logloss: 0.2517\tvalid_1's binary_logloss: 0.299866\n",
            "[500]\ttraining's binary_logloss: 0.232268\tvalid_1's binary_logloss: 0.291279\n",
            "[550]\ttraining's binary_logloss: 0.223917\tvalid_1's binary_logloss: 0.287897\n",
            "[600]\ttraining's binary_logloss: 0.217369\tvalid_1's binary_logloss: 0.285841\n",
            "[650]\ttraining's binary_logloss: 0.202935\tvalid_1's binary_logloss: 0.282529\n",
            "[700]\ttraining's binary_logloss: 0.193301\tvalid_1's binary_logloss: 0.280876\n",
            "[750]\ttraining's binary_logloss: 0.181604\tvalid_1's binary_logloss: 0.280066\n",
            "[800]\ttraining's binary_logloss: 0.172786\tvalid_1's binary_logloss: 0.279804\n",
            "[850]\ttraining's binary_logloss: 0.161877\tvalid_1's binary_logloss: 0.279291\n",
            "[900]\ttraining's binary_logloss: 0.155793\tvalid_1's binary_logloss: 0.279393\n",
            "[950]\ttraining's binary_logloss: 0.15374\tvalid_1's binary_logloss: 0.279124\n",
            "[1000]\ttraining's binary_logloss: 0.14676\tvalid_1's binary_logloss: 0.279016\n",
            "[1050]\ttraining's binary_logloss: 0.142027\tvalid_1's binary_logloss: 0.279496\n",
            "[1100]\ttraining's binary_logloss: 0.132993\tvalid_1's binary_logloss: 0.279661\n",
            "[1150]\ttraining's binary_logloss: 0.131473\tvalid_1's binary_logloss: 0.279712\n",
            "[1200]\ttraining's binary_logloss: 0.127182\tvalid_1's binary_logloss: 0.279835\n",
            "[1250]\ttraining's binary_logloss: 0.123051\tvalid_1's binary_logloss: 0.280384\n",
            "[1300]\ttraining's binary_logloss: 0.120409\tvalid_1's binary_logloss: 0.280714\n",
            "[1350]\ttraining's binary_logloss: 0.11847\tvalid_1's binary_logloss: 0.280803\n",
            "[1400]\ttraining's binary_logloss: 0.112413\tvalid_1's binary_logloss: 0.281209\n",
            "[1450]\ttraining's binary_logloss: 0.110331\tvalid_1's binary_logloss: 0.280772\n",
            "[1500]\ttraining's binary_logloss: 0.108122\tvalid_1's binary_logloss: 0.280952\n",
            "[1550]\ttraining's binary_logloss: 0.102655\tvalid_1's binary_logloss: 0.282068\n",
            "[1600]\ttraining's binary_logloss: 0.0986022\tvalid_1's binary_logloss: 0.282397\n",
            "[1650]\ttraining's binary_logloss: 0.0951676\tvalid_1's binary_logloss: 0.28352\n",
            "[1700]\ttraining's binary_logloss: 0.0932298\tvalid_1's binary_logloss: 0.283921\n",
            "[1750]\ttraining's binary_logloss: 0.0913371\tvalid_1's binary_logloss: 0.284321\n",
            "[1800]\ttraining's binary_logloss: 0.0900523\tvalid_1's binary_logloss: 0.284461\n",
            "[1850]\ttraining's binary_logloss: 0.0878552\tvalid_1's binary_logloss: 0.284637\n",
            "[1900]\ttraining's binary_logloss: 0.085461\tvalid_1's binary_logloss: 0.284713\n",
            "[1950]\ttraining's binary_logloss: 0.0823783\tvalid_1's binary_logloss: 0.284702\n",
            "[2000]\ttraining's binary_logloss: 0.0802952\tvalid_1's binary_logloss: 0.28493\n",
            "[2050]\ttraining's binary_logloss: 0.078665\tvalid_1's binary_logloss: 0.285686\n",
            "[2100]\ttraining's binary_logloss: 0.0772862\tvalid_1's binary_logloss: 0.286136\n",
            "[2150]\ttraining's binary_logloss: 0.077105\tvalid_1's binary_logloss: 0.286006\n",
            "[2200]\ttraining's binary_logloss: 0.0749285\tvalid_1's binary_logloss: 0.28729\n",
            "[2250]\ttraining's binary_logloss: 0.0732011\tvalid_1's binary_logloss: 0.287823\n",
            "[2300]\ttraining's binary_logloss: 0.0710764\tvalid_1's binary_logloss: 0.28857\n",
            "[2350]\ttraining's binary_logloss: 0.0698727\tvalid_1's binary_logloss: 0.289252\n",
            "[2400]\ttraining's binary_logloss: 0.0688501\tvalid_1's binary_logloss: 0.289298\n",
            "[2450]\ttraining's binary_logloss: 0.0672542\tvalid_1's binary_logloss: 0.289914\n",
            "[2500]\ttraining's binary_logloss: 0.0665166\tvalid_1's binary_logloss: 0.289975\n",
            "[2550]\ttraining's binary_logloss: 0.0652424\tvalid_1's binary_logloss: 0.290377\n",
            "[2600]\ttraining's binary_logloss: 0.0639609\tvalid_1's binary_logloss: 0.290748\n",
            "[2650]\ttraining's binary_logloss: 0.0627245\tvalid_1's binary_logloss: 0.2912\n",
            "[2700]\ttraining's binary_logloss: 0.0612052\tvalid_1's binary_logloss: 0.291812\n",
            "[2750]\ttraining's binary_logloss: 0.0606616\tvalid_1's binary_logloss: 0.29151\n",
            "[2800]\ttraining's binary_logloss: 0.0597989\tvalid_1's binary_logloss: 0.292161\n",
            "[2850]\ttraining's binary_logloss: 0.0578968\tvalid_1's binary_logloss: 0.292641\n",
            "[2900]\ttraining's binary_logloss: 0.0570314\tvalid_1's binary_logloss: 0.292779\n",
            "[2950]\ttraining's binary_logloss: 0.0555318\tvalid_1's binary_logloss: 0.293701\n",
            "[3000]\ttraining's binary_logloss: 0.0543139\tvalid_1's binary_logloss: 0.294036\n",
            "[3050]\ttraining's binary_logloss: 0.0534328\tvalid_1's binary_logloss: 0.294412\n",
            "[3100]\ttraining's binary_logloss: 0.0524552\tvalid_1's binary_logloss: 0.294724\n",
            "[3150]\ttraining's binary_logloss: 0.0516618\tvalid_1's binary_logloss: 0.2952\n",
            "[3200]\ttraining's binary_logloss: 0.0505282\tvalid_1's binary_logloss: 0.296018\n",
            "[3250]\ttraining's binary_logloss: 0.0494976\tvalid_1's binary_logloss: 0.297038\n",
            "[3300]\ttraining's binary_logloss: 0.0487627\tvalid_1's binary_logloss: 0.297386\n",
            "[3350]\ttraining's binary_logloss: 0.0476604\tvalid_1's binary_logloss: 0.297826\n",
            "[3400]\ttraining's binary_logloss: 0.0464803\tvalid_1's binary_logloss: 0.298521\n",
            "[3450]\ttraining's binary_logloss: 0.0455699\tvalid_1's binary_logloss: 0.299058\n",
            "[3500]\ttraining's binary_logloss: 0.045056\tvalid_1's binary_logloss: 0.298771\n",
            "[3550]\ttraining's binary_logloss: 0.0442682\tvalid_1's binary_logloss: 0.299238\n",
            "[3600]\ttraining's binary_logloss: 0.0435707\tvalid_1's binary_logloss: 0.299543\n",
            "[3650]\ttraining's binary_logloss: 0.042887\tvalid_1's binary_logloss: 0.299779\n",
            "[3700]\ttraining's binary_logloss: 0.0414967\tvalid_1's binary_logloss: 0.300794\n",
            "[3750]\ttraining's binary_logloss: 0.0408344\tvalid_1's binary_logloss: 0.301601\n",
            "[3800]\ttraining's binary_logloss: 0.0403724\tvalid_1's binary_logloss: 0.301696\n",
            "[3850]\ttraining's binary_logloss: 0.0398155\tvalid_1's binary_logloss: 0.302152\n",
            "[3900]\ttraining's binary_logloss: 0.0394508\tvalid_1's binary_logloss: 0.302368\n",
            "[3950]\ttraining's binary_logloss: 0.0394446\tvalid_1's binary_logloss: 0.302091\n",
            "[4000]\ttraining's binary_logloss: 0.038602\tvalid_1's binary_logloss: 0.302966\n",
            "[4050]\ttraining's binary_logloss: 0.0381711\tvalid_1's binary_logloss: 0.303401\n",
            "[4100]\ttraining's binary_logloss: 0.0375859\tvalid_1's binary_logloss: 0.303627\n",
            "[4150]\ttraining's binary_logloss: 0.0366393\tvalid_1's binary_logloss: 0.304502\n",
            "[4200]\ttraining's binary_logloss: 0.0361334\tvalid_1's binary_logloss: 0.305067\n",
            "[4250]\ttraining's binary_logloss: 0.0355845\tvalid_1's binary_logloss: 0.305831\n",
            "[4300]\ttraining's binary_logloss: 0.0347197\tvalid_1's binary_logloss: 0.306459\n",
            "[4350]\ttraining's binary_logloss: 0.0345572\tvalid_1's binary_logloss: 0.306556\n",
            "[4400]\ttraining's binary_logloss: 0.0342637\tvalid_1's binary_logloss: 0.306778\n",
            "[4450]\ttraining's binary_logloss: 0.0335892\tvalid_1's binary_logloss: 0.30726\n",
            "[4500]\ttraining's binary_logloss: 0.033258\tvalid_1's binary_logloss: 0.307699\n",
            " - 0 round - train_metric: 0.673895 - valid_metric: 0.674874\n",
            "\n",
            " - 50 round - train_metric: 0.427534 - valid_metric: 0.438716\n",
            "\n",
            " - 100 round - train_metric: 0.362092 - valid_metric: 0.380103\n",
            "\n",
            " - 150 round - train_metric: 0.341430 - valid_metric: 0.362019\n",
            "\n",
            " - 200 round - train_metric: 0.326736 - valid_metric: 0.350317\n",
            "\n",
            " - 250 round - train_metric: 0.292427 - valid_metric: 0.323611\n",
            "\n",
            " - 300 round - train_metric: 0.274449 - valid_metric: 0.310875\n",
            "\n",
            " - 350 round - train_metric: 0.262691 - valid_metric: 0.304730\n",
            "\n",
            " - 400 round - train_metric: 0.255970 - valid_metric: 0.301517\n",
            "\n",
            " - 450 round - train_metric: 0.252209 - valid_metric: 0.300180\n",
            "\n",
            " - 500 round - train_metric: 0.231393 - valid_metric: 0.291060\n",
            "\n",
            " - 550 round - train_metric: 0.223184 - valid_metric: 0.287538\n",
            "\n",
            " - 600 round - train_metric: 0.216677 - valid_metric: 0.285494\n",
            "\n",
            " - 650 round - train_metric: 0.203185 - valid_metric: 0.282638\n",
            "\n",
            " - 700 round - train_metric: 0.193565 - valid_metric: 0.280947\n",
            "\n",
            " - 750 round - train_metric: 0.181873 - valid_metric: 0.280126\n",
            "\n",
            " - 800 round - train_metric: 0.172962 - valid_metric: 0.279842\n",
            "\n",
            " - 850 round - train_metric: 0.161390 - valid_metric: 0.279191\n",
            "\n",
            " - 900 round - train_metric: 0.155377 - valid_metric: 0.279292\n",
            "\n",
            " - 950 round - train_metric: 0.153333 - valid_metric: 0.278972\n",
            "\n",
            " - 1000 round - train_metric: 0.146929 - valid_metric: 0.279020\n",
            "\n",
            " - 1050 round - train_metric: 0.141715 - valid_metric: 0.279502\n",
            "\n",
            " - 1100 round - train_metric: 0.132570 - valid_metric: 0.279613\n",
            "\n",
            " - 1150 round - train_metric: 0.131590 - valid_metric: 0.279714\n",
            "\n",
            " - 1200 round - train_metric: 0.127307 - valid_metric: 0.279821\n",
            "\n",
            " - 1250 round - train_metric: 0.123151 - valid_metric: 0.280376\n",
            "\n",
            " - 1300 round - train_metric: 0.120515 - valid_metric: 0.280699\n",
            "\n",
            " - 1350 round - train_metric: 0.118601 - valid_metric: 0.280794\n",
            "\n",
            " - 1400 round - train_metric: 0.112192 - valid_metric: 0.281300\n",
            "\n",
            " - 1450 round - train_metric: 0.110442 - valid_metric: 0.280751\n",
            "\n",
            " - 1500 round - train_metric: 0.107921 - valid_metric: 0.281038\n",
            "\n",
            " - 1550 round - train_metric: 0.102366 - valid_metric: 0.282099\n",
            "\n",
            " - 1600 round - train_metric: 0.098714 - valid_metric: 0.282360\n",
            "\n",
            " - 1650 round - train_metric: 0.094967 - valid_metric: 0.283530\n",
            "\n",
            " - 1700 round - train_metric: 0.093044 - valid_metric: 0.283984\n",
            "\n",
            " - 1750 round - train_metric: 0.091419 - valid_metric: 0.284290\n",
            "\n",
            " - 1800 round - train_metric: 0.089919 - valid_metric: 0.284444\n",
            "\n",
            " - 1850 round - train_metric: 0.087965 - valid_metric: 0.284597\n",
            "\n",
            " - 1900 round - train_metric: 0.085290 - valid_metric: 0.284592\n",
            "\n",
            " - 1950 round - train_metric: 0.082447 - valid_metric: 0.284671\n",
            "\n",
            " - 2000 round - train_metric: 0.080173 - valid_metric: 0.284985\n",
            "\n",
            " - 2050 round - train_metric: 0.078726 - valid_metric: 0.285654\n",
            "\n",
            " - 2100 round - train_metric: 0.077336 - valid_metric: 0.286113\n",
            "\n",
            " - 2150 round - train_metric: 0.077180 - valid_metric: 0.285978\n",
            "\n",
            " - 2200 round - train_metric: 0.074996 - valid_metric: 0.287251\n",
            "\n",
            " - 2250 round - train_metric: 0.073081 - valid_metric: 0.287882\n",
            "\n",
            " - 2300 round - train_metric: 0.071142 - valid_metric: 0.288529\n",
            "\n",
            " - 2350 round - train_metric: 0.069947 - valid_metric: 0.289198\n",
            "\n",
            " - 2400 round - train_metric: 0.068733 - valid_metric: 0.289342\n",
            "\n",
            " - 2450 round - train_metric: 0.067157 - valid_metric: 0.290033\n",
            "\n",
            " - 2500 round - train_metric: 0.066553 - valid_metric: 0.289951\n",
            "\n",
            " - 2550 round - train_metric: 0.065151 - valid_metric: 0.290429\n",
            "\n",
            " - 2600 round - train_metric: 0.063990 - valid_metric: 0.290724\n",
            "\n",
            " - 2650 round - train_metric: 0.062756 - valid_metric: 0.291176\n",
            "\n",
            " - 2700 round - train_metric: 0.061252 - valid_metric: 0.291777\n",
            "\n",
            " - 2750 round - train_metric: 0.060699 - valid_metric: 0.291487\n",
            "\n",
            " - 2800 round - train_metric: 0.059709 - valid_metric: 0.292262\n",
            "\n",
            " - 2850 round - train_metric: 0.057931 - valid_metric: 0.292609\n",
            "\n",
            " - 2900 round - train_metric: 0.057082 - valid_metric: 0.292742\n",
            "\n",
            " - 2950 round - train_metric: 0.055565 - valid_metric: 0.293675\n",
            "\n",
            " - 3000 round - train_metric: 0.054348 - valid_metric: 0.294008\n",
            "\n",
            " - 3050 round - train_metric: 0.053363 - valid_metric: 0.294529\n",
            "\n",
            " - 3100 round - train_metric: 0.052481 - valid_metric: 0.294702\n",
            "\n",
            " - 3150 round - train_metric: 0.051698 - valid_metric: 0.295171\n",
            "\n",
            " - 3200 round - train_metric: 0.050453 - valid_metric: 0.296071\n",
            "\n",
            " - 3250 round - train_metric: 0.049519 - valid_metric: 0.297014\n",
            "\n",
            " - 3300 round - train_metric: 0.048792 - valid_metric: 0.297353\n",
            "\n",
            " - 3350 round - train_metric: 0.047690 - valid_metric: 0.297793\n",
            "\n",
            " - 3400 round - train_metric: 0.046508 - valid_metric: 0.298494\n",
            "\n",
            " - 3450 round - train_metric: 0.045516 - valid_metric: 0.299039\n",
            "\n",
            " - 3500 round - train_metric: 0.044993 - valid_metric: 0.298761\n",
            "\n",
            " - 3550 round - train_metric: 0.044289 - valid_metric: 0.299211\n",
            "\n",
            " - 3600 round - train_metric: 0.043596 - valid_metric: 0.299515\n",
            "\n",
            " - 3650 round - train_metric: 0.042922 - valid_metric: 0.299737\n",
            "\n",
            " - 3700 round - train_metric: 0.041448 - valid_metric: 0.300852\n",
            "\n",
            " - 3750 round - train_metric: 0.040789 - valid_metric: 0.301674\n",
            "\n",
            " - 3800 round - train_metric: 0.040327 - valid_metric: 0.301736\n",
            "\n",
            " - 3850 round - train_metric: 0.039762 - valid_metric: 0.302184\n",
            "\n",
            " - 3900 round - train_metric: 0.039466 - valid_metric: 0.302350\n",
            "\n",
            " - 3950 round - train_metric: 0.039409 - valid_metric: 0.302157\n",
            "\n",
            " - 4000 round - train_metric: 0.038565 - valid_metric: 0.303021\n",
            "\n",
            " - 4050 round - train_metric: 0.038190 - valid_metric: 0.303372\n",
            "\n",
            " - 4100 round - train_metric: 0.037612 - valid_metric: 0.303590\n",
            "\n",
            " - 4150 round - train_metric: 0.036664 - valid_metric: 0.304469\n",
            "\n",
            " - 4200 round - train_metric: 0.036154 - valid_metric: 0.305035\n",
            "\n",
            " - 4250 round - train_metric: 0.035605 - valid_metric: 0.305796\n",
            "\n",
            " - 4300 round - train_metric: 0.034746 - valid_metric: 0.306413\n",
            "\n",
            " - 4350 round - train_metric: 0.034518 - valid_metric: 0.306666\n",
            "\n",
            " - 4400 round - train_metric: 0.034233 - valid_metric: 0.306790\n",
            "\n",
            " - 4450 round - train_metric: 0.033606 - valid_metric: 0.307235\n",
            "\n",
            "- fold3 valid metric: 0.645440\n",
            "\n",
            "[50]\ttraining's binary_logloss: 0.425578\tvalid_1's binary_logloss: 0.436364\n",
            "[100]\ttraining's binary_logloss: 0.365897\tvalid_1's binary_logloss: 0.382587\n",
            "[150]\ttraining's binary_logloss: 0.339512\tvalid_1's binary_logloss: 0.359661\n",
            "[200]\ttraining's binary_logloss: 0.325276\tvalid_1's binary_logloss: 0.349242\n",
            "[250]\ttraining's binary_logloss: 0.294088\tvalid_1's binary_logloss: 0.325272\n",
            "[300]\ttraining's binary_logloss: 0.275337\tvalid_1's binary_logloss: 0.313422\n",
            "[350]\ttraining's binary_logloss: 0.261212\tvalid_1's binary_logloss: 0.305353\n",
            "[400]\ttraining's binary_logloss: 0.254804\tvalid_1's binary_logloss: 0.30218\n",
            "[450]\ttraining's binary_logloss: 0.25044\tvalid_1's binary_logloss: 0.300005\n",
            "[500]\ttraining's binary_logloss: 0.231332\tvalid_1's binary_logloss: 0.291952\n",
            "[550]\ttraining's binary_logloss: 0.223238\tvalid_1's binary_logloss: 0.288308\n",
            "[600]\ttraining's binary_logloss: 0.216889\tvalid_1's binary_logloss: 0.28775\n",
            "[650]\ttraining's binary_logloss: 0.202651\tvalid_1's binary_logloss: 0.284024\n",
            "[700]\ttraining's binary_logloss: 0.19283\tvalid_1's binary_logloss: 0.283224\n",
            "[750]\ttraining's binary_logloss: 0.181715\tvalid_1's binary_logloss: 0.282434\n",
            "[800]\ttraining's binary_logloss: 0.173901\tvalid_1's binary_logloss: 0.281428\n",
            "[850]\ttraining's binary_logloss: 0.162864\tvalid_1's binary_logloss: 0.280984\n",
            "[900]\ttraining's binary_logloss: 0.156687\tvalid_1's binary_logloss: 0.280593\n",
            "[950]\ttraining's binary_logloss: 0.154348\tvalid_1's binary_logloss: 0.280408\n",
            "[1000]\ttraining's binary_logloss: 0.147383\tvalid_1's binary_logloss: 0.280181\n",
            "[1050]\ttraining's binary_logloss: 0.142903\tvalid_1's binary_logloss: 0.279728\n",
            "[1100]\ttraining's binary_logloss: 0.133485\tvalid_1's binary_logloss: 0.280128\n",
            "[1150]\ttraining's binary_logloss: 0.131684\tvalid_1's binary_logloss: 0.280098\n",
            "[1200]\ttraining's binary_logloss: 0.127607\tvalid_1's binary_logloss: 0.281298\n",
            "[1250]\ttraining's binary_logloss: 0.123366\tvalid_1's binary_logloss: 0.281581\n",
            "[1300]\ttraining's binary_logloss: 0.121225\tvalid_1's binary_logloss: 0.282346\n",
            "[1350]\ttraining's binary_logloss: 0.119049\tvalid_1's binary_logloss: 0.283043\n",
            "[1400]\ttraining's binary_logloss: 0.113383\tvalid_1's binary_logloss: 0.284037\n",
            "[1450]\ttraining's binary_logloss: 0.111057\tvalid_1's binary_logloss: 0.283903\n",
            "[1500]\ttraining's binary_logloss: 0.108969\tvalid_1's binary_logloss: 0.283582\n",
            "[1550]\ttraining's binary_logloss: 0.103431\tvalid_1's binary_logloss: 0.284863\n",
            "[1600]\ttraining's binary_logloss: 0.0992603\tvalid_1's binary_logloss: 0.285153\n",
            "[1650]\ttraining's binary_logloss: 0.0957927\tvalid_1's binary_logloss: 0.285655\n",
            "[1700]\ttraining's binary_logloss: 0.0939984\tvalid_1's binary_logloss: 0.286023\n",
            "[1750]\ttraining's binary_logloss: 0.0920335\tvalid_1's binary_logloss: 0.286428\n",
            "[1800]\ttraining's binary_logloss: 0.091008\tvalid_1's binary_logloss: 0.28609\n",
            "[1850]\ttraining's binary_logloss: 0.0886486\tvalid_1's binary_logloss: 0.286728\n",
            "[1900]\ttraining's binary_logloss: 0.0862033\tvalid_1's binary_logloss: 0.28768\n",
            "[1950]\ttraining's binary_logloss: 0.0831402\tvalid_1's binary_logloss: 0.288649\n",
            "[2000]\ttraining's binary_logloss: 0.0811633\tvalid_1's binary_logloss: 0.289491\n",
            "[2050]\ttraining's binary_logloss: 0.0796028\tvalid_1's binary_logloss: 0.289903\n",
            "[2100]\ttraining's binary_logloss: 0.0779882\tvalid_1's binary_logloss: 0.29037\n",
            "[2150]\ttraining's binary_logloss: 0.0779226\tvalid_1's binary_logloss: 0.290473\n",
            "[2200]\ttraining's binary_logloss: 0.0758446\tvalid_1's binary_logloss: 0.291259\n",
            "[2250]\ttraining's binary_logloss: 0.074089\tvalid_1's binary_logloss: 0.291148\n",
            "[2300]\ttraining's binary_logloss: 0.0718083\tvalid_1's binary_logloss: 0.292345\n",
            "[2350]\ttraining's binary_logloss: 0.0705806\tvalid_1's binary_logloss: 0.292984\n",
            "[2400]\ttraining's binary_logloss: 0.0695156\tvalid_1's binary_logloss: 0.293426\n",
            "[2450]\ttraining's binary_logloss: 0.0681059\tvalid_1's binary_logloss: 0.294045\n",
            "[2500]\ttraining's binary_logloss: 0.0673657\tvalid_1's binary_logloss: 0.293938\n",
            "[2550]\ttraining's binary_logloss: 0.0660683\tvalid_1's binary_logloss: 0.294611\n",
            "[2600]\ttraining's binary_logloss: 0.0647572\tvalid_1's binary_logloss: 0.295356\n",
            "[2650]\ttraining's binary_logloss: 0.0634422\tvalid_1's binary_logloss: 0.296271\n",
            "[2700]\ttraining's binary_logloss: 0.0618319\tvalid_1's binary_logloss: 0.297041\n",
            "[2750]\ttraining's binary_logloss: 0.0613514\tvalid_1's binary_logloss: 0.297175\n",
            "[2800]\ttraining's binary_logloss: 0.0604527\tvalid_1's binary_logloss: 0.29784\n",
            "[2850]\ttraining's binary_logloss: 0.0586271\tvalid_1's binary_logloss: 0.298919\n",
            "[2900]\ttraining's binary_logloss: 0.0577929\tvalid_1's binary_logloss: 0.299301\n",
            "[2950]\ttraining's binary_logloss: 0.0562375\tvalid_1's binary_logloss: 0.300648\n",
            "[3000]\ttraining's binary_logloss: 0.055023\tvalid_1's binary_logloss: 0.301188\n",
            "[3050]\ttraining's binary_logloss: 0.0540768\tvalid_1's binary_logloss: 0.301365\n",
            "[3100]\ttraining's binary_logloss: 0.0530971\tvalid_1's binary_logloss: 0.302355\n",
            "[3150]\ttraining's binary_logloss: 0.0523984\tvalid_1's binary_logloss: 0.3026\n",
            "[3200]\ttraining's binary_logloss: 0.0511852\tvalid_1's binary_logloss: 0.303342\n",
            "[3250]\ttraining's binary_logloss: 0.0502341\tvalid_1's binary_logloss: 0.303925\n",
            "[3300]\ttraining's binary_logloss: 0.049521\tvalid_1's binary_logloss: 0.304389\n",
            "[3350]\ttraining's binary_logloss: 0.048355\tvalid_1's binary_logloss: 0.305336\n",
            "[3400]\ttraining's binary_logloss: 0.0471962\tvalid_1's binary_logloss: 0.306219\n",
            "[3450]\ttraining's binary_logloss: 0.0462034\tvalid_1's binary_logloss: 0.306696\n",
            "[3500]\ttraining's binary_logloss: 0.0456056\tvalid_1's binary_logloss: 0.30715\n",
            "[3550]\ttraining's binary_logloss: 0.0448481\tvalid_1's binary_logloss: 0.307547\n",
            "[3600]\ttraining's binary_logloss: 0.0441841\tvalid_1's binary_logloss: 0.307852\n",
            "[3650]\ttraining's binary_logloss: 0.0434675\tvalid_1's binary_logloss: 0.308322\n",
            "[3700]\ttraining's binary_logloss: 0.0419355\tvalid_1's binary_logloss: 0.309024\n",
            "[3750]\ttraining's binary_logloss: 0.0412937\tvalid_1's binary_logloss: 0.309848\n",
            "[3800]\ttraining's binary_logloss: 0.0407573\tvalid_1's binary_logloss: 0.310093\n",
            "[3850]\ttraining's binary_logloss: 0.0401712\tvalid_1's binary_logloss: 0.310762\n",
            "[3900]\ttraining's binary_logloss: 0.0398108\tvalid_1's binary_logloss: 0.311408\n",
            "[3950]\ttraining's binary_logloss: 0.0398009\tvalid_1's binary_logloss: 0.311394\n",
            "[4000]\ttraining's binary_logloss: 0.0389425\tvalid_1's binary_logloss: 0.312445\n",
            "[4050]\ttraining's binary_logloss: 0.0384627\tvalid_1's binary_logloss: 0.312985\n",
            "[4100]\ttraining's binary_logloss: 0.0378259\tvalid_1's binary_logloss: 0.314401\n",
            "[4150]\ttraining's binary_logloss: 0.036936\tvalid_1's binary_logloss: 0.31551\n",
            "[4200]\ttraining's binary_logloss: 0.0364171\tvalid_1's binary_logloss: 0.316579\n",
            "[4250]\ttraining's binary_logloss: 0.0358474\tvalid_1's binary_logloss: 0.317354\n",
            "[4300]\ttraining's binary_logloss: 0.0350531\tvalid_1's binary_logloss: 0.317972\n",
            "[4350]\ttraining's binary_logloss: 0.0348384\tvalid_1's binary_logloss: 0.317736\n",
            "[4400]\ttraining's binary_logloss: 0.0345765\tvalid_1's binary_logloss: 0.317973\n",
            "[4450]\ttraining's binary_logloss: 0.0338921\tvalid_1's binary_logloss: 0.318831\n",
            "[4500]\ttraining's binary_logloss: 0.0336083\tvalid_1's binary_logloss: 0.319095\n",
            " - 0 round - train_metric: 0.674010 - valid_metric: 0.674528\n",
            "\n",
            " - 50 round - train_metric: 0.427877 - valid_metric: 0.438515\n",
            "\n",
            " - 100 round - train_metric: 0.361850 - valid_metric: 0.379167\n",
            "\n",
            " - 150 round - train_metric: 0.341415 - valid_metric: 0.361330\n",
            "\n",
            " - 200 round - train_metric: 0.326539 - valid_metric: 0.350298\n",
            "\n",
            " - 250 round - train_metric: 0.292180 - valid_metric: 0.324018\n",
            "\n",
            " - 300 round - train_metric: 0.273840 - valid_metric: 0.312381\n",
            "\n",
            " - 350 round - train_metric: 0.261919 - valid_metric: 0.305799\n",
            "\n",
            " - 400 round - train_metric: 0.255357 - valid_metric: 0.302516\n",
            "\n",
            " - 450 round - train_metric: 0.250948 - valid_metric: 0.300300\n",
            "\n",
            " - 500 round - train_metric: 0.230358 - valid_metric: 0.291955\n",
            "\n",
            " - 550 round - train_metric: 0.222459 - valid_metric: 0.288013\n",
            "\n",
            " - 600 round - train_metric: 0.216170 - valid_metric: 0.287327\n",
            "\n",
            " - 650 round - train_metric: 0.202892 - valid_metric: 0.284086\n",
            "\n",
            " - 700 round - train_metric: 0.193097 - valid_metric: 0.283284\n",
            "\n",
            " - 750 round - train_metric: 0.181977 - valid_metric: 0.282456\n",
            "\n",
            " - 800 round - train_metric: 0.174073 - valid_metric: 0.281440\n",
            "\n",
            " - 850 round - train_metric: 0.162441 - valid_metric: 0.280879\n",
            "\n",
            " - 900 round - train_metric: 0.156183 - valid_metric: 0.280559\n",
            "\n",
            " - 950 round - train_metric: 0.153892 - valid_metric: 0.280620\n",
            "\n",
            " - 1000 round - train_metric: 0.147549 - valid_metric: 0.280164\n",
            "\n",
            " - 1050 round - train_metric: 0.142577 - valid_metric: 0.279809\n",
            "\n",
            " - 1100 round - train_metric: 0.133158 - valid_metric: 0.280150\n",
            "\n",
            " - 1150 round - train_metric: 0.131798 - valid_metric: 0.280087\n",
            "\n",
            " - 1200 round - train_metric: 0.127730 - valid_metric: 0.281290\n",
            "\n",
            " - 1250 round - train_metric: 0.123468 - valid_metric: 0.281557\n",
            "\n",
            " - 1300 round - train_metric: 0.121328 - valid_metric: 0.282330\n",
            "\n",
            " - 1350 round - train_metric: 0.119178 - valid_metric: 0.283026\n",
            "\n",
            " - 1400 round - train_metric: 0.113141 - valid_metric: 0.283946\n",
            "\n",
            " - 1450 round - train_metric: 0.111170 - valid_metric: 0.283882\n",
            "\n",
            " - 1500 round - train_metric: 0.108788 - valid_metric: 0.283570\n",
            "\n",
            " - 1550 round - train_metric: 0.103237 - valid_metric: 0.284914\n",
            "\n",
            " - 1600 round - train_metric: 0.099373 - valid_metric: 0.285117\n",
            "\n",
            " - 1650 round - train_metric: 0.095639 - valid_metric: 0.285691\n",
            "\n",
            " - 1700 round - train_metric: 0.093802 - valid_metric: 0.286027\n",
            "\n",
            " - 1750 round - train_metric: 0.092119 - valid_metric: 0.286399\n",
            "\n",
            " - 1800 round - train_metric: 0.090807 - valid_metric: 0.286273\n",
            "\n",
            " - 1850 round - train_metric: 0.088757 - valid_metric: 0.286685\n",
            "\n",
            " - 1900 round - train_metric: 0.086056 - valid_metric: 0.287723\n",
            "\n",
            " - 1950 round - train_metric: 0.083208 - valid_metric: 0.288618\n",
            "\n",
            " - 2000 round - train_metric: 0.081046 - valid_metric: 0.289432\n",
            "\n",
            " - 2050 round - train_metric: 0.079668 - valid_metric: 0.289868\n",
            "\n",
            " - 2100 round - train_metric: 0.078037 - valid_metric: 0.290349\n",
            "\n",
            " - 2150 round - train_metric: 0.077996 - valid_metric: 0.290424\n",
            "\n",
            " - 2200 round - train_metric: 0.075913 - valid_metric: 0.291227\n",
            "\n",
            " - 2250 round - train_metric: 0.073949 - valid_metric: 0.291299\n",
            "\n",
            " - 2300 round - train_metric: 0.071871 - valid_metric: 0.292310\n",
            "\n",
            " - 2350 round - train_metric: 0.070652 - valid_metric: 0.292932\n",
            "\n",
            " - 2400 round - train_metric: 0.069404 - valid_metric: 0.293548\n",
            "\n",
            " - 2450 round - train_metric: 0.067989 - valid_metric: 0.294238\n",
            "\n",
            " - 2500 round - train_metric: 0.067402 - valid_metric: 0.293910\n",
            "\n",
            " - 2550 round - train_metric: 0.065953 - valid_metric: 0.294720\n",
            "\n",
            " - 2600 round - train_metric: 0.064786 - valid_metric: 0.295334\n",
            "\n",
            " - 2650 round - train_metric: 0.063474 - valid_metric: 0.296246\n",
            "\n",
            " - 2700 round - train_metric: 0.061877 - valid_metric: 0.297004\n",
            "\n",
            " - 2750 round - train_metric: 0.061388 - valid_metric: 0.297140\n",
            "\n",
            " - 2800 round - train_metric: 0.060354 - valid_metric: 0.297969\n",
            "\n",
            " - 2850 round - train_metric: 0.058661 - valid_metric: 0.298884\n",
            "\n",
            " - 2900 round - train_metric: 0.057843 - valid_metric: 0.299256\n",
            "\n",
            " - 2950 round - train_metric: 0.056272 - valid_metric: 0.300609\n",
            "\n",
            " - 3000 round - train_metric: 0.055056 - valid_metric: 0.301153\n",
            "\n",
            " - 3050 round - train_metric: 0.053998 - valid_metric: 0.301417\n",
            "\n",
            " - 3100 round - train_metric: 0.053124 - valid_metric: 0.302325\n",
            "\n",
            " - 3150 round - train_metric: 0.052433 - valid_metric: 0.302568\n",
            "\n",
            " - 3200 round - train_metric: 0.051119 - valid_metric: 0.303398\n",
            "\n",
            " - 3250 round - train_metric: 0.050255 - valid_metric: 0.303898\n",
            "\n",
            " - 3300 round - train_metric: 0.049551 - valid_metric: 0.304361\n",
            "\n",
            " - 3350 round - train_metric: 0.048384 - valid_metric: 0.305299\n",
            "\n",
            " - 3400 round - train_metric: 0.047224 - valid_metric: 0.306179\n",
            "\n",
            " - 3450 round - train_metric: 0.046133 - valid_metric: 0.306779\n",
            "\n",
            " - 3500 round - train_metric: 0.045554 - valid_metric: 0.307198\n",
            "\n",
            " - 3550 round - train_metric: 0.044869 - valid_metric: 0.307515\n",
            "\n",
            " - 3600 round - train_metric: 0.044209 - valid_metric: 0.307822\n",
            "\n",
            " - 3650 round - train_metric: 0.043503 - valid_metric: 0.308282\n",
            "\n",
            " - 3700 round - train_metric: 0.041893 - valid_metric: 0.309062\n",
            "\n",
            " - 3750 round - train_metric: 0.041237 - valid_metric: 0.309895\n",
            "\n",
            " - 3800 round - train_metric: 0.040711 - valid_metric: 0.310131\n",
            "\n",
            " - 3850 round - train_metric: 0.040118 - valid_metric: 0.310815\n",
            "\n",
            " - 3900 round - train_metric: 0.039826 - valid_metric: 0.311381\n",
            "\n",
            " - 3950 round - train_metric: 0.039762 - valid_metric: 0.311406\n",
            "\n",
            " - 4000 round - train_metric: 0.038900 - valid_metric: 0.312541\n",
            "\n",
            " - 4050 round - train_metric: 0.038483 - valid_metric: 0.312957\n",
            "\n",
            " - 4100 round - train_metric: 0.037852 - valid_metric: 0.314369\n",
            "\n",
            " - 4150 round - train_metric: 0.036959 - valid_metric: 0.315478\n",
            "\n",
            " - 4200 round - train_metric: 0.036438 - valid_metric: 0.316549\n",
            "\n",
            " - 4250 round - train_metric: 0.035867 - valid_metric: 0.317322\n",
            "\n",
            " - 4300 round - train_metric: 0.035079 - valid_metric: 0.317933\n",
            "\n",
            " - 4350 round - train_metric: 0.034793 - valid_metric: 0.317748\n",
            "\n",
            " - 4400 round - train_metric: 0.034542 - valid_metric: 0.318078\n",
            "\n",
            " - 4450 round - train_metric: 0.033909 - valid_metric: 0.318804\n",
            "\n",
            "- fold4 valid metric: 0.675345\n",
            "\n",
            "all valid mean metric:0.650658, global valid metric:0.649484\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (80000, 190)\n",
            "========test[features]         P_2  ...  D_145\n",
            "0      63.0  ...    NaN\n",
            "1      58.0  ...    0.0\n",
            "2      60.0  ...    0.0\n",
            "3      61.0  ...    0.0\n",
            "4      59.0  ...    0.0\n",
            "...     ...  ...    ...\n",
            "79995  68.0  ...    0.0\n",
            "79996  64.0  ...    0.0\n",
            "79997  69.0  ...    0.0\n",
            "79998  58.0  ...    0.0\n",
            "79999  58.0  ...    0.0\n",
            "\n",
            "[80000 rows x 188 columns]\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (80000, 190)\n",
            "========test[features]         P_2  ...  D_145\n",
            "0      63.0  ...    NaN\n",
            "1      58.0  ...    0.0\n",
            "2      60.0  ...    0.0\n",
            "3      61.0  ...    0.0\n",
            "4      59.0  ...    0.0\n",
            "...     ...  ...    ...\n",
            "79995  68.0  ...    0.0\n",
            "79996  64.0  ...    0.0\n",
            "79997  69.0  ...    0.0\n",
            "79998  58.0  ...    0.0\n",
            "79999  58.0  ...    0.0\n",
            "\n",
            "[80000 rows x 188 columns]\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (80000, 190)\n",
            "========test[features]         P_2  ...  D_145\n",
            "0      63.0  ...    NaN\n",
            "1      58.0  ...    0.0\n",
            "2      60.0  ...    0.0\n",
            "3      61.0  ...    0.0\n",
            "4      59.0  ...    0.0\n",
            "...     ...  ...    ...\n",
            "79995  68.0  ...    0.0\n",
            "79996  64.0  ...    0.0\n",
            "79997  69.0  ...    0.0\n",
            "79998  58.0  ...    0.0\n",
            "79999  58.0  ...    0.0\n",
            "\n",
            "[80000 rows x 188 columns]\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (80000, 190)\n",
            "========test[features]         P_2  ...  D_145\n",
            "0      63.0  ...    NaN\n",
            "1      58.0  ...    0.0\n",
            "2      60.0  ...    0.0\n",
            "3      61.0  ...    0.0\n",
            "4      59.0  ...    0.0\n",
            "...     ...  ...    ...\n",
            "79995  68.0  ...    0.0\n",
            "79996  64.0  ...    0.0\n",
            "79997  69.0  ...    0.0\n",
            "79998  58.0  ...    0.0\n",
            "79999  58.0  ...    0.0\n",
            "\n",
            "[80000 rows x 188 columns]\n",
            "========features ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'B_8', 'D_50', 'D_51', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_6', 'D_54', 'R_4', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'D_63', 'D_64', 'D_65', 'B_16', 'B_17', 'B_18', 'B_19', 'D_66', 'B_20', 'D_68', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'B_22', 'D_70', 'D_71', 'D_72', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'R_7', 'D_77', 'B_25', 'B_26', 'D_78', 'D_79', 'R_8', 'R_9', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'D_82', 'S_17', 'R_12', 'B_28', 'R_13', 'D_83', 'R_14', 'R_15', 'D_84', 'R_16', 'B_29', 'B_30', 'S_18', 'D_86', 'D_87', 'R_17', 'R_18', 'D_88', 'B_31', 'S_19', 'R_19', 'B_32', 'S_20', 'R_20', 'R_21', 'B_33', 'D_89', 'R_22', 'R_23', 'D_91', 'D_92', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_103', 'D_104', 'D_105', 'D_106', 'D_107', 'B_36', 'B_37', 'R_26', 'R_27', 'B_38', 'D_108', 'D_109', 'D_110', 'D_111', 'B_39', 'D_112', 'B_40', 'S_27', 'D_113', 'D_114', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_127', 'D_128', 'D_129', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'R_28', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_139', 'D_140', 'D_141', 'D_142', 'D_143', 'D_144', 'D_145']\n",
            "========test.shape (80000, 190)\n",
            "========test[features]         P_2  ...  D_145\n",
            "0      63.0  ...    NaN\n",
            "1      58.0  ...    0.0\n",
            "2      60.0  ...    0.0\n",
            "3      61.0  ...    0.0\n",
            "4      59.0  ...    0.0\n",
            "...     ...  ...    ...\n",
            "79995  68.0  ...    0.0\n",
            "79996  64.0  ...    0.0\n",
            "79997  69.0  ...    0.0\n",
            "79998  58.0  ...    0.0\n",
            "79999  58.0  ...    0.0\n",
            "\n",
            "[80000 rows x 188 columns]\n",
            "oof.shape,sub.shape (50000, 2) (80000, 2)\n",
            "mean_valid_metric,global_valid_metric 0.6506575689547132 0.6494839461127883\n",
            "available gpus: []\n",
            "----tmp1.shape------ (4154,)\n",
            "----tmp2.shape------ (6529,)\n",
            "----tmp.shape------ (10683,)\n",
            "----len(df)--before df.append(tmp)------ 9\n",
            "----len(df)--after df.append(tmp)------ 10\n",
            "----df.shape--all_feature.feather------ (10683, 6380)\n",
            "100% 224/224 [00:01<00:00, 184.23it/s]\n",
            "----df.shape--nn_series.feather------ (130000, 224)\n",
            "100% 208/208 [00:01<00:00, 112.42it/s]\n",
            "100% 1062/1062 [00:20<00:00, 52.12it/s] \n",
            "100% 1062/1062 [00:18<00:00, 58.74it/s] \n",
            "100% 177/177 [00:01<00:00, 149.02it/s]\n",
            "100% 141/141 [00:00<00:00, 267.76it/s]\n",
            "100% 885/885 [00:13<00:00, 65.15it/s] \n",
            "100% 885/885 [00:14<00:00, 60.87it/s] \n",
            "100% 885/885 [00:15<00:00, 55.97it/s] \n",
            "100% 1062/1062 [00:19<00:00, 55.47it/s] \n",
            "----tmp.shape------ (10683, 13)\n",
            "----df.shape--nn_all_feature.feather------ (10683, 6380)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LightGBM Quickstart**"
      ],
      "metadata": {
        "id": "r6MA1tFg2KPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "istZFEpQ2uUQ",
        "outputId": "1c2eae8e-d131-4b14-cdbf-d3d214db3c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU times: user 928 ms, sys: 328 ms, total: 1.26 s\n",
        "# Wall time: 43.7 s\n",
        "!rm -r /kaggle/working/lightgbm_kaggle \n",
        "!rm -r /kaggle/working/LightGBM\n",
        "!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n",
        "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "#git clone https://github.com/appleyuchi/lightgbm_colab\n",
        "!mv lightgbm_colab  LightGBM\n",
        " \n",
        "!apt-get install -y -qq libboost-all-dev\n",
        "# !cd LightGBM;rm -r build;mkdir build;cd build;echo\"here1\";cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..;echo\"here2\";make -j$(nproc)\n",
        "!cd LightGBM/python-package/;python setup.py install --precompile\n",
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcwyYVUP4SrH",
        "outputId": "97adf3df-8f02-4973-8947-a055a689c49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/kaggle/working/lightgbm_kaggle': No such file or directory\n",
            "rm: cannot remove '/kaggle/working/LightGBM': No such file or directory\n",
            "rm: cannot remove '/opt/conda/lib/python3.6/site-packages/lightgbm': No such file or directory\n",
            "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n",
            "mv: cannot stat 'lightgbm_colab': No such file or directory\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "running egg_info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching '*.txt' under directory 'compile'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching '*' under directory 'compile/compute'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "running install_lib\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "running install_egg_info\n",
            "removing '/usr/local/lib/python3.7/dist-packages/lightgbm-2.2.4-py3.7.egg-info' (and everything under it)\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.7/dist-packages/lightgbm-2.2.4-py3.7.egg-info\n",
            "running install_scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After running\n",
        "! git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "\n",
        "#You can run this oneliner which will build and compile LightGBM with GPU enabled in colab:\n",
        "! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 /usr/local/lib/python3.7/dist-packages/LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vxub3-o6LjS",
        "outputId": "c34a77a2-9940-4cd8-e028-c0ab1f7eba6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n",
            "\u001b[0mCMake Error: The source directory \"/usr/local/lib/python3.7/dist-packages/LightGBM\" does not exist.\n",
            "Specify --help for usage, or press the help button on the CMake GUI.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDi04ZlT9CVR",
        "outputId": "459b0eb8-5bd4-4227-9b76-153b67d81cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from matplotlib.colors import ListedColormap\n",
        "from cycler import cycler\n",
        "from IPython.display import display\n",
        "import datetime\n",
        "import scipy.stats\n",
        "import warnings\n",
        "from colorama import Fore, Back, Style\n",
        "import gc\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.calibration import CalibrationDisplay\n",
        "#from lightgbm import LGBMClassifier, log_evaluation\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "plt.rcParams['axes.facecolor'] = '#0057b8' # blue\n",
        "plt.rcParams['axes.prop_cycle'] = cycler(color=['#ffd700'] +\n",
        "                                         plt.rcParams['axes.prop_cycle'].by_key()['color'][1:])\n",
        "plt.rcParams['text.color'] = 'w'\n",
        "\n",
        "INFERENCE = True # set to False if you only want to cross-validate"
      ],
      "metadata": {
        "id": "9rK61b3y2Zzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def amex_metric(y_true: np.array, y_pred: np.array) -> float:\n",
        "\n",
        "    # count of positives and negatives\n",
        "    n_pos = y_true.sum()\n",
        "    n_neg = y_true.shape[0] - n_pos\n",
        "\n",
        "    # sorting by descring prediction values\n",
        "    indices = np.argsort(y_pred)[::-1]\n",
        "    preds, target = y_pred[indices], y_true[indices]\n",
        "\n",
        "    # filter the top 4% by cumulative row weights\n",
        "    weight = 20.0 - target * 19.0\n",
        "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
        "    four_pct_filter = cum_norm_weight <= 0.04\n",
        "\n",
        "    # default rate captured at 4%\n",
        "    d = target[four_pct_filter].sum() / n_pos\n",
        "\n",
        "    # weighted gini coefficient\n",
        "    lorentz = (target / n_pos).cumsum()\n",
        "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
        "\n",
        "    # max weighted gini coefficient\n",
        "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
        "\n",
        "    # normalized weighted gini coefficient\n",
        "    g = gini / gini_max\n",
        "\n",
        "    return 0.5 * (g + d)\n",
        "\n",
        "def lgb_amex_metric(y_true, y_pred):\n",
        "    \"\"\"The competition metric with lightgbm's calling convention\"\"\"\n",
        "    return ('amex',\n",
        "            amex_metric(y_true, y_pred),\n",
        "            True)"
      ],
      "metadata": {
        "id": "TiyMRhJX2abd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "features_avg = ['B_1', 'B_2', 'B_3', 'B_4', 'B_5', 'B_6', 'B_8', 'B_9', 'B_10', 'B_11', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_20', 'B_21', 'B_22', 'B_23', 'B_24', 'B_25', 'B_28', 'B_29', 'B_30', 'B_32', 'B_33', 'B_37', 'B_38', 'B_39', 'B_40', 'B_41', 'B_42', 'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_50', 'D_51', 'D_53', 'D_54', 'D_55', 'D_58', 'D_59', 'D_60', 'D_61', 'D_62', 'D_65', 'D_66', 'D_69', 'D_70', 'D_71', 'D_72', 'D_73', 'D_74', 'D_75', 'D_76', 'D_77', 'D_78', 'D_80', 'D_82', 'D_84', 'D_86', 'D_91', 'D_92', 'D_94', 'D_96', 'D_103', 'D_104', 'D_108', 'D_112', 'D_113', 'D_114', 'D_115', 'D_117', 'D_118', 'D_119', 'D_120', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_128', 'D_129', 'D_131', 'D_132', 'D_133', 'D_134', 'D_135', 'D_136', 'D_140', 'D_141', 'D_142', 'D_144', 'D_145', 'P_2', 'P_3', 'P_4', 'R_1', 'R_2', 'R_3', 'R_7', 'R_8', 'R_9', 'R_10', 'R_11', 'R_14', 'R_15', 'R_16', 'R_17', 'R_20', 'R_21', 'R_22', 'R_24', 'R_26', 'R_27', 'S_3', 'S_5', 'S_6', 'S_7', 'S_9', 'S_11', 'S_12', 'S_13', 'S_15', 'S_16', 'S_18', 'S_22', 'S_23', 'S_25', 'S_26']\n",
        "features_min = ['B_2', 'B_4', 'B_5', 'B_9', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_19', 'B_20', 'B_28', 'B_29', 'B_33', 'B_36', 'B_42', 'D_39', 'D_41', 'D_42', 'D_45', 'D_46', 'D_48', 'D_50', 'D_51', 'D_53', 'D_55', 'D_56', 'D_58', 'D_59', 'D_60', 'D_62', 'D_70', 'D_71', 'D_74', 'D_75', 'D_78', 'D_83', 'D_102', 'D_112', 'D_113', 'D_115', 'D_118', 'D_119', 'D_121', 'D_122', 'D_128', 'D_132', 'D_140', 'D_141', 'D_144', 'D_145', 'P_2', 'P_3', 'R_1', 'R_27', 'S_3', 'S_5', 'S_7', 'S_9', 'S_11', 'S_12', 'S_23', 'S_25']\n",
        "features_max = ['B_1', 'B_2', 'B_3', 'B_4', 'B_5', 'B_6', 'B_7', 'B_8', 'B_9', 'B_10', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_21', 'B_23', 'B_24', 'B_25', 'B_29', 'B_30', 'B_33', 'B_37', 'B_38', 'B_39', 'B_40', 'B_42', 'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_49', 'D_50', 'D_52', 'D_55', 'D_56', 'D_58', 'D_59', 'D_60', 'D_61', 'D_63', 'D_64', 'D_65', 'D_70', 'D_71', 'D_72', 'D_73', 'D_74', 'D_76', 'D_77', 'D_78', 'D_80', 'D_82', 'D_84', 'D_91', 'D_102', 'D_105', 'D_107', 'D_110', 'D_111', 'D_112', 'D_115', 'D_116', 'D_117', 'D_118', 'D_119', 'D_121', 'D_122', 'D_123', 'D_124', 'D_125', 'D_126', 'D_128', 'D_131', 'D_132', 'D_133', 'D_134', 'D_135', 'D_136', 'D_138', 'D_140', 'D_141', 'D_142', 'D_144', 'D_145', 'P_2', 'P_3', 'P_4', 'R_1', 'R_3', 'R_5', 'R_6', 'R_7', 'R_8', 'R_10', 'R_11', 'R_14', 'R_17', 'R_20', 'R_26', 'R_27', 'S_3', 'S_5', 'S_7', 'S_8', 'S_11', 'S_12', 'S_13', 'S_15', 'S_16', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27']\n",
        "features_last = ['B_1', 'B_2', 'B_3', 'B_4', 'B_5', 'B_6', 'B_7', 'B_8', 'B_9', 'B_10', 'B_11', 'B_12', 'B_13', 'B_14', 'B_15', 'B_16', 'B_17', 'B_18', 'B_19', 'B_20', 'B_21', 'B_22', 'B_23', 'B_24', 'B_25', 'B_26', 'B_28', 'B_29', 'B_30', 'B_32', 'B_33', 'B_36', 'B_37', 'B_38', 'B_39', 'B_40', 'B_41', 'B_42', 'D_39', 'D_41', 'D_42', 'D_43', 'D_44', 'D_45', 'D_46', 'D_47', 'D_48', 'D_49', 'D_50', 'D_51', 'D_52', 'D_53', 'D_54', 'D_55', 'D_56', 'D_58', 'D_59', 'D_60', 'D_61', 'D_62', 'D_63', 'D_64', 'D_65', 'D_69', 'D_70', 'D_71', 'D_72', 'D_73', 'D_75', 'D_76', 'D_77', 'D_78', 'D_79', 'D_80', 'D_81', 'D_82', 'D_83', 'D_86', 'D_91', 'D_96', 'D_105', 'D_106', 'D_112', 'D_114', 'D_119', 'D_120', 'D_121', 'D_122', 'D_124', 'D_125', 'D_126', 'D_127', 'D_130', 'D_131', 'D_132', 'D_133', 'D_134', 'D_138', 'D_140', 'D_141', 'D_142', 'D_145', 'P_2', 'P_3', 'P_4', 'R_1', 'R_2', 'R_3', 'R_4', 'R_5', 'R_6', 'R_7', 'R_8', 'R_9', 'R_10', 'R_11', 'R_12', 'R_13', 'R_14', 'R_15', 'R_19', 'R_20', 'R_26', 'R_27', 'S_3', 'S_5', 'S_6', 'S_7', 'S_8', 'S_9', 'S_11', 'S_12', 'S_13', 'S_16', 'S_19', 'S_20', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'S_27']\n",
        "#for i in ['test', 'train'] if INFERENCE else ['train']:\n",
        "for i in ['train', 'train'] if INFERENCE else ['train']:\n",
        "    #df = pd.read_parquet(f'../input/amex-data-integer-dtypes-parquet-format/{i}.parquet')\n",
        "    df = pd.read_parquet(f'/content/drive/MyDrive/Credit_risk/Kaggle-American-Express/input/{i}.parquet')\n",
        "    cid = pd.Categorical(df.pop('customer_ID'), ordered=True)\n",
        "    last = (cid != np.roll(cid, -1)) # mask for last statement of every customer\n",
        "    if 'target' in df.columns:\n",
        "        df.drop(columns=['target'], inplace=True)\n",
        "    gc.collect()\n",
        "    print('Read', i)\n",
        "    df_avg = (df\n",
        "              .groupby(cid)\n",
        "              .mean()[features_avg]\n",
        "              .rename(columns={f: f\"{f}_avg\" for f in features_avg})\n",
        "             )\n",
        "    gc.collect()\n",
        "    print('Computed avg', i)\n",
        "    df_min = (df\n",
        "              .groupby(cid)\n",
        "              .min()[features_min]\n",
        "              .rename(columns={f: f\"{f}_min\" for f in features_min})\n",
        "             )\n",
        "    gc.collect()\n",
        "    print('Computed min', i)\n",
        "    df_max = (df\n",
        "              .groupby(cid)\n",
        "              .max()[features_max]\n",
        "              .rename(columns={f: f\"{f}_max\" for f in features_max})\n",
        "             )\n",
        "    gc.collect()\n",
        "    print('Computed max', i)\n",
        "    df = (df.loc[last, features_last]\n",
        "          .rename(columns={f: f\"{f}_last\" for f in features_last})\n",
        "          .set_index(np.asarray(cid[last]))\n",
        "         )\n",
        "    gc.collect()\n",
        "    print('Computed last', i)\n",
        "    df = pd.concat([df, df_min, df_max, df_avg], axis=1)\n",
        "    if i == 'train': train = df\n",
        "    else: test = df\n",
        "    print(f\"{i} shape: {df.shape}\")\n",
        "    del df, df_avg, df_min, df_max, cid, last\n",
        "\n",
        "target = pd.read_csv('../content/drive/MyDrive/Credit_risk/Kaggle-American-Express/input/train_labels.csv').target.values\n",
        "print(f\"target shape: {target.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "t2uHECyI2Ke3",
        "outputId": "1a492f6c-9e12-43fb-d30e-50ea5d3c7b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ArrowInvalid",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             result = self.api.parquet.read_table(\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             ).to_pandas(**to_pandas_kwargs)\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit)\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mignore_prefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_prefixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m                 \u001b[0mpre_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m                 \u001b[0mcoerce_int96_timestamp_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_int96_timestamp_unit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m             )\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, **kwargs)\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m             self._dataset = ds.FileSystemDataset(\n\u001b[0;32m-> 1711\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysical_schema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1712\u001b[0m                 \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m                 \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfragment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P2P lending with AI master"
      ],
      "metadata": {
        "id": "klwS6TsO1bG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbhXTQy71zc4",
        "outputId": "f6758796-f6d4-420e-d0c6-66287885bd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python code_1_acceptance.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kto3TH7q1kq3",
        "outputId": "fc47f44b-449f-4b57-aa56-1cd2b4c8d9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading file\n",
            "file shape (2, 1)\n",
            "date encoding\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\", line 3361, in get_loc\n",
            "    return self._engine.get_loc(casted_key)\n",
            "  File \"pandas/_libs/index.pyx\", line 76, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
            "KeyError: 'issue_d'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"code_1_acceptance.py\", line 18, in <module>\n",
            "    data['issue_d'] = pd.to_datetime(data['issue_d'])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\", line 3458, in __getitem__\n",
            "    indexer = self.columns.get_loc(key)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\", line 3363, in get_loc\n",
            "    raise KeyError(key) from err\n",
            "KeyError: 'issue_d'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "print('reading file')\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/data/input_file_1.csv.zip', sep = ',', index_col=0, compression='zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "KW6QGRQv2WAn",
        "outputId": "5db56e1b-4e2d-4d2e-b663-d694608aff2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading file\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d2e352243678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reading file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Credit_risk/P2P-lending-with-AI-master/data/input_file_1.csv.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;31m# ZIP Compression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_BytesZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m                 \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;31m# TextIOBase, TextIOWrapper, mmap]]]\"; expected \"Union[Union[str,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# _PathLike[str]], IO[bytes]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_zip\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    }
  ]
}